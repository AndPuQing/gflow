<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>gflow Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A lightweight, single-node job scheduler inspired by Slurm">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">gflow Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Welcome to the <strong>gflow</strong> documentation! gflow is a lightweight, single-node job scheduler written in Rust, inspired by Slurm. It is designed for efficiently managing and scheduling tasks, especially on machines with GPU resources.</p>
<h2 id="what-is-gflow"><a class="header" href="#what-is-gflow">What is gflow?</a></h2>
<p>gflow provides a simple yet powerful way to:</p>
<ul>
<li><strong>Queue and schedule jobs</strong> on a single machine with multiple GPUs</li>
<li><strong>Manage dependencies</strong> between jobs</li>
<li><strong>Set priorities</strong> for different tasks</li>
<li><strong>Enforce time limits</strong> to prevent runaway jobs</li>
<li><strong>Monitor and control</strong> job execution through intuitive CLI tools</li>
</ul>
<h2 id="who-is-gflow-for"><a class="header" href="#who-is-gflow-for">Who is gflow for?</a></h2>
<p>gflow is perfect for:</p>
<ul>
<li><strong>ML/DL Researchers</strong>: Training multiple models on a shared workstation</li>
<li><strong>Data Scientists</strong>: Running long experiments with proper resource allocation</li>
<li><strong>Students</strong>: Learning job scheduling concepts in a simplified environment</li>
<li><strong>Developers</strong>: Testing and debugging batch processing workflows</li>
<li><strong>Anyone</strong> who needs better control over job execution on a single powerful machine</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<h3 id="-daemon-based-scheduling"><a class="header" href="#-daemon-based-scheduling">🚀 Daemon-based Scheduling</a></h3>
<p>A persistent daemon (<code>gflowd</code>) runs in the background, managing the job queue and automatically allocating resources.</p>
<h3 id="-rich-job-submission"><a class="header" href="#-rich-job-submission">📋 Rich Job Submission</a></h3>
<p>Submit jobs with various options:</p>
<ul>
<li>GPU resource requests</li>
<li>Job dependencies</li>
<li>Priority levels</li>
<li>Time limits</li>
<li>Conda environment activation</li>
<li>Job arrays for parallel tasks</li>
</ul>
<h3 id="-time-limits"><a class="header" href="#-time-limits">⏱️ Time Limits</a></h3>
<p>Set maximum runtime for jobs (similar to Slurm's <code>--time</code>) to prevent runaway processes:</p>
<pre><code class="language-bash">gbatch --time 2:00:00 python train.py
</code></pre>
<h3 id="-job-dependencies"><a class="header" href="#-job-dependencies">🔗 Job Dependencies</a></h3>
<p>Create complex workflows where jobs depend on others:</p>
<pre><code class="language-bash">gbatch --depends-on 123 python postprocess.py
</code></pre>
<h3 id="-powerful-monitoring"><a class="header" href="#-powerful-monitoring">📊 Powerful Monitoring</a></h3>
<p>Query and filter jobs with flexible options:</p>
<pre><code class="language-bash">gqueue -s Running -f JOBID,NAME,TIME,TIMELIMIT
</code></pre>
<h3 id="-tmux-integration"><a class="header" href="#-tmux-integration">🖥️ tmux Integration</a></h3>
<p>Every job runs in its own tmux session, allowing you to:</p>
<ul>
<li>Attach to running jobs</li>
<li>View output in real-time</li>
<li>Resume interrupted sessions</li>
<li>Automatic output logging to files</li>
</ul>
<h2 id="quick-example"><a class="header" href="#quick-example">Quick Example</a></h2>
<pre><code class="language-bash"># Start the scheduler (run in a separate terminal)
$ gflowd up

# Submit a training job with 1 GPU and 2-hour time limit
$ gbatch --gpus 1 --time 2:00:00 python train.py

# Check the job queue
$ gqueue

# Inspect scheduler status and GPU usage
$ ginfo info

# Watch jobs in real-time
$ watch gqueue

# Stop the scheduler
$ gflowd down
</code></pre>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<pre><code>┌──────────────────────────────────┐
│          User Commands           │
│ (gbatch, gqueue, gcancel, ginfo) │
└────────────────┬─────────────────┘
                 │
                 │ HTTP API
                 ▼
┌──────────────────────────────────┐
│          gflowd Daemon           │
│  ┌────────────────────────────┐  │
│  │ Scheduler (5s interval)    │  │
│  │ - Check dependencies       │  │
│  │ - Check GPU availability   │  │
│  │ - Check timeouts           │  │
│  │ - Assign jobs to resources │  │
│  └────────────────────────────┘  │
└────────────────┬─────────────────┘
                 │
                 │ TmuxExecutor
                 ▼
 ┌─────────────────────────────────┐
 │       Tmux Sessions (Jobs)      │
 │  ┌───────┐ ┌───────┐ ┌───────┐  │
 │  │ Job 1 │ │ Job 2 │ │ Job 3 │  │
 │  │       │ │       │ │       │  │
 │  │(GPU 0)│ │(NoGPU)│ │(GPU 1)│  │
 │  └──┬────┘ └───┬───┘ └───┬───┘  │
 │     │          │         │      │
 │     └──────────┴─────────┘      │
 │        pipe-pane logging        │
 └───────────────┬─────────────────┘
                 │
                 ▼
     ~/.local/share/gflow/logs
</code></pre>
<h2 id="command-overview"><a class="header" href="#command-overview">Command Overview</a></h2>
<p>gflow consists of five command-line tools:</p>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Purpose</th><th>Similar to</th></tr></thead><tbody>
<tr><td><code>gflowd</code></td><td>Scheduler daemon</td><td>Slurm's <code>slurmctld</code></td></tr>
<tr><td><code>ginfo</code></td><td>Display scheduler and GPU info</td><td>Slurm's <code>scontrol show nodes</code></td></tr>
<tr><td><code>gbatch</code></td><td>Submit jobs</td><td>Slurm's <code>sbatch</code></td></tr>
<tr><td><code>gqueue</code></td><td>Query job queue</td><td>Slurm's <code>squeue</code></td></tr>
<tr><td><code>gcancel</code></td><td>Cancel jobs</td><td>Slurm's <code>scancel</code></td></tr>
</tbody></table>
</div>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Ready to dive in? Check out the <a href="./getting-started/installation.html">Installation Guide</a> to get gflow up and running!</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>gflow is open source! Contributions are welcome:</p>
<ul>
<li>🐛 <a href="https://github.com/AndPuQing/gflow/issues">Report bugs</a></li>
<li>💡 <a href="https://github.com/AndPuQing/gflow/issues">Request features</a></li>
<li>🔧 <a href="https://github.com/AndPuQing/gflow/pulls">Submit pull requests</a></li>
<li>📖 <a href="https://github.com/AndPuQing/gflow/edit/main/docs/">Improve documentation</a></li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>gflow is licensed under the MIT License. See <a href="https://github.com/AndPuQing/gflow/blob/main/LICENSE">LICENSE</a> for details.</p>
<hr />
<p><strong>Next</strong>: <a href="./getting-started/installation.html">Installation Guide</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>This guide will help you install gflow on your system.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li><strong>Operating System</strong>: Linux (tested on Ubuntu 20.04+)</li>
<li><strong>Rust</strong>: Version 1.70+ (for building from source)</li>
<li><strong>tmux</strong>: Required for job execution</li>
<li><strong>NVIDIA GPU</strong> (optional): For GPU job scheduling</li>
<li><strong>NVIDIA drivers</strong> (optional): If using GPU features</li>
</ul>
<h3 id="installing-prerequisites"><a class="header" href="#installing-prerequisites">Installing Prerequisites</a></h3>
<h4 id="ubuntudebian"><a class="header" href="#ubuntudebian">Ubuntu/Debian</a></h4>
<pre><code class="language-bash"># Install tmux
sudo apt-get update
sudo apt-get install tmux

# Install Rust (if building from source)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h4 id="fedorarhel"><a class="header" href="#fedorarhel">Fedora/RHEL</a></h4>
<pre><code class="language-bash"># Install tmux
sudo dnf install tmux

# Install Rust (if building from source)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre>
<h2 id="installation-methods"><a class="header" href="#installation-methods">Installation Methods</a></h2>
<h3 id="method-1-install-via-cargo-recommended"><a class="header" href="#method-1-install-via-cargo-recommended">Method 1: Install via Cargo (Recommended)</a></h3>
<p>This is the easiest way to install gflow:</p>
<pre><code class="language-bash">cargo install gflow
</code></pre>
<p>This will install all five binaries:</p>
<ul>
<li><code>gflowd</code> - The scheduler daemon</li>
<li><code>ginfo</code> - Scheduler inspection tool</li>
<li><code>gbatch</code> - Job submission tool</li>
<li><code>gqueue</code> - Job query tool</li>
<li><code>gcancel</code> - Job cancellation tool</li>
</ul>
<p>The binaries will be installed to <code>~/.cargo/bin/</code>, which should be in your <code>PATH</code>.</p>
<h3 id="method-2-build-from-source"><a class="header" href="#method-2-build-from-source">Method 2: Build from Source</a></h3>
<p>If you want to build from the latest source code:</p>
<ol>
<li>
<p><strong>Clone the repository</strong>:</p>
<pre><code class="language-bash">git clone https://github.com/AndPuQing/gflow.git
cd gflow
</code></pre>
</li>
<li>
<p><strong>Build the project</strong>:</p>
<pre><code class="language-bash">cargo build --release
</code></pre>
<p>The executables will be in <code>target/release/</code>.</p>
</li>
<li>
<p><strong>Install to system</strong> (optional):</p>
<pre><code class="language-bash">cargo install --path .
</code></pre>
</li>
</ol>
<h3 id="method-3-download-pre-built-binaries"><a class="header" href="#method-3-download-pre-built-binaries">Method 3: Download Pre-built Binaries</a></h3>
<p>Check the <a href="https://github.com/AndPuQing/gflow/releases">Releases page</a> for pre-built binaries (if available).</p>
<h2 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h2>
<p>After installation, verify that gflow is properly installed:</p>
<p>Check versions:</p>
<pre><code class="language-bash">$ gflowd --version
gflowd 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<pre><code class="language-bash">$ ginfo --version
ginfo 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<pre><code class="language-bash">$ gbatch --version
gbatch 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<pre><code class="language-bash">$ gqueue --version
gqueue 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<pre><code class="language-bash">$ gcancel --version
gcancel 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<p>Verify commands are in PATH:</p>
<pre><code class="language-bash">$ which ginfo
/home/happy/.cargo/bin/ginfo
</code></pre>
<p>All commands are properly installed and available in your PATH.</p>
<h2 id="post-installation-setup"><a class="header" href="#post-installation-setup">Post-Installation Setup</a></h2>
<h3 id="1-test-tmux"><a class="header" href="#1-test-tmux">1. Test tmux</a></h3>
<p>Make sure tmux is working:</p>
<pre><code class="language-bash">tmux new-session -d -s test
tmux has-session -t test &amp;&amp; echo "tmux is working!"
tmux kill-session -t test
</code></pre>
<h3 id="2-gpu-detection-optional"><a class="header" href="#2-gpu-detection-optional">2. GPU Detection (Optional)</a></h3>
<p>If you have NVIDIA GPUs, verify they're detected:</p>
<pre><code class="language-bash"># Start the daemon
$ gflowd up

# Verify it started
$ gflowd status
Status: Not Running
</code></pre>
<p>Check system info and GPU allocation:</p>
<pre><code class="language-bash">$ ginfo info
</code></pre>
<p>The daemon shows GPU information if NVIDIA GPUs are available.</p>
<h3 id="3-create-configuration-directory"><a class="header" href="#3-create-configuration-directory">3. Create Configuration Directory</a></h3>
<p>gflow will create this automatically, but you can do it manually:</p>
<pre><code class="language-bash">mkdir -p ~/.config/gflow
mkdir -p ~/.local/share/gflow/logs
</code></pre>
<h2 id="configuration-files"><a class="header" href="#configuration-files">Configuration Files</a></h2>
<p>gflow uses the following directories:</p>
<div class="table-wrapper"><table><thead><tr><th>Location</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>~/.config/gflow/gflowd.toml</code></td><td>Configuration file (optional)</td></tr>
<tr><td><code>~/.local/share/gflow/state.json</code></td><td>Persistent job state</td></tr>
<tr><td><code>~/.local/share/gflow/logs/</code></td><td>Job output logs</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="issue-command-not-found"><a class="header" href="#issue-command-not-found">Issue: Command not found</a></h3>
<p>If you get "command not found" after installation:</p>
<ol>
<li>
<p><strong>Check if <code>~/.cargo/bin</code> is in your PATH</strong>:</p>
<pre><code class="language-bash">echo $PATH | grep -o ~/.cargo/bin
</code></pre>
</li>
<li>
<p><strong>Add to PATH</strong> if missing (add to <code>~/.bashrc</code> or <code>~/.zshrc</code>):</p>
<pre><code class="language-bash">export PATH="$HOME/.cargo/bin:$PATH"
</code></pre>
</li>
<li>
<p><strong>Reload shell</strong>:</p>
<pre><code class="language-bash">source ~/.bashrc  # or ~/.zshrc
</code></pre>
</li>
</ol>
<h3 id="issue-permission-denied"><a class="header" href="#issue-permission-denied">Issue: Permission denied</a></h3>
<p>If you get permission errors:</p>
<pre><code class="language-bash"># Make binaries executable
chmod +x ~/.cargo/bin/gflow*
</code></pre>
<h3 id="issue-tmux-not-found"><a class="header" href="#issue-tmux-not-found">Issue: tmux not found</a></h3>
<p>Install tmux using your package manager:</p>
<pre><code class="language-bash"># Ubuntu/Debian
sudo apt-get install tmux

# Fedora/RHEL
sudo dnf install tmux

# macOS (if attempting to use gflow on macOS)
brew install tmux
</code></pre>
<h3 id="issue-gpu-not-detected"><a class="header" href="#issue-gpu-not-detected">Issue: GPU not detected</a></h3>
<ol>
<li>
<p><strong>Check NVIDIA drivers</strong>:</p>
<pre><code class="language-bash">nvidia-smi
</code></pre>
</li>
<li>
<p><strong>Verify NVML library</strong>:</p>
<pre><code class="language-bash">ldconfig -p | grep libnvidia-ml
</code></pre>
</li>
<li>
<p>If GPU detection fails, gflow will still work but won't manage GPU resources.</p>
</li>
</ol>
<h2 id="updating-gflow"><a class="header" href="#updating-gflow">Updating gflow</a></h2>
<h3 id="if-installed-via-cargo"><a class="header" href="#if-installed-via-cargo">If installed via cargo:</a></h3>
<pre><code class="language-bash">cargo install gflow --force
</code></pre>
<h3 id="if-built-from-source"><a class="header" href="#if-built-from-source">If built from source:</a></h3>
<pre><code class="language-bash">cd gflow
git pull
cargo build --release
cargo install --path . --force
</code></pre>
<h2 id="uninstallation"><a class="header" href="#uninstallation">Uninstallation</a></h2>
<p>To remove gflow:</p>
<pre><code class="language-bash"># Stop the daemon first
gflowd down

# Uninstall binaries
cargo uninstall gflow

# Remove configuration and data (optional)
rm -rf ~/.config/gflow
rm -rf ~/.local/share/gflow
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now that gflow is installed, head to the <a href="getting-started/./quick-start.html">Quick Start Guide</a> to learn how to use it!</p>
<hr />
<p><strong>Previous</strong>: <a href="getting-started/../introduction.html">Introduction</a> | <strong>Next</strong>: <a href="getting-started/./quick-start.html">Quick Start</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<p>This guide will get you up and running with gflow in 5 minutes.</p>
<h2 id="starting-the-scheduler"><a class="header" href="#starting-the-scheduler">Starting the Scheduler</a></h2>
<p>First, start the gflow daemon:</p>
<pre><code class="language-shell">$ gflowd up
gflowd started.
</code></pre>
<p>Run this in its own terminal or tmux session and leave it running. You can confirm that it started successfully with:</p>
<pre><code class="language-shell">$ gflowd status
Status: Not Running
</code></pre>
<p>Verify it's reachable from another terminal:</p>
<pre><code class="language-shell">$ ginfo info
</code></pre>
<h2 id="your-first-job"><a class="header" href="#your-first-job">Your First Job</a></h2>
<p>Let's submit a simple job:</p>
<pre><code class="language-shell">$ gbatch echo 'Hello from gflow!'
</code></pre>
<h2 id="checking-job-status"><a class="header" href="#checking-job-status">Checking Job Status</a></h2>
<p>View the job queue:</p>
<pre><code class="language-shell">$ gqueue
</code></pre>
<p>Job states:</p>
<ul>
<li><code>PD</code> (Queued) - Waiting to run</li>
<li><code>R</code> (Running) - Currently executing</li>
<li><code>CD</code> (Finished) - Completed successfully</li>
<li><code>F</code> (Failed) - Failed with error</li>
<li><code>CA</code> (Cancelled) - Manually cancelled</li>
<li><code>TO</code> (Timeout) - Exceeded time limit</li>
</ul>
<h2 id="viewing-job-output"><a class="header" href="#viewing-job-output">Viewing Job Output</a></h2>
<p>Job output is automatically logged:</p>
<pre><code class="language-shell">$ sleep 6
$ gjob -j 1
</code></pre>
<h2 id="submitting-jobs-with-options"><a class="header" href="#submitting-jobs-with-options">Submitting Jobs with Options</a></h2>
<h3 id="job-with-gpu-request"><a class="header" href="#job-with-gpu-request">Job with GPU Request</a></h3>
<pre><code class="language-shell">gbatch --gpus 1 nvidia-smi
</code></pre>
<h3 id="job-with-time-limit"><a class="header" href="#job-with-time-limit">Job with Time Limit</a></h3>
<pre><code class="language-shell"># 30-minute limit
gbatch --time 30 python train.py

# 2-hour limit
gbatch --time 2:00:00 python long_train.py
</code></pre>
<h3 id="job-with-priority"><a class="header" href="#job-with-priority">Job with Priority</a></h3>
<pre><code class="language-shell"># Higher priority (runs first)
gbatch --priority 100 python urgent_task.py

# Lower priority (default is 10)
gbatch --priority 5 python background_task.py
</code></pre>
<h3 id="job-script"><a class="header" href="#job-script">Job Script</a></h3>
<p>Create a file <code>my_job.sh</code>:</p>
<pre><code class="language-shell">#!/bin/shell
# GFLOW --gpus 1
# GFLOW --time 1:00:00
# GFLOW --priority 20

echo "Job started at $(date)"
python train.py --epochs 10
echo "Job finished at $(date)"
</code></pre>
<p>Make it executable and submit:</p>
<pre><code class="language-shell">chmod +x my_job.sh
gbatch my_job.sh
</code></pre>
<h2 id="job-dependencies"><a class="header" href="#job-dependencies">Job Dependencies</a></h2>
<p>Run jobs in sequence:</p>
<pre><code class="language-shell"># Job 1: Preprocessing
gbatch python preprocess.py --name "prep"
# Note the job ID, e.g., 2

# Job 2: Training (depends on job 2)
gbatch python train.py --depends-on 2 --name "train"

# Job 3: Evaluation (depends on job 3)
gbatch python evaluate.py --depends-on 3 --name "eval"
</code></pre>
<p>View dependency tree:</p>
<pre><code class="language-shell">gqueue -t
</code></pre>
<h2 id="monitoring-jobs"><a class="header" href="#monitoring-jobs">Monitoring Jobs</a></h2>
<h3 id="watch-queue-in-real-time"><a class="header" href="#watch-queue-in-real-time">Watch Queue in Real-time</a></h3>
<pre><code class="language-shell">watch -n 2 gqueue
</code></pre>
<h3 id="filter-by-state"><a class="header" href="#filter-by-state">Filter by State</a></h3>
<pre><code class="language-shell"># Show only running jobs
gqueue -s Running

# Show running and queued jobs
gqueue -s Running,Queued
</code></pre>
<h3 id="custom-output-format"><a class="header" href="#custom-output-format">Custom Output Format</a></h3>
<pre><code class="language-shell">$ gqueue -f JOBID,NAME,ST,TIME,TIMELIMIT
</code></pre>
<h3 id="view-specific-jobs"><a class="header" href="#view-specific-jobs">View Specific Jobs</a></h3>
<pre><code class="language-shell"># Single job
gqueue -j 5

# Multiple jobs
gqueue -j 5,6,7
</code></pre>
<h2 id="cancelling-jobs"><a class="header" href="#cancelling-jobs">Cancelling Jobs</a></h2>
<p>Cancel a job:</p>
<pre><code class="language-shell">gcancel 5
</code></pre>
<p>Output:</p>
<pre><code>Job 5 cancelled.
</code></pre>
<h2 id="attaching-to-running-jobs"><a class="header" href="#attaching-to-running-jobs">Attaching to Running Jobs</a></h2>
<p>Each job runs in a tmux session. You can attach to see live output:</p>
<pre><code class="language-shell"># Get the job's session name from gqueue
gqueue -f JOBID,NAME

# Attach to the session
tmux attach -t &lt;session_name&gt;

# Detach without stopping the job
# Press: Ctrl+B then D
</code></pre>
<h2 id="stopping-the-scheduler"><a class="header" href="#stopping-the-scheduler">Stopping the Scheduler</a></h2>
<p>When you're done:</p>
<pre><code class="language-shell">gflowd down
</code></pre>
<p>This stops the daemon, saves state, and removes the tmux session.</p>
<h2 id="example-workflow"><a class="header" href="#example-workflow">Example Workflow</a></h2>
<p>Here's a complete example workflow:</p>
<pre><code class="language-shell"># 1. Start scheduler (run in another terminal)
gflowd up

# 2. Submit preprocessing job
gbatch --time 10 python preprocess.py --output data.pkl --name prep
# Job ID: 1

# 3. Submit training jobs (depend on preprocessing)
gbatch --time 2:00:00 --gpus 1 --depends-on 1 python train.py --lr 0.001 --name train_lr001
gbatch --time 2:00:00 --gpus 1 --depends-on 1 python train.py --lr 0.01 --name train_lr01

# 4. Monitor jobs
watch gqueue

# 5. Check logs when done
cat ~/.local/share/gflow/logs/1.log
cat ~/.local/share/gflow/logs/2.log
cat ~/.local/share/gflow/logs/3.log

# 6. Stop scheduler
gflowd down
</code></pre>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="parallel-jobs-array"><a class="header" href="#parallel-jobs-array">Parallel Jobs (Array)</a></h3>
<p>Run multiple similar tasks:</p>
<pre><code class="language-shell">gbatch --array 1-10 --time 30 \
       python process.py --task $GFLOW_ARRAY_TASK_ID
</code></pre>
<p>This creates 10 jobs, each with <code>$GFLOW_ARRAY_TASK_ID</code> set to 1, 2, ..., 10.</p>
<h3 id="gpu-sweeps"><a class="header" href="#gpu-sweeps">GPU Sweeps</a></h3>
<p>Test different hyperparameters on different GPUs:</p>
<pre><code class="language-shell"># Each job gets 1 GPU
gbatch --gpus 1 --time 4:00:00 python train.py --lr 0.001
gbatch --gpus 1 --time 4:00:00 python train.py --lr 0.01
gbatch --gpus 1 --time 4:00:00 python train.py --lr 0.1
</code></pre>
<h3 id="conda-environment"><a class="header" href="#conda-environment">Conda Environment</a></h3>
<p>Use a specific conda environment:</p>
<pre><code class="language-shell">gbatch --conda-env myenv python script.py
</code></pre>
<h2 id="tips-for-beginners"><a class="header" href="#tips-for-beginners">Tips for Beginners</a></h2>
<ol>
<li>
<p><strong>Always set time limits</strong> for production jobs:</p>
<pre><code class="language-shell">gbatch --time 2:00:00 your_command
</code></pre>
</li>
<li>
<p><strong>Use <code>watch gqueue</code></strong> to monitor jobs in real-time</p>
</li>
<li>
<p><strong>Check logs</strong> when jobs fail:</p>
<pre><code class="language-shell">cat ~/.local/share/gflow/logs/&lt;job_id&gt;.log
</code></pre>
</li>
<li>
<p><strong>Test scripts first</strong> with short time limits:</p>
<pre><code class="language-shell">gbatch --time 1 shell test.sh
</code></pre>
</li>
<li>
<p><strong>Use job dependencies</strong> for workflows:</p>
<pre><code class="language-shell">gbatch --depends-on &lt;prev_job_id&gt; your_command
</code></pre>
</li>
</ol>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Now that you're familiar with the basics, explore:</p>
<ul>
<li><a href="getting-started/../user-guide/job-submission.html">Job Submission</a> - Detailed job options</li>
<li><a href="getting-started/../user-guide/time-limits.html">Time Limits</a> - Managing job timeouts</li>
<li><a href="getting-started/../user-guide/job-dependencies.html">Job Dependencies</a> - Complex workflows</li>
<li><a href="getting-started/../user-guide/gpu-management.html">GPU Management</a> - GPU allocation</li>
<li><a href="getting-started/../reference/quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
</ul>
<hr />
<p><strong>Previous</strong>: <a href="getting-started/./installation.html">Installation</a> | <strong>Next</strong>: <a href="getting-started/../user-guide/job-submission.html">Job Submission</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="job-submission"><a class="header" href="#job-submission">Job Submission</a></h1>
<p>This guide covers all aspects of submitting jobs with <code>gbatch</code>, from basic usage to advanced features.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p><code>gbatch</code> is gflow's job submission tool, similar to Slurm's <code>sbatch</code>. It supports both direct command execution and script-based job submission.</p>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<h3 id="submitting-a-command"><a class="header" href="#submitting-a-command">Submitting a Command</a></h3>
<p>The simplest way to submit a job is to provide the command directly:</p>
<pre><code class="language-bash">gbatch python script.py
</code></pre>
<p>Output:</p>
<pre><code>Submitted batch job 1 (silent-pump-6338)
</code></pre>
<p><strong>No quotes needed</strong> for simple commands! Arguments are automatically joined:</p>
<pre><code class="language-bash">gbatch python train.py --epochs 100 --lr 0.01
</code></pre>
<h3 id="submitting-a-script"><a class="header" href="#submitting-a-script">Submitting a Script</a></h3>
<p>Create a script file and submit it:</p>
<pre><code class="language-bash"># Create script
cat &gt; my_job.sh &lt;&lt; 'EOF'
#!/bin/bash
echo "Hello from gflow!"
python train.py
EOF

# Make executable
chmod +x my_job.sh

# Submit
gbatch my_job.sh
</code></pre>
<h2 id="resource-allocation"><a class="header" href="#resource-allocation">Resource Allocation</a></h2>
<h3 id="gpu-requests"><a class="header" href="#gpu-requests">GPU Requests</a></h3>
<p>Request GPUs for your job:</p>
<pre><code class="language-bash"># Request 1 GPU
gbatch --gpus 1 python train.py

# Request 2 GPUs
gbatch --gpus 2 python multi_gpu_train.py
</code></pre>
<p>The scheduler sets <code>CUDA_VISIBLE_DEVICES</code> automatically to the allocated GPUs.</p>
<p><strong>Check GPU allocation</strong>:</p>
<pre><code class="language-bash">$ gqueue -f JOBID,NAME,NODES,NODELIST
JOBID    NAME                NODES    NODELIST(REASON)
42       silent-pump-6338    1        0
43       brave-river-1234    2        1,2
</code></pre>
<h3 id="conda-environment-1"><a class="header" href="#conda-environment-1">Conda Environment</a></h3>
<p>Activate a conda environment before running your job:</p>
<pre><code class="language-bash">gbatch --conda-env myenv python script.py
</code></pre>
<p>This is equivalent to running:</p>
<pre><code class="language-bash">conda activate myenv
python script.py
</code></pre>
<h2 id="job-scheduling-options"><a class="header" href="#job-scheduling-options">Job Scheduling Options</a></h2>
<h3 id="priority"><a class="header" href="#priority">Priority</a></h3>
<p>Control when your job runs relative to others:</p>
<pre><code class="language-bash"># High priority (runs first)
gbatch --priority 100 python urgent.py

# Default priority
gbatch python normal.py  # priority = 10

# Low priority (runs last)
gbatch --priority 1 python background.py
</code></pre>
<p><strong>Priority details</strong>:</p>
<ul>
<li>Range: 0-255</li>
<li>Default: 10</li>
<li>Higher values = higher priority</li>
<li>Jobs are scheduled based on a multi-factor priority system (see below)</li>
</ul>
<p><strong>Scheduling Priority Hierarchy</strong>:</p>
<p>When resources become available, gflow schedules jobs using a three-level priority system:</p>
<ol>
<li><strong>User Priority</strong> (Primary): Jobs with higher <code>--priority</code> values run first</li>
<li><strong>Time Limit Bonus</strong> (Secondary): Among jobs with equal priority:
<ul>
<li>Time-limited jobs are preferred over unlimited jobs</li>
<li>Shorter jobs run before longer jobs</li>
</ul>
</li>
<li><strong>Submission Order</strong> (Tertiary): Jobs submitted earlier run first (FIFO)</li>
</ol>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># These jobs will run in the following order when GPUs become available:

# 1st: High priority, even though unlimited
gbatch --priority 20 python urgent.py

# 2nd: Same priority, but 10-minute limit beats unlimited
gbatch --priority 10 --time 10 python quick.py

# 3rd: Same priority, but 1-hour limit (submitted first)
gbatch --priority 10 --time 1:00:00 python train1.py  # Job ID 100

# 4th: Same priority and limit, but submitted later
gbatch --priority 10 --time 1:00:00 python train2.py  # Job ID 101

# 5th: Same priority, unlimited (submitted first)
gbatch --priority 10 python long1.py  # Job ID 102

# 6th: Same priority, unlimited (submitted later)
gbatch --priority 10 python long2.py  # Job ID 103
</code></pre>
<p><strong>Key Insights</strong>:</p>
<ul>
<li>Setting <code>--time</code> not only prevents runaway jobs but also improves scheduling priority</li>
<li>Shorter time limits get slight preference, encouraging accurate estimates</li>
<li>Submission order acts as a fair tie-breaker when all else is equal</li>
</ul>
<h3 id="time-limits"><a class="header" href="#time-limits">Time Limits</a></h3>
<p>Set maximum runtime for jobs:</p>
<pre><code class="language-bash"># 30 minutes
gbatch --time 30 python quick.py

# 2 hours
gbatch --time 2:00:00 python train.py

# 5 minutes 30 seconds
gbatch --time 5:30 python test.py
</code></pre>
<p>See <a href="user-guide/./time-limits.html">Time Limits</a> for comprehensive documentation.</p>
<h3 id="job-names"><a class="header" href="#job-names">Job Names</a></h3>
<p>By default, jobs get auto-generated names (e.g., "silent-pump-6338"). You can specify custom names:</p>
<pre><code class="language-bash">gbatch --name "my-training-run" python train.py
</code></pre>
<p><strong>Note</strong>: The <code>--name</code> option is for custom naming. If not specified, a random name is generated.</p>
<h2 id="job-dependencies-1"><a class="header" href="#job-dependencies-1">Job Dependencies</a></h2>
<p>Make jobs wait for other jobs to complete:</p>
<pre><code class="language-bash"># Job 1: Preprocessing
gbatch --name "prep" python preprocess.py
# Returns: Submitted batch job 1

# Job 2: Training (waits for job 1)
gbatch --depends-on 1 --name "train" python train.py

# Job 3: Evaluation (waits for job 2)
gbatch --depends-on 2 --name "eval" python evaluate.py
</code></pre>
<p>See <a href="user-guide/./job-dependencies.html">Job Dependencies</a> for advanced dependency management.</p>
<h2 id="job-arrays"><a class="header" href="#job-arrays">Job Arrays</a></h2>
<p>Run multiple similar tasks in parallel:</p>
<pre><code class="language-bash"># Create 10 jobs with task IDs 1-10
gbatch --array 1-10 python process.py --task '$GFLOW_ARRAY_TASK_ID'
</code></pre>
<p><strong>How it works</strong>:</p>
<ul>
<li>Creates 10 separate jobs</li>
<li>Each job has <code>$GFLOW_ARRAY_TASK_ID</code> set to its task number</li>
<li>All jobs share the same resource requirements</li>
<li>Useful for parameter sweeps, data processing, etc.</li>
</ul>
<p><strong>Example with different parameters</strong>:</p>
<pre><code class="language-bash">gbatch --array 1-5 --gpus 1 --time 2:00:00 \
       python train.py --lr '$(echo "0.001 0.01 0.1 0.5 1.0" | cut -d" " -f$GFLOW_ARRAY_TASK_ID)'
</code></pre>
<p><strong>Environment variable</strong>:</p>
<ul>
<li><code>GFLOW_ARRAY_TASK_ID</code>: Task ID for array jobs (1, 2, 3, ...)</li>
<li>Set to 0 for non-array jobs</li>
</ul>
<h2 id="script-directives"><a class="header" href="#script-directives">Script Directives</a></h2>
<p>Instead of command-line options, you can embed job requirements in your script using <code># GFLOW</code> directives:</p>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1
# GFLOW --time 2:00:00
# GFLOW --priority 20
# GFLOW --conda-env myenv

echo "Starting training..."
python train.py --epochs 100
echo "Training complete!"
</code></pre>
<p>Submit the script:</p>
<pre><code class="language-bash">gbatch my_script.sh
</code></pre>
<p><strong>Directive precedence</strong>:</p>
<ul>
<li>Command-line arguments override script directives</li>
<li>Example: <code>gbatch --time 1:00:00 my_script.sh</code> overrides the <code>--time</code> directive in the script</li>
</ul>
<p><strong>Supported directives</strong>:</p>
<ul>
<li><code># GFLOW --gpus &lt;N&gt;</code></li>
<li><code># GFLOW --time &lt;TIME&gt;</code></li>
<li><code># GFLOW --priority &lt;N&gt;</code></li>
<li><code># GFLOW --conda-env &lt;ENV&gt;</code></li>
<li><code># GFLOW --depends-on &lt;ID&gt;</code></li>
</ul>
<h2 id="creating-script-templates"><a class="header" href="#creating-script-templates">Creating Script Templates</a></h2>
<p>Use <code>gbatch new</code> to create a job script template:</p>
<pre><code class="language-bash">$ gbatch new my_job
</code></pre>
<p>This creates <code>my_job.sh</code> with a template:</p>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 0
# GFLOW --time 1:00:00
# GFLOW --priority 10

# Your commands here
echo "Job started at $(date)"

# Add your actual commands
# python script.py

echo "Job finished at $(date)"
</code></pre>
<p>Edit the template and submit:</p>
<pre><code class="language-bash"># Edit the script
vim my_job.sh

# Make executable
chmod +x my_job.sh

# Submit
gbatch my_job.sh
</code></pre>
<h2 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h2>
<p>gflow automatically sets these environment variables in your job:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>CUDA_VISIBLE_DEVICES</code></td><td>GPU IDs allocated to the job</td><td><code>0,1</code></td></tr>
<tr><td><code>GFLOW_ARRAY_TASK_ID</code></td><td>Task ID for array jobs (0 for non-array)</td><td><code>5</code></td></tr>
</tbody></table>
</div>
<p><strong>Example usage</strong>:</p>
<pre><code class="language-bash">#!/bin/bash
echo "Using GPUs: $CUDA_VISIBLE_DEVICES"
echo "Array task ID: $GFLOW_ARRAY_TASK_ID"
python train.py
</code></pre>
<h2 id="output-and-logging"><a class="header" href="#output-and-logging">Output and Logging</a></h2>
<p>Job output is automatically captured to log files:</p>
<p><strong>Log location</strong>: <code>~/.local/share/gflow/logs/&lt;job_id&gt;.log</code></p>
<p><strong>View logs</strong>:</p>
<pre><code class="language-bash"># View completed job log
cat ~/.local/share/gflow/logs/42.log

# Follow running job log
tail -f ~/.local/share/gflow/logs/42.log
</code></pre>
<p><strong>Attach to running job</strong> (via tmux):</p>
<pre><code class="language-bash"># Get job session name
gqueue -f JOBID,NAME

# Attach to session
tmux attach -t &lt;session_name&gt;

# Detach without stopping (Ctrl-B, then D)
</code></pre>
<h2 id="advanced-examples"><a class="header" href="#advanced-examples">Advanced Examples</a></h2>
<h3 id="parameter-sweep"><a class="header" href="#parameter-sweep">Parameter Sweep</a></h3>
<p>Test multiple hyperparameters:</p>
<pre><code class="language-bash"># Submit multiple training runs
for lr in 0.001 0.01 0.1; do
    gbatch --gpus 1 --time 4:00:00 \
           --name "train-lr-$lr" \
           python train.py --lr $lr
done
</code></pre>
<h3 id="pipeline-with-dependencies"><a class="header" href="#pipeline-with-dependencies">Pipeline with Dependencies</a></h3>
<pre><code class="language-bash"># Step 1: Data preprocessing
ID1=$(gbatch --time 30 python preprocess.py | grep -oP '\d+')

# Step 2: Training
ID2=$(gbatch --time 4:00:00 --gpus 1 --depends-on $ID1 \
             python train.py | grep -oP '\d+')

# Step 3: Evaluation
gbatch --time 10 --depends-on $ID2 python evaluate.py
</code></pre>
<h3 id="multi-stage-job-script"><a class="header" href="#multi-stage-job-script">Multi-stage Job Script</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1
# GFLOW --time 8:00:00

set -e  # Exit on error

echo "Stage 1: Data preparation"
python prepare_data.py

echo "Stage 2: Model training"
python train.py --checkpoint model.pth

echo "Stage 3: Evaluation"
python evaluate.py --model model.pth

echo "All stages complete!"
</code></pre>
<h3 id="conditional-job-submission"><a class="header" href="#conditional-job-submission">Conditional Job Submission</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Submit job only if previous job succeeded

PREV_JOB=42
STATUS=$(gqueue -j $PREV_JOB -f ST | tail -n 1)

if [ "$STATUS" = "CD" ]; then
    gbatch python next_step.py
else
    echo "Previous job not completed successfully"
fi
</code></pre>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="long-running-with-checkpointing"><a class="header" href="#long-running-with-checkpointing">Long-running with Checkpointing</a></h3>
<pre><code class="language-python"># train.py with checkpoint support
import signal
import sys

def save_checkpoint():
    print("Saving checkpoint...")
    # Save model state
    torch.save(model.state_dict(), 'checkpoint.pth')

def signal_handler(sig, frame):
    save_checkpoint()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

# Training loop
for epoch in range(epochs):
    train_epoch()
    if epoch % 10 == 0:
        save_checkpoint()
</code></pre>
<p>Submit with time limit:</p>
<pre><code class="language-bash">gbatch --time 8:00:00 --gpus 1 python train.py
</code></pre>
<h3 id="gpu-utilization-check"><a class="header" href="#gpu-utilization-check">GPU Utilization Check</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1

echo "Allocated GPUs: $CUDA_VISIBLE_DEVICES"
nvidia-smi --query-gpu=index,name,memory.total --format=csv
python train.py
</code></pre>
<h2 id="validation-and-error-handling"><a class="header" href="#validation-and-error-handling">Validation and Error Handling</a></h2>
<p><code>gbatch</code> validates your submission before accepting it:</p>
<p><strong>Common validation errors</strong>:</p>
<ul>
<li>
<p><strong>Invalid dependency</strong>: Job ID doesn't exist</p>
<pre><code>Error: Dependency job 999 not found
</code></pre>
</li>
<li>
<p><strong>Circular dependency</strong>: Job depends on itself or creates a cycle</p>
<pre><code>Error: Circular dependency detected
</code></pre>
</li>
<li>
<p><strong>Invalid time format</strong>: Malformed time specification</p>
<pre><code>Error: Invalid time format. Use HH:MM:SS, MM:SS, or MM
</code></pre>
</li>
<li>
<p><strong>Script not found</strong>: File doesn't exist</p>
<pre><code>Error: Script file not found: missing.sh
</code></pre>
</li>
</ul>
<h2 id="tips-and-best-practices"><a class="header" href="#tips-and-best-practices">Tips and Best Practices</a></h2>
<ol>
<li><strong>Always set time limits</strong> for production jobs to prevent runaway processes</li>
<li><strong>Use meaningful names</strong> for easier job tracking</li>
<li><strong>Test scripts locally</strong> before submitting</li>
<li><strong>Add error handling</strong> (<code>set -e</code>) in bash scripts</li>
<li><strong>Implement checkpointing</strong> for long-running jobs</li>
<li><strong>Use job arrays</strong> for parallel independent tasks</li>
<li><strong>Check dependencies</strong> before submitting dependent jobs</li>
<li><strong>Monitor GPU usage</strong> when requesting multiple GPUs</li>
<li><strong>Use conda environments</strong> for reproducibility</li>
<li><strong>Add logging</strong> to your scripts for easier debugging</li>
</ol>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="issue-job-submission-fails-with-dependency-not-found"><a class="header" href="#issue-job-submission-fails-with-dependency-not-found">Issue: Job submission fails with "dependency not found"</a></h3>
<p><strong>Solution</strong>: Verify the dependency job exists:</p>
<pre><code class="language-bash">gqueue -j &lt;dependency_id&gt;
</code></pre>
<h3 id="issue-job-doesnt-get-gpu"><a class="header" href="#issue-job-doesnt-get-gpu">Issue: Job doesn't get GPU</a></h3>
<p><strong>Check</strong>:</p>
<ol>
<li>Did you request GPU? <code>--gpus 1</code></li>
<li>Are GPUs available? <code>ginfo info</code></li>
<li>Are other jobs using all GPUs? <code>gqueue -s Running -f NODES,NODELIST</code></li>
</ol>
<h3 id="issue-conda-environment-not-activating"><a class="header" href="#issue-conda-environment-not-activating">Issue: Conda environment not activating</a></h3>
<p><strong>Check</strong>:</p>
<ol>
<li>Environment name is correct: <code>conda env list</code></li>
<li>Conda is initialized in your shell</li>
<li>Check job logs for activation errors</li>
</ol>
<h3 id="issue-script-not-executable"><a class="header" href="#issue-script-not-executable">Issue: Script not executable</a></h3>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash">chmod +x my_script.sh
gbatch my_script.sh
</code></pre>
<h2 id="reference"><a class="header" href="#reference">Reference</a></h2>
<p><strong>Full command syntax</strong>:</p>
<pre><code class="language-bash">gbatch [OPTIONS] &lt;SCRIPT&gt;
gbatch [OPTIONS] &lt;COMMAND&gt; [ARGS...]
</code></pre>
<p><strong>All options</strong>:</p>
<ul>
<li><code>--gpus &lt;N&gt;</code> or <code>-g &lt;N&gt;</code>: Number of GPUs</li>
<li><code>--time &lt;TIME&gt;</code> or <code>-t &lt;TIME&gt;</code>: Time limit</li>
<li><code>--priority &lt;N&gt;</code>: Job priority (0-255, default: 10)</li>
<li><code>--depends-on &lt;ID&gt;</code>: Job dependency</li>
<li><code>--conda-env &lt;ENV&gt;</code> or <code>-c &lt;ENV&gt;</code>: Conda environment</li>
<li><code>--array &lt;SPEC&gt;</code>: Job array (e.g., "1-10")</li>
<li><code>--name &lt;NAME&gt;</code>: Custom job name</li>
<li><code>--config &lt;PATH&gt;</code>: Custom config file (hidden)</li>
</ul>
<p><strong>Get help</strong>:</p>
<pre><code class="language-bash">$ gbatch --help
Submits jobs to the gflow scheduler. Inspired by sbatch.

Usage: gbatch [OPTIONS] &lt;SCRIPT_OR_COMMAND&gt;... [COMMAND]

Commands:
  new   Create a new job script template
  help  Print this message or the help of the given subcommand(s)

Arguments:
  &lt;SCRIPT_OR_COMMAND&gt;...  The script or command to run (e.g., "script.sh" or "python train.py --epochs 100") If a single argument that exists as a file, it's treated as a script. Otherwise, all arguments are joined as a command

Options:
  -c, --conda-env &lt;CONDA_ENV&gt;    The conda environment to use
  -g, --gpus &lt;NUMS&gt;              The GPU count to request
      --priority &lt;PRIORITY&gt;      The priority of the job
      --depends-on &lt;DEPENDS_ON&gt;  The ID of the job this job depends on
      --array &lt;ARRAY&gt;            The job array specification (e.g., "1-10")
  -t, --time &lt;TIME&gt;              Time limit for the job (formats: "HH:MM:SS", "MM:SS", "MM", or seconds as number)
  -h, --help                     Print help
  -V, --version                  Print version
</code></pre>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="user-guide/./time-limits.html">Time Limits</a> - Detailed time limit documentation</li>
<li><a href="user-guide/./job-dependencies.html">Job Dependencies</a> - Advanced dependency workflows</li>
<li><a href="user-guide/./gpu-management.html">GPU Management</a> - GPU allocation and monitoring</li>
<li><a href="user-guide/../reference/quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="job-dependencies-2"><a class="header" href="#job-dependencies-2">Job Dependencies</a></h1>
<p>This guide covers how to create complex workflows using job dependencies in gflow.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Job dependencies allow you to create workflows where jobs wait for other jobs to complete before starting. This is essential for:</p>
<ul>
<li>Multi-stage pipelines (preprocessing → training → evaluation)</li>
<li>Sequential workflows with data dependencies</li>
<li>Conditional execution based on previous results</li>
<li>Resource optimization (release GPUs between stages)</li>
</ul>
<h2 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h2>
<h3 id="simple-dependency"><a class="header" href="#simple-dependency">Simple Dependency</a></h3>
<p>Submit a job that depends on another:</p>
<pre><code class="language-bash"># Job 1: Preprocessing
$ gbatch --name "prep" python preprocess.py
Submitted batch job 1 (prep)

# Job 2: Training (waits for job 1)
$ gbatch --depends-on 1 --name "train" python train.py
Submitted batch job 2 (train)
</code></pre>
<p><strong>How it works</strong>:</p>
<ul>
<li>Job 2 starts only after Job 1 completes successfully (state: <code>Finished</code>)</li>
<li>If Job 1 fails, Job 2 remains in <code>Queued</code> state indefinitely</li>
<li>You must manually cancel Job 2 if Job 1 fails</li>
</ul>
<p><strong>Tip</strong>: You can reference recent submissions without copying IDs. Use <code>--depends-on @</code> for the most recent job or <code>--depends-on @~N</code> for the Nth submission from the end.</p>
<h3 id="checking-dependencies"><a class="header" href="#checking-dependencies">Checking Dependencies</a></h3>
<p>View dependency relationships:</p>
<pre><code class="language-bash">$ gqueue -t
JOBID    NAME      ST    TIME         TIMELIMIT
1        prep      CD    00:02:15     UNLIMITED
└─ 2     train     R     00:05:30     04:00:00
   └─ 3  eval      PD    00:00:00     00:10:00
</code></pre>
<p>The tree view (<code>-t</code>) shows the dependency hierarchy with ASCII art.</p>
<h2 id="creating-workflows"><a class="header" href="#creating-workflows">Creating Workflows</a></h2>
<h3 id="linear-pipeline"><a class="header" href="#linear-pipeline">Linear Pipeline</a></h3>
<p>Execute jobs in sequence:</p>
<pre><code class="language-bash"># Stage 1: Data collection
ID1=$(gbatch --time 10 python collect_data.py | grep -oP '\d+')

# Stage 2: Data preprocessing (depends on stage 1)
ID2=$(gbatch --time 30 --depends-on $ID1 python preprocess.py | grep -oP '\d+')

# Stage 3: Training (depends on stage 2)
ID3=$(gbatch --time 4:00:00 --gpus 1 --depends-on $ID2 python train.py | grep -oP '\d+')

# Stage 4: Evaluation (depends on stage 3)
gbatch --time 10 --depends-on $ID3 python evaluate.py
</code></pre>
<p><strong>Watch the pipeline</strong>:</p>
<pre><code class="language-bash">watch -n 5 gqueue -t
</code></pre>
<h3 id="parallel-processing-with-join"><a class="header" href="#parallel-processing-with-join">Parallel Processing with Join</a></h3>
<p>Multiple jobs feeding into one:</p>
<pre><code class="language-bash"># Parallel data processing tasks
ID1=$(gbatch --time 30 python process_part1.py | grep -oP '\d+')
ID2=$(gbatch --time 30 python process_part2.py | grep -oP '\d+')
ID3=$(gbatch --time 30 python process_part3.py | grep -oP '\d+')

# Merge results (waits for all three)
# Note: Currently gflow supports single dependency per job
# For multiple dependencies, you'll need to chain them
gbatch --depends-on $ID3 python merge_results.py
</code></pre>
<p><strong>Current limitation</strong>: gflow currently supports only one dependency per job. For multiple dependencies, create intermediate coordination jobs.</p>
<h3 id="branching-workflow"><a class="header" href="#branching-workflow">Branching Workflow</a></h3>
<p>One job triggering multiple downstream jobs:</p>
<pre><code class="language-bash"># Main processing
ID1=$(gbatch --time 1:00:00 python main_process.py | grep -oP '\d+')

# Multiple analysis jobs (all depend on ID1)
gbatch --depends-on $ID1 --time 30 python analysis_a.py
gbatch --depends-on $ID1 --time 30 python analysis_b.py
gbatch --depends-on $ID1 --time 30 python analysis_c.py
</code></pre>
<h2 id="dependency-states-and-behavior"><a class="header" href="#dependency-states-and-behavior">Dependency States and Behavior</a></h2>
<h3 id="when-dependencies-start"><a class="header" href="#when-dependencies-start">When Dependencies Start</a></h3>
<p>A job with dependencies transitions from <code>Queued</code> to <code>Running</code> when:</p>
<ol>
<li>The dependency job reaches <code>Finished</code> state</li>
<li>Required resources (GPUs, etc.) are available</li>
</ol>
<h3 id="failed-dependencies"><a class="header" href="#failed-dependencies">Failed Dependencies</a></h3>
<p>If a dependency job fails:</p>
<ul>
<li>The dependent job remains in <code>Queued</code> state</li>
<li>It will <strong>never</strong> start automatically</li>
<li>You must manually cancel it with <code>gcancel</code></li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Job 1 fails
$ gqueue
JOBID    NAME      ST    TIME
1        prep      F     00:01:23
2        train     PD    00:00:00

# Job 2 will never run - must cancel it
$ gcancel 2
</code></pre>
<h3 id="timeout-dependencies"><a class="header" href="#timeout-dependencies">Timeout Dependencies</a></h3>
<p>If a dependency job times out:</p>
<ul>
<li>State changes to <code>Timeout</code> (TO)</li>
<li>Treated the same as <code>Failed</code></li>
<li>Dependent jobs remain queued</li>
</ul>
<h3 id="cancelled-dependencies"><a class="header" href="#cancelled-dependencies">Cancelled Dependencies</a></h3>
<p>If you cancel a job with dependencies:</p>
<ul>
<li>The job is cancelled</li>
<li>Dependent jobs remain in queue (won't start)</li>
<li>Use <code>gcancel --dry-run</code> to see impact before cancelling</li>
</ul>
<p><strong>Check cancellation impact</strong>:</p>
<pre><code class="language-bash">$ gcancel --dry-run 1
Would cancel job 1 (prep)
Warning: The following jobs depend on job 1:
  - Job 2 (train)
  - Job 3 (eval)
These jobs will never start if job 1 is cancelled.
</code></pre>
<h2 id="dependency-visualization"><a class="header" href="#dependency-visualization">Dependency Visualization</a></h2>
<h3 id="tree-view"><a class="header" href="#tree-view">Tree View</a></h3>
<p>The tree view shows job dependencies clearly:</p>
<pre><code class="language-bash">$ gqueue -t
JOBID    NAME           ST    TIME         TIMELIMIT
1        data-prep      CD    00:05:23     01:00:00
├─ 2     train-model-a  R     00:15:45     04:00:00
│  └─ 4  eval-a         PD    00:00:00     00:10:00
└─ 3     train-model-b  R     00:15:50     04:00:00
   └─ 5  eval-b         PD    00:00:00     00:10:00
</code></pre>
<p><strong>Legend</strong>:</p>
<ul>
<li><code>├─</code>: Branch connection</li>
<li><code>└─</code>: Last child connection</li>
<li><code>│</code>: Continuation line</li>
</ul>
<h3 id="circular-dependency-detection"><a class="header" href="#circular-dependency-detection">Circular Dependency Detection</a></h3>
<p>gflow detects and prevents circular dependencies:</p>
<pre><code class="language-bash"># This will fail
$ gbatch --depends-on 2 python a.py
Submitted batch job 1

$ gbatch --depends-on 1 python b.py
Error: Circular dependency detected: Job 2 depends on Job 1, which depends on Job 2
</code></pre>
<p><strong>Protection</strong>:</p>
<ul>
<li>Validation happens at submission time</li>
<li>Prevents deadlocks in the job queue</li>
<li>Ensures all dependencies can eventually resolve</li>
</ul>
<h2 id="advanced-patterns"><a class="header" href="#advanced-patterns">Advanced Patterns</a></h2>
<h3 id="checkpointed-pipeline"><a class="header" href="#checkpointed-pipeline">Checkpointed Pipeline</a></h3>
<p>Resume from failure points:</p>
<pre><code class="language-bash">#!/bin/bash
# pipeline.sh - Resume from checkpoints

set -e

if [ ! -f "data.pkl" ]; then
    echo "Stage 1: Preprocessing"
    python preprocess.py
fi

if [ ! -f "model.pth" ]; then
    echo "Stage 2: Training"
    python train.py
fi

echo "Stage 3: Evaluation"
python evaluate.py
</code></pre>
<p>Submit:</p>
<pre><code class="language-bash">gbatch --gpus 1 --time 8:00:00 pipeline.sh
</code></pre>
<h3 id="conditional-dependency-script"><a class="header" href="#conditional-dependency-script">Conditional Dependency Script</a></h3>
<p>Create a script that submits jobs based on previous results:</p>
<pre><code class="language-bash">#!/bin/bash
# conditional_submit.sh

# Wait for job 1 to complete
while [ "$(gqueue -j 1 -f ST | tail -n 1)" = "R" ]; do
    sleep 5
done

# Check if it succeeded
STATUS=$(gqueue -j 1 -f ST | tail -n 1)

if [ "$STATUS" = "CD" ]; then
    echo "Job 1 succeeded, submitting next job"
    gbatch python next_step.py
else
    echo "Job 1 failed with status: $STATUS"
    exit 1
fi
</code></pre>
<h3 id="array-jobs-with-dependencies"><a class="header" href="#array-jobs-with-dependencies">Array Jobs with Dependencies</a></h3>
<p>Create job arrays that depend on a preprocessing job:</p>
<pre><code class="language-bash"># Preprocessing
ID=$(gbatch --time 30 python preprocess.py | grep -oP '\d+')

# Array of training jobs (all depend on preprocessing)
for i in {1..5}; do
    gbatch --depends-on $ID --gpus 1 --time 2:00:00 \
           python train.py --fold $i
done
</code></pre>
<h3 id="resource-efficient-pipeline"><a class="header" href="#resource-efficient-pipeline">Resource-Efficient Pipeline</a></h3>
<p>Release GPUs between stages:</p>
<pre><code class="language-bash"># Stage 1: CPU-only preprocessing
ID1=$(gbatch --time 30 python preprocess.py | grep -oP '\d+')

# Stage 2: GPU training
ID2=$(gbatch --depends-on $ID1 --gpus 2 --time 4:00:00 \
             python train.py | grep -oP '\d+')

# Stage 3: CPU-only evaluation
gbatch --depends-on $ID2 --time 10 python evaluate.py
</code></pre>
<p><strong>Benefit</strong>: GPUs are only allocated when needed, maximizing resource utilization.</p>
<h2 id="monitoring-dependencies"><a class="header" href="#monitoring-dependencies">Monitoring Dependencies</a></h2>
<h3 id="check-dependency-status"><a class="header" href="#check-dependency-status">Check Dependency Status</a></h3>
<pre><code class="language-bash"># View specific job and its dependencies
gqueue -j 1,2,3 -f JOBID,NAME,ST,TIME

# View all jobs in tree format
gqueue -t

# Filter by state and view dependencies
gqueue -s Queued,Running -t
</code></pre>
<h3 id="watch-pipeline-progress"><a class="header" href="#watch-pipeline-progress">Watch Pipeline Progress</a></h3>
<pre><code class="language-bash"># Real-time monitoring
watch -n 2 'gqueue -t'

# Show only active jobs
watch -n 2 'gqueue -s Running,Queued -t'
</code></pre>
<h3 id="identify-blocked-jobs"><a class="header" href="#identify-blocked-jobs">Identify Blocked Jobs</a></h3>
<p>Find jobs waiting on dependencies:</p>
<pre><code class="language-bash"># Show queued jobs with dependency info
gqueue -s Queued -t

# Check why a job is queued
gqueue -j 5 -f JOBID,NAME,ST
gqueue -t | grep -A5 "^5"
</code></pre>
<h2 id="dependency-validation"><a class="header" href="#dependency-validation">Dependency Validation</a></h2>
<h3 id="submission-time-validation"><a class="header" href="#submission-time-validation">Submission-time Validation</a></h3>
<p><code>gbatch</code> validates dependencies when you submit:</p>
<p>✅ <strong>Valid submissions</strong>:</p>
<ul>
<li>Dependency job exists</li>
<li>No circular dependencies</li>
<li>Dependency is not the job itself</li>
</ul>
<p>❌ <strong>Invalid submissions</strong>:</p>
<ul>
<li>Dependency job doesn't exist: <code>Error: Dependency job 999 not found</code></li>
<li>Circular dependency: <code>Error: Circular dependency detected</code></li>
<li>Self-dependency: <code>Error: Job cannot depend on itself</code></li>
</ul>
<h3 id="runtime-behavior"><a class="header" href="#runtime-behavior">Runtime Behavior</a></h3>
<p>During execution:</p>
<ul>
<li>Scheduler checks dependencies every 5 seconds</li>
<li>Jobs start when dependencies are <code>Finished</code> AND resources are available</li>
<li>Failed/timeout dependencies never trigger dependent jobs</li>
</ul>
<h2 id="practical-examples"><a class="header" href="#practical-examples">Practical Examples</a></h2>
<h3 id="example-1-ml-training-pipeline"><a class="header" href="#example-1-ml-training-pipeline">Example 1: ML Training Pipeline</a></h3>
<pre><code class="language-bash"># Complete ML pipeline
PREP=$(gbatch --time 20 python prepare_dataset.py | grep -oP '\d+')

TRAIN=$(gbatch --depends-on $PREP --gpus 1 --time 8:00:00 \
               python train.py --output model.pth | grep -oP '\d+')

EVAL=$(gbatch --depends-on $TRAIN --time 15 \
              python evaluate.py --model model.pth | grep -oP '\d+')

gbatch --depends-on $EVAL --time 5 \
       python generate_report.py
</code></pre>
<h3 id="example-2-data-processing-pipeline"><a class="header" href="#example-2-data-processing-pipeline">Example 2: Data Processing Pipeline</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Submit a data processing pipeline

echo "Submitting data processing pipeline..."

# Download data
ID1=$(gbatch --time 1:00:00 --name "download" \
             python download_data.py | grep -oP '\d+')

# Validate data
ID2=$(gbatch --depends-on $ID1 --time 30 --name "validate" \
             python validate_data.py | grep -oP '\d+')

# Transform data
ID3=$(gbatch --depends-on $ID2 --time 45 --name "transform" \
             python transform_data.py | grep -oP '\d+')

# Upload results
gbatch --depends-on $ID3 --time 30 --name "upload" \
       python upload_results.py

echo "Pipeline submitted. Monitor with: watch gqueue -t"
</code></pre>
<h3 id="example-3-hyperparameter-sweep-with-evaluation"><a class="header" href="#example-3-hyperparameter-sweep-with-evaluation">Example 3: Hyperparameter Sweep with Evaluation</a></h3>
<pre><code class="language-bash"># Train multiple models
MODELS=()
for lr in 0.001 0.01 0.1; do
    ID=$(gbatch --gpus 1 --time 2:00:00 \
                python train.py --lr $lr --output model_$lr.pth | grep -oP '\d+')
    MODELS+=($ID)
done

# Wait for all models, then evaluate
# (Create a dummy job that depends on the last model)
LAST_MODEL=${MODELS[-1]}
gbatch --depends-on $LAST_MODEL --time 30 \
       python compare_models.py --models model_*.pth
</code></pre>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="issue-dependent-job-not-starting"><a class="header" href="#issue-dependent-job-not-starting">Issue: Dependent job not starting</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>
<p>Dependency job hasn't finished:</p>
<pre><code class="language-bash">gqueue -t
</code></pre>
</li>
<li>
<p>Dependency job failed:</p>
<pre><code class="language-bash">gqueue -j &lt;dep_id&gt; -f JOBID,ST
</code></pre>
</li>
<li>
<p>No resources available (GPUs):</p>
<pre><code class="language-bash">ginfo info
gqueue -s Running -f NODES,NODELIST
</code></pre>
</li>
</ol>
<h3 id="issue-want-to-cancel-a-job-with-dependencies"><a class="header" href="#issue-want-to-cancel-a-job-with-dependencies">Issue: Want to cancel a job with dependencies</a></h3>
<p><strong>Solution</strong>: Use dry-run first to see impact:</p>
<pre><code class="language-bash"># See what would happen
gcancel --dry-run &lt;job_id&gt;

# Cancel if acceptable
gcancel &lt;job_id&gt;

# Cancel dependent jobs too if needed
gcancel &lt;job_id&gt;
gcancel &lt;dependent_job_id&gt;
</code></pre>
<h3 id="issue-circular-dependency-error"><a class="header" href="#issue-circular-dependency-error">Issue: Circular dependency error</a></h3>
<p><strong>Solution</strong>: Review your dependency chain:</p>
<pre><code class="language-bash"># Check the job sequence
gqueue -j &lt;job_ids&gt; -t

# Restructure to eliminate cycles
</code></pre>
<h3 id="issue-lost-track-of-dependencies"><a class="header" href="#issue-lost-track-of-dependencies">Issue: Lost track of dependencies</a></h3>
<p><strong>Solution</strong>: Use tree view:</p>
<pre><code class="language-bash"># Show all job relationships
gqueue -a -t

# Focus on specific jobs
gqueue -j 1,2,3,4,5 -t
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li><strong>Plan workflows</strong> before submitting jobs</li>
<li><strong>Use meaningful names</strong> for jobs in pipelines</li>
<li><strong>Extract job IDs</strong> for reliable dependency tracking</li>
<li><strong>Set appropriate time limits</strong> for each stage</li>
<li><strong>Monitor pipelines</strong> with <code>watch gqueue -t</code></li>
<li><strong>Handle failures</strong> by checking dependency status</li>
<li><strong>Use dry-run</strong> before cancelling jobs with dependents</li>
<li><strong>Document pipelines</strong> in submission scripts</li>
<li><strong>Test small</strong> before submitting long pipelines</li>
<li><strong>Check logs</strong> when dependencies fail</li>
</ol>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<p><strong>Current limitations</strong>:</p>
<ul>
<li>Only one dependency per job (no multi-parent dependencies)</li>
<li>No automatic cancellation of dependents when parent fails</li>
<li>No dependency on specific job states (e.g., "start when job X fails")</li>
<li>No job groups or batch dependencies</li>
</ul>
<p><strong>Workarounds</strong>:</p>
<ul>
<li>For multiple dependencies, use intermediate coordination jobs</li>
<li>Monitor job status and submit conditionally with scripts</li>
<li>Use external workflow managers for complex DAGs if needed</li>
</ul>
<h2 id="see-also-1"><a class="header" href="#see-also-1">See Also</a></h2>
<ul>
<li><a href="user-guide/./job-submission.html">Job Submission</a> - Complete job submission guide</li>
<li><a href="user-guide/./time-limits.html">Time Limits</a> - Managing job timeouts</li>
<li><a href="user-guide/../reference/quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
<li><a href="user-guide/../getting-started/quick-start.html">Quick Start</a> - Basic usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gpu-management"><a class="header" href="#gpu-management">GPU Management</a></h1>
<p>This guide covers how gflow manages GPU resources, from detection to allocation and monitoring.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>gflow provides automatic GPU detection, allocation, and management for NVIDIA GPUs through the NVML library. It ensures efficient GPU utilization across multiple jobs while preventing resource conflicts.</p>
<h2 id="gpu-detection"><a class="header" href="#gpu-detection">GPU Detection</a></h2>
<h3 id="checking-available-gpus"><a class="header" href="#checking-available-gpus">Checking Available GPUs</a></h3>
<p>View system GPU information:</p>
<pre><code class="language-bash">$ ginfo info
</code></pre>
<p><strong>Information displayed</strong>:</p>
<ul>
<li>Total number of GPUs in the system</li>
<li>Number of currently available (unused) GPUs</li>
<li>GPU model and UUID for each device</li>
<li>Current allocation status (available or in use by which job)</li>
</ul>
<h3 id="requirements"><a class="header" href="#requirements">Requirements</a></h3>
<p><strong>System requirements</strong>:</p>
<ul>
<li>NVIDIA GPU(s)</li>
<li>NVIDIA drivers installed</li>
<li>NVML library available (<code>libnvidia-ml.so</code>)</li>
</ul>
<p><strong>Verify GPU setup</strong>:</p>
<pre><code class="language-bash"># Check NVIDIA driver
nvidia-smi

# Check NVML library
ldconfig -p | grep libnvidia-ml

# Test GPU detection with gflow
gflowd up
ginfo info
</code></pre>
<h3 id="no-gpu-systems"><a class="header" href="#no-gpu-systems">No GPU Systems</a></h3>
<p>gflow works perfectly fine on systems without GPUs:</p>
<ul>
<li>GPU detection fails gracefully</li>
<li>All features work except GPU allocation</li>
<li>Jobs can still be submitted without <code>--gpus</code> flag</li>
</ul>
<h2 id="gpu-allocation"><a class="header" href="#gpu-allocation">GPU Allocation</a></h2>
<h3 id="requesting-gpus"><a class="header" href="#requesting-gpus">Requesting GPUs</a></h3>
<p>Request GPUs when submitting jobs:</p>
<pre><code class="language-bash"># Request 1 GPU
gbatch --gpus 1 python train.py

# Request 2 GPUs
gbatch --gpus 2 python multi_gpu_train.py

# Request 4 GPUs
gbatch --gpus 4 python distributed_train.py
</code></pre>
<h3 id="automatic-gpu-assignment"><a class="header" href="#automatic-gpu-assignment">Automatic GPU Assignment</a></h3>
<p>When a job requests GPUs:</p>
<ol>
<li>Scheduler checks for available GPUs</li>
<li>Assigns specific GPU IDs to the job</li>
<li>Sets <code>CUDA_VISIBLE_DEVICES</code> environment variable</li>
<li>Job sees only its allocated GPUs (numbered 0, 1, 2, ...)</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Submit job requesting 2 GPUs
$ gbatch --gpus 2 nvidia-smi

# Check allocation
$ gqueue -f JOBID,NAME,NODES,NODELIST
JOBID    NAME                NODES    NODELIST(REASON)
42       brave-river-1234    2        1,2

# Inside the job, CUDA_VISIBLE_DEVICES=1,2
# But CUDA will renumber them as 0,1 for the application
</code></pre>
<h3 id="gpu-visibility"><a class="header" href="#gpu-visibility">GPU Visibility</a></h3>
<p>gflow uses <code>CUDA_VISIBLE_DEVICES</code> to control GPU access:</p>
<pre><code class="language-python"># In your job (Python example)
import os
import torch

# gflow sets this automatically
print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")

# CUDA sees only allocated GPUs
print(f"Visible GPUs to CUDA: {torch.cuda.device_count()}")

# Use GPUs normally (indexed from 0)
device = torch.device('cuda:0')  # First allocated GPU
</code></pre>
<p><strong>Bash example</strong>:</p>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 2

echo "Allocated GPUs: $CUDA_VISIBLE_DEVICES"
nvidia-smi --query-gpu=index,name,memory.free --format=csv
python train.py
</code></pre>
<h2 id="gpu-scheduling"><a class="header" href="#gpu-scheduling">GPU Scheduling</a></h2>
<h3 id="job-queue-with-gpu-requests"><a class="header" href="#job-queue-with-gpu-requests">Job Queue with GPU Requests</a></h3>
<p>Jobs wait for GPUs when none are available:</p>
<pre><code class="language-bash"># System has 2 GPUs

# Job 1: Uses 2 GPUs
$ gbatch --gpus 2 python long_train.py
Submitted batch job 1

# Job 2: Requests 1 GPU (must wait)
$ gbatch --gpus 1 python train.py
Submitted batch job 2

$ gqueue
JOBID    NAME      ST    NODES    NODELIST(REASON)
1        job-1     R     2        0,1
2        job-2     PD    1        (Resources)
</code></pre>
<p>Job 2 waits until Job 1 releases at least 1 GPU.</p>
<h3 id="priority-and-gpu-allocation"><a class="header" href="#priority-and-gpu-allocation">Priority and GPU Allocation</a></h3>
<p>Higher priority jobs get GPUs first:</p>
<pre><code class="language-bash"># Low priority job
gbatch --priority 5 --gpus 1 python task1.py

# High priority job
gbatch --priority 100 --gpus 1 python urgent_task.py
</code></pre>
<p>When GPUs become available:</p>
<ol>
<li>Scheduler selects highest priority queued job</li>
<li>Checks if enough GPUs are free</li>
<li>Allocates GPUs and starts the job</li>
</ol>
<h3 id="partial-gpu-availability"><a class="header" href="#partial-gpu-availability">Partial GPU Availability</a></h3>
<p>If a job requests more GPUs than currently available, it waits:</p>
<pre><code class="language-bash"># System has 4 GPUs, 3 in use

# This waits for 4 GPUs
gbatch --gpus 4 python distributed_train.py

$ gqueue
JOBID    NAME      ST    NODES    NODELIST(REASON)
5        job-5     PD    4        (Resources: Need 4 GPUs, only 1 available)
</code></pre>
<h2 id="monitoring-gpu-usage"><a class="header" href="#monitoring-gpu-usage">Monitoring GPU Usage</a></h2>
<h3 id="check-current-gpu-allocation"><a class="header" href="#check-current-gpu-allocation">Check Current GPU Allocation</a></h3>
<pre><code class="language-bash"># View GPU allocation for running jobs
$ gqueue -s Running -f JOBID,NAME,NODES,NODELIST
JOBID    NAME                NODES    NODELIST(REASON)
1        train-resnet        1        0
2        train-vit           1        1
3        train-bert          2        2,3
</code></pre>
<h3 id="system-wide-gpu-status"><a class="header" href="#system-wide-gpu-status">System-wide GPU Status</a></h3>
<pre><code class="language-bash"># View system info
$ ginfo info

# Use nvidia-smi for real-time monitoring
watch -n 1 nvidia-smi
</code></pre>
<h3 id="per-job-gpu-usage"><a class="header" href="#per-job-gpu-usage">Per-job GPU Usage</a></h3>
<pre><code class="language-bash"># Submit job with GPU monitoring
cat &gt; monitor_gpu.sh &lt;&lt; 'EOF'
#!/bin/bash
# GFLOW --gpus 1

echo "=== GPU Allocation ==="
echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"

echo "=== GPU Details ==="
nvidia-smi --query-gpu=index,name,memory.total,memory.free,utilization.gpu \
           --format=csv

echo "=== Training ==="
python train.py
EOF

chmod +x monitor_gpu.sh
gbatch monitor_gpu.sh
</code></pre>
<p>Check the log:</p>
<pre><code class="language-bash">cat ~/.local/share/gflow/logs/&lt;job_id&gt;.log
</code></pre>
<h2 id="multi-gpu-training"><a class="header" href="#multi-gpu-training">Multi-GPU Training</a></h2>
<h3 id="data-parallel-training-pytorch"><a class="header" href="#data-parallel-training-pytorch">Data Parallel Training (PyTorch)</a></h3>
<pre><code class="language-python"># train.py
import torch
import torch.nn as nn

# gflow sets CUDA_VISIBLE_DEVICES automatically
device_count = torch.cuda.device_count()
print(f"Using {device_count} GPUs")

model = MyModel()
if device_count &gt; 1:
    model = nn.DataParallel(model)
model = model.cuda()

# Train normally
train(model)
</code></pre>
<p>Submit with multiple GPUs:</p>
<pre><code class="language-bash">gbatch --gpus 2 python train.py
</code></pre>
<h3 id="distributed-training-pytorch"><a class="header" href="#distributed-training-pytorch">Distributed Training (PyTorch)</a></h3>
<pre><code class="language-python"># distributed_train.py
import torch
import torch.distributed as dist

def main():
    # gflow allocates GPUs via CUDA_VISIBLE_DEVICES
    world_size = torch.cuda.device_count()

    # Initialize process group
    dist.init_process_group(backend='nccl', world_size=world_size)

    # Get local rank
    local_rank = dist.get_rank()
    torch.cuda.set_device(local_rank)

    # Training code
    train(local_rank)

if __name__ == '__main__':
    main()
</code></pre>
<p>Submit:</p>
<pre><code class="language-bash">gbatch --gpus 4 python distributed_train.py
</code></pre>
<h3 id="tensorflow-multi-gpu"><a class="header" href="#tensorflow-multi-gpu">TensorFlow Multi-GPU</a></h3>
<pre><code class="language-python"># tf_train.py
import tensorflow as tf

# Let TensorFlow see all allocated GPUs
gpus = tf.config.list_physical_devices('GPU')
print(f"Available GPUs: {len(gpus)}")

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = create_model()
    model.compile(...)

model.fit(...)
</code></pre>
<p>Submit:</p>
<pre><code class="language-bash">gbatch --gpus 2 python tf_train.py
</code></pre>
<h2 id="advanced-gpu-management"><a class="header" href="#advanced-gpu-management">Advanced GPU Management</a></h2>
<h3 id="gpu-memory-considerations"><a class="header" href="#gpu-memory-considerations">GPU Memory Considerations</a></h3>
<p>Even if GPUs are "available", they might have insufficient memory:</p>
<pre><code class="language-bash"># Check GPU memory before submitting large jobs
nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits

# Example: Job needs 20GB per GPU
gbatch --gpus 1 python memory_intensive_train.py
</code></pre>
<p><strong>Note</strong>: gflow tracks GPU allocation, not memory usage. Plan accordingly.</p>
<h3 id="exclusive-gpu-access"><a class="header" href="#exclusive-gpu-access">Exclusive GPU Access</a></h3>
<p>Each job gets exclusive access to its allocated GPUs:</p>
<ul>
<li>No other gflow job can use them</li>
<li>Other processes (outside gflow) can still access them</li>
<li>Use <code>CUDA_VISIBLE_DEVICES</code> to ensure isolation</li>
</ul>
<h3 id="mixed-gpucpu-jobs"><a class="header" href="#mixed-gpucpu-jobs">Mixed GPU/CPU Jobs</a></h3>
<p>Run CPU and GPU jobs simultaneously:</p>
<pre><code class="language-bash"># CPU-only job
gbatch python cpu_task.py

# GPU job
gbatch --gpus 1 python gpu_task.py
</code></pre>
<p>CPU jobs don't consume GPU slots and can run in parallel with GPU jobs.</p>
<h2 id="gpu-job-patterns"><a class="header" href="#gpu-job-patterns">GPU Job Patterns</a></h2>
<h3 id="sequential-gpu-pipeline"><a class="header" href="#sequential-gpu-pipeline">Sequential GPU Pipeline</a></h3>
<p>Release GPUs between stages:</p>
<pre><code class="language-bash"># Stage 1: Preprocessing (no GPU)
ID1=$(gbatch --time 30 python preprocess.py | grep -oP '\d+')

# Stage 2: Training (uses GPU)
ID2=$(gbatch --depends-on $ID1 --gpus 1 --time 4:00:00 \
             python train.py | grep -oP '\d+')

# Stage 3: Evaluation (no GPU)
gbatch --depends-on $ID2 --time 10 python evaluate.py
</code></pre>
<p><strong>Benefit</strong>: GPU is free during preprocessing and evaluation.</p>
<h3 id="parallel-multi-gpu-experiments"><a class="header" href="#parallel-multi-gpu-experiments">Parallel Multi-GPU Experiments</a></h3>
<p>Run experiments in parallel on different GPUs:</p>
<pre><code class="language-bash"># Each gets one GPU
gbatch --gpus 1 --time 2:00:00 --config config1.yaml --name "exp1" python train.py
gbatch --gpus 1 --time 2:00:00 --config config2.yaml --name "exp2" python train.py
gbatch --gpus 1 --time 2:00:00 --config config3.yaml --name "exp3" python train.py
</code></pre>
<p>If you have 4 GPUs, the first 4 jobs run in parallel.</p>
<h3 id="dynamic-gpu-scaling"><a class="header" href="#dynamic-gpu-scaling">Dynamic GPU Scaling</a></h3>
<p>Start with fewer GPUs, scale up later:</p>
<pre><code class="language-bash"># Initial experiment (1 GPU)
gbatch --gpus 1 --time 1:00:00 python train.py --test-run

# Full training (4 GPUs) - submit after validation
gbatch --gpus 4 --time 8:00:00 python train.py --full
</code></pre>
<h3 id="hyperparameter-sweep-with-gpus"><a class="header" href="#hyperparameter-sweep-with-gpus">Hyperparameter Sweep with GPUs</a></h3>
<pre><code class="language-bash"># Grid search across 4 GPUs
for lr in 0.001 0.01 0.1; do
    for batch_size in 32 64 128; do
        gbatch --gpus 1 --time 3:00:00 \
               --name "lr${lr}_bs${batch_size}" \
               python train.py --lr $lr --batch-size $batch_size
    done
done

# Monitor GPU allocation
watch -n 2 'gqueue -s Running,Queued -f JOBID,NAME,NODES,NODELIST'
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="issue-job-not-getting-gpu"><a class="header" href="#issue-job-not-getting-gpu">Issue: Job not getting GPU</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>
<p><strong>Forgot to request GPU</strong>:</p>
<pre><code class="language-bash"># Wrong - no GPU requested
gbatch python train.py

# Correct
gbatch --gpus 1 python train.py
</code></pre>
</li>
<li>
<p><strong>All GPUs in use</strong>:</p>
<pre><code class="language-bash"># Check allocation
gqueue -s Running -f NODES,NODELIST
ginfo info
</code></pre>
</li>
<li>
<p><strong>Job is queued</strong>:</p>
<pre><code class="language-bash"># Job waits for GPU
$ gqueue -j &lt;job_id&gt; -f JOBID,ST,NODES,NODELIST
JOBID    ST    NODES    NODELIST(REASON)
42       PD    1        (Resources)
</code></pre>
</li>
</ol>
<h3 id="issue-job-sees-wrong-gpus"><a class="header" href="#issue-job-sees-wrong-gpus">Issue: Job sees wrong GPUs</a></h3>
<p><strong>Check CUDA_VISIBLE_DEVICES</strong>:</p>
<pre><code class="language-bash"># In your job script
echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"

# Should match gqueue output
gqueue -f JOBID,NODELIST
</code></pre>
<h3 id="issue-out-of-memory-error"><a class="header" href="#issue-out-of-memory-error">Issue: Out of memory error</a></h3>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Request more GPUs: <code>--gpus 2</code></li>
<li>Reduce batch size in your code</li>
<li>Use gradient accumulation</li>
<li>Enable mixed precision training (FP16)</li>
</ol>
<p><strong>Check memory</strong>:</p>
<pre><code class="language-bash">nvidia-smi --query-gpu=memory.free,memory.used --format=csv
</code></pre>
<h3 id="issue-gpu-utilization-low"><a class="header" href="#issue-gpu-utilization-low">Issue: GPU utilization low</a></h3>
<p><strong>Possible causes</strong>:</p>
<ul>
<li>Data loading bottleneck (use more workers)</li>
<li>CPU preprocessing bottleneck</li>
<li>Small batch size</li>
<li>Model too small for GPU</li>
</ul>
<p><strong>Debug</strong>:</p>
<pre><code class="language-bash"># Monitor GPU utilization
watch -n 1 nvidia-smi

# Check job logs for bottlenecks
tail -f ~/.local/share/gflow/logs/&lt;job_id&gt;.log
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Request only needed GPUs</strong>: Don't over-allocate resources</li>
<li><strong>Monitor GPU usage</strong>: Use <code>nvidia-smi</code> to verify utilization</li>
<li><strong>Optimize data loading</strong>: Prevent GPU starvation</li>
<li><strong>Use mixed precision</strong>: Reduce memory usage with FP16</li>
<li><strong>Batch jobs efficiently</strong>: Group similar GPU requirements</li>
<li><strong>Release GPUs early</strong>: Use dependencies to chain CPU/GPU stages</li>
<li><strong>Test on 1 GPU first</strong>: Validate before scaling to multiple GPUs</li>
<li><strong>Set time limits</strong>: Prevent GPU hogging by runaway jobs</li>
<li><strong>Log GPU stats</strong>: Include GPU info in job logs</li>
<li><strong>Clean up checkpoints</strong>: Manage disk space when using GPUs</li>
</ol>
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h2>
<h3 id="maximize-gpu-utilization"><a class="header" href="#maximize-gpu-utilization">Maximize GPU Utilization</a></h3>
<pre><code class="language-python"># Increase batch size
train_loader = DataLoader(dataset, batch_size=128, num_workers=8)

# Use pin_memory for faster transfers
train_loader = DataLoader(dataset, batch_size=128, pin_memory=True)

# Enable AMP for mixed precision
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

with autocast():
    output = model(input)
    loss = criterion(output, target)
</code></pre>
<h3 id="efficient-multi-gpu-usage"><a class="header" href="#efficient-multi-gpu-usage">Efficient Multi-GPU Usage</a></h3>
<pre><code class="language-python"># Use DistributedDataParallel instead of DataParallel
from torch.nn.parallel import DistributedDataParallel as DDP

# More efficient communication
model = DDP(model, device_ids=[local_rank])
</code></pre>
<h3 id="monitor-and-optimize"><a class="header" href="#monitor-and-optimize">Monitor and Optimize</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1

# Log GPU stats before training
nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv -l 10 &gt; gpu_stats.log &amp;
GPU_MONITOR_PID=$!

# Run training
python train.py

# Stop monitoring
kill $GPU_MONITOR_PID
</code></pre>
<h2 id="reference-1"><a class="header" href="#reference-1">Reference</a></h2>
<h3 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Set By</th><th>Description</th></tr></thead><tbody>
<tr><td><code>CUDA_VISIBLE_DEVICES</code></td><td>gflow</td><td>Comma-separated GPU IDs (e.g., "0,1")</td></tr>
</tbody></table>
</div>
<h3 id="gpu-related-commands"><a class="header" href="#gpu-related-commands">GPU-Related Commands</a></h3>
<pre><code class="language-bash"># Check system GPUs
ginfo info

# Submit job with GPUs
gbatch --gpus &lt;N&gt; ...

# Check GPU allocation
gqueue -f JOBID,NODES,NODELIST

# Monitor running GPU jobs
gqueue -s Running -f JOBID,NODES,NODELIST

# Monitor system GPUs
nvidia-smi
watch -n 1 nvidia-smi
</code></pre>
<h2 id="see-also-2"><a class="header" href="#see-also-2">See Also</a></h2>
<ul>
<li><a href="user-guide/./job-submission.html">Job Submission</a> - Complete job submission guide</li>
<li><a href="user-guide/./job-dependencies.html">Job Dependencies</a> - Workflow management</li>
<li><a href="user-guide/./time-limits.html">Time Limits</a> - Job timeout management</li>
<li><a href="user-guide/../reference/quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="job-time-limits-in-gflow"><a class="header" href="#job-time-limits-in-gflow">Job Time Limits in gflow</a></h1>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>gflow supports setting time limits for jobs, similar to Slurm's <code>sbatch --time</code> parameter. When a job exceeds its specified time limit, the scheduler automatically terminates it and marks it with a <code>Timeout</code> status. This feature helps prevent runaway jobs from consuming resources indefinitely and facilitates better resource planning.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="user-guide/time-limits.html#basic-usage">Basic Usage</a></li>
<li><a href="user-guide/time-limits.html#time-format-specifications">Time Format Specifications</a></li>
<li><a href="user-guide/time-limits.html#behavior-and-enforcement">Behavior and Enforcement</a></li>
<li><a href="user-guide/time-limits.html#job-states">Job States</a></li>
<li><a href="user-guide/time-limits.html#examples">Examples</a></li>
<li><a href="user-guide/time-limits.html#best-practices">Best Practices</a></li>
<li><a href="user-guide/time-limits.html#faq">FAQ</a></li>
</ul>
<h2 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h2>
<h3 id="setting-time-limits-with-gbatch"><a class="header" href="#setting-time-limits-with-gbatch">Setting Time Limits with <code>gbatch</code></a></h3>
<p>Use the <code>--time</code> (or <code>-t</code>) flag when submitting jobs:</p>
<pre><code class="language-bash">gbatch --time &lt;TIME_SPEC&gt; your_command
</code></pre>
<h3 id="in-job-scripts"><a class="header" href="#in-job-scripts">In Job Scripts</a></h3>
<p>You can also specify time limits directly in your job scripts using the <code># GFLOW</code> directive:</p>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --time 2:00:00
# GFLOW --gpus 1

echo "Starting training..."
python train.py
</code></pre>
<p>Note: Command-line arguments take precedence over script directives.</p>
<h2 id="time-format-specifications"><a class="header" href="#time-format-specifications">Time Format Specifications</a></h2>
<p>gflow supports multiple time format specifications for flexibility:</p>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Description</th><th>Example</th><th>Equivalent Duration</th></tr></thead><tbody>
<tr><td><code>HH:MM:SS</code></td><td>Hours:Minutes:Seconds</td><td><code>2:30:45</code></td><td>2 hours, 30 minutes, 45 seconds</td></tr>
<tr><td><code>MM:SS</code></td><td>Minutes:Seconds</td><td><code>45:30</code></td><td>45 minutes, 30 seconds</td></tr>
<tr><td><code>MM</code></td><td>Minutes only</td><td><code>30</code></td><td>30 minutes</td></tr>
</tbody></table>
</div>
<h3 id="format-details"><a class="header" href="#format-details">Format Details</a></h3>
<h4 id="hhmmss-format"><a class="header" href="#hhmmss-format"><code>HH:MM:SS</code> Format</a></h4>
<ul>
<li><strong>Use case</strong>: Long-running jobs (hours)</li>
<li><strong>Example</strong>: <code>--time 1:30:00</code> (1.5 hours)</li>
<li><strong>Range</strong>: Any valid combination of hours, minutes, and seconds</li>
</ul>
<h4 id="mmss-format"><a class="header" href="#mmss-format"><code>MM:SS</code> Format</a></h4>
<ul>
<li><strong>Use case</strong>: Medium-duration jobs (minutes)</li>
<li><strong>Example</strong>: <code>--time 45:30</code> (45 minutes, 30 seconds)</li>
<li><strong>Note</strong>: Two numbers separated by colon are interpreted as minutes:seconds</li>
</ul>
<h4 id="mm-format"><a class="header" href="#mm-format"><code>MM</code> Format</a></h4>
<ul>
<li><strong>Use case</strong>: Short jobs (minutes)</li>
<li><strong>Example</strong>: <code>--time 10</code> (10 minutes)</li>
<li><strong>Note</strong>: A single number is always interpreted as minutes, not seconds</li>
</ul>
<h3 id="examples-by-format"><a class="header" href="#examples-by-format">Examples by Format</a></h3>
<pre><code class="language-bash"># 2 hours
gbatch --time 2:00:00 long_simulation

# 30 minutes
gbatch --time 30 medium_task

# 5 minutes 30 seconds
gbatch --time 5:30 quick_task

# 12 hours 45 minutes
gbatch --time 12:45:00 overnight_job
</code></pre>
<h2 id="scheduling-benefits"><a class="header" href="#scheduling-benefits">Scheduling Benefits</a></h2>
<h3 id="time-limits-improve-scheduling-priority"><a class="header" href="#time-limits-improve-scheduling-priority">Time Limits Improve Scheduling Priority</a></h3>
<p>When multiple jobs are queued with the same priority level, gflow uses a multi-factor scheduling algorithm:</p>
<ol>
<li><strong>User Priority</strong> (Primary factor)</li>
<li><strong>Time Limit Bonus</strong> (Secondary factor)</li>
<li><strong>Submission Order</strong> (Tie-breaker)</li>
</ol>
<p><strong>How the Time Bonus Works</strong>:</p>
<ul>
<li><strong>Unlimited jobs</strong>: Receive lowest scheduling bonus</li>
<li><strong>Time-limited jobs</strong>: Receive higher scheduling bonus</li>
<li><strong>Shorter jobs</strong>: Receive even higher bonus within time-limited jobs</li>
</ul>
<p>This means setting a time limit provides two benefits:</p>
<ul>
<li>✅ <strong>Safety</strong>: Prevents runaway jobs from consuming resources indefinitely</li>
<li>✅ <strong>Priority</strong>: Your job runs sooner when competing with unlimited jobs</li>
</ul>
<p><strong>Example Scheduling Order</strong>:</p>
<pre><code class="language-bash"># Assume all jobs have priority=10 and are submitted in this order:

gbatch --priority 10 --time 10 quick.py        # Runs 1st (shortest)
gbatch --priority 10 --time 1:00:00 medium.py  # Runs 2nd (medium)
gbatch --priority 10 --time 8:00:00 long.py    # Runs 3rd (long limit)
gbatch --priority 10 unlimited.py              # Runs 4th (no limit)
</code></pre>
<p><strong>Key Insight</strong>: Even a very generous time limit (e.g., 24 hours) gives your job an advantage over unlimited jobs at the same priority level. Setting realistic time limits is a win-win!</p>
<h3 id="scheduling-priority-details"><a class="header" href="#scheduling-priority-details">Scheduling Priority Details</a></h3>
<p>The time bonus uses the following formula:</p>
<ul>
<li>No time limit: Bonus = 100</li>
<li>With time limit: Bonus = 200-300 (based on duration)
<ul>
<li>Very short jobs (seconds-minutes): ~300</li>
<li>Medium jobs (hours): ~250</li>
<li>Long jobs (≥24 hours): ~200</li>
</ul>
</li>
</ul>
<p>User priority is multiplied by 1000, so it always dominates the scheduling decision. Time bonuses only matter when jobs have equal priority.</p>
<h2 id="behavior-and-enforcement"><a class="header" href="#behavior-and-enforcement">Behavior and Enforcement</a></h2>
<h3 id="how-time-limits-work"><a class="header" href="#how-time-limits-work">How Time Limits Work</a></h3>
<ol>
<li>
<p><strong>Job Submission</strong>: When you submit a job with <code>--time</code>, the time limit is stored with the job metadata.</p>
</li>
<li>
<p><strong>Execution Start</strong>: When the job starts running, the scheduler records the start time.</p>
</li>
<li>
<p><strong>Monitoring</strong>: The scheduler checks all running jobs every 5 seconds for timeout violations.</p>
</li>
<li>
<p><strong>Timeout Detection</strong>: If a job's elapsed time exceeds its time limit, the scheduler:</p>
<ul>
<li>Logs a warning: <code>Job &lt;id&gt; has exceeded time limit, terminating...</code></li>
<li>Sends <code>Ctrl-C</code> to the job's tmux session (graceful interrupt)</li>
<li>Transitions the job to <code>Timeout</code> state</li>
<li>Records the finish time</li>
</ul>
</li>
<li>
<p><strong>Post-Termination</strong>: The job's output is preserved in the log file, and the session is cleaned up.</p>
</li>
</ol>
<h3 id="graceful-vs-forceful-termination"><a class="header" href="#graceful-vs-forceful-termination">Graceful vs Forceful Termination</a></h3>
<ul>
<li>
<p><strong>Graceful Termination</strong>: gflow sends <code>Ctrl-C</code> (SIGINT) first, giving jobs a chance to:</p>
<ul>
<li>Save checkpoints</li>
<li>Close file handles</li>
<li>Clean up temporary files</li>
<li>Log final states</li>
</ul>
</li>
<li>
<p><strong>Forceful Cleanup</strong>: If the tmux session doesn't respond, it will be killed when the job is fully cancelled or the daemon is stopped.</p>
</li>
</ul>
<h3 id="accuracy-and-timing"><a class="header" href="#accuracy-and-timing">Accuracy and Timing</a></h3>
<ul>
<li><strong>Check Interval</strong>: 5 seconds (jobs may run up to 5 seconds past their limit)</li>
<li><strong>Tolerance</strong>: Jobs are terminated as soon as the next check detects the timeout</li>
<li><strong>Precision</strong>: Sub-second timing is recorded, but enforcement happens at 5-second intervals</li>
</ul>
<h2 id="job-states"><a class="header" href="#job-states">Job States</a></h2>
<h3 id="timeout-state-to"><a class="header" href="#timeout-state-to">Timeout State (<code>TO</code>)</a></h3>
<p>When a job exceeds its time limit, it transitions to the <code>Timeout</code> state:</p>
<pre><code class="language-bash">$ gqueue -j 42
JOBID    NAME             ST    TIME         TIMELIMIT
42       my-long-job      TO    00:10:05     00:10:00
</code></pre>
<p>Key characteristics:</p>
<ul>
<li><strong>State Code</strong>: <code>TO</code> (Timeout)</li>
<li><strong>Terminal State</strong>: Job will not restart or continue</li>
<li><strong>Distinguishable</strong>: Different from <code>F</code> (Failed) and <code>CA</code> (Cancelled)</li>
<li><strong>Logged</strong>: Timeout event is recorded in daemon logs</li>
</ul>
<h3 id="state-transitions"><a class="header" href="#state-transitions">State Transitions</a></h3>
<pre><code>Queued ──→ Running ──→ Finished
            │
            ├──→ Failed
            ├──→ Cancelled
            └──→ Timeout (new)
</code></pre>
<p>Valid transitions to <code>Timeout</code>:</p>
<ul>
<li>✅ <code>Running</code> → <code>Timeout</code> (time limit exceeded)</li>
<li>❌ <code>Queued</code> → <code>Timeout</code> (not possible)</li>
<li>❌ <code>Finished</code> → <code>Timeout</code> (terminal state)</li>
</ul>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="example-1-training-job-with-time-limit"><a class="header" href="#example-1-training-job-with-time-limit">Example 1: Training Job with Time Limit</a></h3>
<pre><code class="language-bash"># Submit a training job with 2-hour limit
gbatch --time 2:00:00 \
       --gpus 1 \
       python train.py --epochs 100
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Submitted batch job 42 (elegant-mountain-1234)
</code></pre>
<p><strong>Check status</strong>:</p>
<pre><code class="language-bash">$ gqueue -j 42 -f JOBID,NAME,ST,TIME,TIMELIMIT
JOBID    NAME                   ST    TIME         TIMELIMIT
42       elegant-mountain-1234  R     00:15:23     02:00:00
</code></pre>
<h3 id="example-2-job-that-times-out"><a class="header" href="#example-2-job-that-times-out">Example 2: Job that Times Out</a></h3>
<pre><code class="language-bash"># Submit a job that will exceed its limit
gbatch --time 0:10 \
       sleep 1000  # Will run for 1000 seconds
</code></pre>
<p><strong>After 10 seconds</strong>:</p>
<pre><code class="language-bash">$ gqueue -j 43 -f JOBID,NAME,ST,TIME,TIMELIMIT
JOBID    NAME                ST    TIME         TIMELIMIT
43       quiet-river-5678    TO    00:00:13     00:00:10
</code></pre>
<p><strong>Log output</strong> (<code>~/.local/share/gflow/logs/43.log</code>):</p>
<pre><code>Line 1
Line 2
...
^C
</code></pre>
<h3 id="example-3-job-array-with-time-limits"><a class="header" href="#example-3-job-array-with-time-limits">Example 3: Job Array with Time Limits</a></h3>
<pre><code class="language-bash"># Submit array of jobs, each with 30-minute limit
gbatch --time 30 \
       --array 1-10 \
       python process.py --task \$GFLOW_ARRAY_TASK_ID
</code></pre>
<p>Each job in the array inherits the same 30-minute time limit.</p>
<h3 id="example-4-dependency-chain-with-time-limits"><a class="header" href="#example-4-dependency-chain-with-time-limits">Example 4: Dependency Chain with Time Limits</a></h3>
<pre><code class="language-bash"># Job 1: Data preprocessing (1 hour)
gbatch --time 1:00:00 \
       --name "preprocess" \
       python preprocess.py


# Job 2: Training (4 hours), depends on Job 1
gbatch --time 4:00:00 \
       --depends-on 1 \
       --name "training" \
       python train.py

# Job 3: Evaluation (30 minutes), depends on Job 2
gbatch --time 30 \
       --depends-on 2 \
       --name "evaluation" \
       python evaluate.py \
</code></pre>
<h3 id="example-5-job-script-with-time-limit"><a class="header" href="#example-5-job-script-with-time-limit">Example 5: Job Script with Time Limit</a></h3>
<p>Create <code>experiment.sh</code>:</p>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --time 3:00:00
# GFLOW --gpus 2
# GFLOW --priority 20

echo "Starting experiment at $(date)"
python run_experiment.py --config config.yaml
echo "Experiment finished at $(date)"
</code></pre>
<p>Submit:</p>
<pre><code class="language-bash">gbatch experiment.sh
</code></pre>
<p>Override time limit from command line:</p>
<pre><code class="language-bash"># This overrides the script's 3-hour limit
gbatch --time 1:00:00 experiment.sh
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="1-set-realistic-time-limits"><a class="header" href="#1-set-realistic-time-limits">1. Set Realistic Time Limits</a></h3>
<ul>
<li><strong>Estimate Runtime</strong>: Add 10-20% buffer to your expected runtime</li>
<li><strong>Account for Variability</strong>: Consider dataset size, hardware performance</li>
<li><strong>Too Short</strong>: Jobs terminate prematurely, wasting computation</li>
<li><strong>Too Long</strong>: Doesn't help catch runaway jobs</li>
</ul>
<pre><code class="language-bash"># Bad: Too tight
gbatch --time 10 python train.py  # Training takes ~12 minutes

# Good: Reasonable buffer
gbatch --time 15 python train.py  # Allows 25% buffer
</code></pre>
<h3 id="2-use-time-limits-for-all-production-jobs"><a class="header" href="#2-use-time-limits-for-all-production-jobs">2. Use Time Limits for All Production Jobs</a></h3>
<pre><code class="language-bash"># Bad: No limit, could run forever
gbatch python train.py

# Good: Always specify limits
gbatch --time 4:00:00 python train.py
</code></pre>
<h3 id="3-implement-checkpointing"><a class="header" href="#3-implement-checkpointing">3. Implement Checkpointing</a></h3>
<p>Time limits work best with checkpointing:</p>
<pre><code class="language-python"># Your training script
import signal
import sys

def signal_handler(sig, frame):
    print('Received interrupt, saving checkpoint...')
    model.save_checkpoint('checkpoint.pth')
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

# Training loop
for epoch in range(epochs):
    train_epoch()
    if epoch % 10 == 0:
        model.save_checkpoint(f'checkpoint_epoch_{epoch}.pth')
</code></pre>
<h3 id="4-monitor-time-usage"><a class="header" href="#4-monitor-time-usage">4. Monitor Time Usage</a></h3>
<p>Use <code>gqueue</code> to monitor job progress:</p>
<pre><code class="language-bash"># Watch jobs with time limits
watch -n 5 'gqueue -s Running -f JOBID,NAME,ST,TIME,TIMELIMIT'
</code></pre>
<h3 id="5-adjust-limits-based-on-history"><a class="header" href="#5-adjust-limits-based-on-history">5. Adjust Limits Based on History</a></h3>
<p>After running jobs, analyze their runtime:</p>
<pre><code class="language-bash"># Check completed job runtime
gqueue -j 42 -f JOBID,TIME,TIMELIMIT

# Adjust future jobs based on actual runtime
</code></pre>
<h3 id="6-different-limits-for-different-stages"><a class="header" href="#6-different-limits-for-different-stages">6. Different Limits for Different Stages</a></h3>
<pre><code class="language-bash"># Quick preprocessing
gbatch --time 10 --name "preprocess" python preprocess.py

# Long training
gbatch --time 8:00:00 --depends-on &lt;prep_id&gt; --name "training" python train.py

# Quick evaluation
gbatch --time 5 --name "evaluation" --depends-on &lt;train_id&gt; python evaluate.py
</code></pre>
<h2 id="displaying-time-limits"><a class="header" href="#displaying-time-limits">Displaying Time Limits</a></h2>
<h3 id="using-gqueue"><a class="header" href="#using-gqueue">Using <code>gqueue</code></a></h3>
<p>Show time limit column:</p>
<pre><code class="language-bash"># Include TIMELIMIT in output
gqueue -f JOBID,NAME,ST,TIME,TIMELIMIT
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>JOBID    NAME                ST    TIME         TIMELIMIT
42       training-job        R     01:23:45     04:00:00
43       quick-task          CD    00:02:15     00:10:00
44       unlimited-job       R     00:45:12     UNLIMITED
</code></pre>
<h3 id="time-display-formats"><a class="header" href="#time-display-formats">Time Display Formats</a></h3>
<ul>
<li><strong>With Days</strong>: <code>D-HH:MM:SS</code> (e.g., <code>2-04:30:00</code> = 2 days, 4.5 hours)</li>
<li><strong>Without Days</strong>: <code>HH:MM:SS</code> (e.g., <code>04:30:00</code> = 4.5 hours)</li>
<li><strong>Unlimited</strong>: <code>UNLIMITED</code> (no time limit set)</li>
</ul>
<h3 id="filtering-by-state"><a class="header" href="#filtering-by-state">Filtering by State</a></h3>
<p>View all timed-out jobs:</p>
<pre><code class="language-bash">gqueue -s Timeout -f JOBID,NAME,TIME,TIMELIMIT
</code></pre>
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="q-what-happens-if-i-dont-specify-a-time-limit"><a class="header" href="#q-what-happens-if-i-dont-specify-a-time-limit">Q: What happens if I don't specify a time limit?</a></h3>
<p><strong>A</strong>: The job runs without any time restrictions (<code>UNLIMITED</code>). It will run until:</p>
<ul>
<li>It completes successfully</li>
<li>It fails due to an error</li>
<li>You manually cancel it with <code>gcancel</code></li>
<li>The system crashes or daemon stops</li>
</ul>
<h3 id="q-can-i-change-a-jobs-time-limit-after-submission"><a class="header" href="#q-can-i-change-a-jobs-time-limit-after-submission">Q: Can I change a job's time limit after submission?</a></h3>
<p><strong>A</strong>: Currently, no. Time limits are set at submission time and cannot be modified for queued or running jobs. You would need to:</p>
<ol>
<li>Cancel the current job</li>
<li>Resubmit with a new time limit</li>
</ol>
<h3 id="q-whats-the-maximum-time-limit"><a class="header" href="#q-whats-the-maximum-time-limit">Q: What's the maximum time limit?</a></h3>
<p><strong>A</strong>: There's no hard maximum, but practical limits depend on:</p>
<ul>
<li>System stability (days/weeks)</li>
<li>Resource availability</li>
<li>Your specific use case</li>
</ul>
<p>Example of a very long limit:</p>
<pre><code class="language-bash">gbatch --time 168:00:00 week_long_simulation # 1 week
</code></pre>
<h3 id="q-will-my-job-save-its-work-when-it-times-out"><a class="header" href="#q-will-my-job-save-its-work-when-it-times-out">Q: Will my job save its work when it times out?</a></h3>
<p><strong>A</strong>: It depends on your job's implementation:</p>
<ul>
<li><strong>With SIGINT handler</strong>: Yes, if you catch <code>Ctrl-C</code> and save state</li>
<li><strong>Without handler</strong>: Possibly not, job is interrupted immediately</li>
<li><strong>Best practice</strong>: Implement periodic checkpointing</li>
</ul>
<h3 id="q-how-do-i-see-why-a-job-timed-out"><a class="header" href="#q-how-do-i-see-why-a-job-timed-out">Q: How do I see why a job timed out?</a></h3>
<p><strong>A</strong>: Check multiple sources:</p>
<ol>
<li>
<p><strong>Job status</strong>:</p>
<pre><code class="language-bash">gqueue -j &lt;job_id&gt;
</code></pre>
</li>
<li>
<p><strong>Job logs</strong>:</p>
<pre><code class="language-bash">cat ~/.local/share/gflow/logs/&lt;job_id&gt;.log
</code></pre>
</li>
<li>
<p><strong>Daemon logs</strong> (if attached to tmux):</p>
<pre><code class="language-bash">tmux attach -t gflow_server
</code></pre>
</li>
</ol>
<h3 id="q-can-i-set-different-time-limits-for-job-arrays"><a class="header" href="#q-can-i-set-different-time-limits-for-job-arrays">Q: Can I set different time limits for job arrays?</a></h3>
<p><strong>A</strong>: Currently, all jobs in an array share the same time limit. To have different limits:</p>
<ul>
<li>Submit jobs individually, or</li>
<li>Implement conditional logic in your script based on <code>$GFLOW_ARRAY_TASK_ID</code></li>
</ul>
<h3 id="q-whats-the-difference-between-timeout-to-and-failed-f"><a class="header" href="#q-whats-the-difference-between-timeout-to-and-failed-f">Q: What's the difference between Timeout (TO) and Failed (F)?</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Timeout (TO)</th><th>Failed (F)</th></tr></thead><tbody>
<tr><td><strong>Cause</strong></td><td>Exceeded time limit</td><td>Job crashed/error</td></tr>
<tr><td><strong>Initiated by</strong></td><td>Scheduler</td><td>Job itself</td></tr>
<tr><td><strong>Exit code</strong></td><td>SIGINT (130)</td><td>Variable (job-dependent)</td></tr>
<tr><td><strong>Planned</strong></td><td>Yes (hit limit)</td><td>No (unexpected)</td></tr>
</tbody></table>
</div>
<h3 id="q-does-the-time-limit-include-queue-time"><a class="header" href="#q-does-the-time-limit-include-queue-time">Q: Does the time limit include queue time?</a></h3>
<p><strong>A</strong>: No, only running time counts. The timer starts when the job transitions from <code>Queued</code> to <code>Running</code> state.</p>
<pre><code>Queued (not counted) → Running (timer starts) → Timeout/Finished
</code></pre>
<h3 id="q-how-accurate-is-the-timeout-enforcement"><a class="header" href="#q-how-accurate-is-the-timeout-enforcement">Q: How accurate is the timeout enforcement?</a></h3>
<p><strong>A</strong>: Within 5 seconds. The scheduler checks every 5 seconds, so:</p>
<ul>
<li><strong>Limit</strong>: 10:00</li>
<li><strong>Actual termination</strong>: Between 10:00 and 10:05</li>
</ul>
<p>For most use cases, this accuracy is sufficient.</p>
<h3 id="q-what-if-the-daemon-restarts-while-jobs-are-running"><a class="header" href="#q-what-if-the-daemon-restarts-while-jobs-are-running">Q: What if the daemon restarts while jobs are running?</a></h3>
<p><strong>A</strong>: Time limits are preserved:</p>
<ol>
<li>Job state (including start time) is saved to disk</li>
<li>When daemon restarts, it reloads job state</li>
<li>Time limit checking resumes automatically</li>
<li>Jobs that exceeded limits during downtime will be caught on next check</li>
</ol>
<h3 id="q-can-i-see-time-remaining-for-a-running-job"><a class="header" href="#q-can-i-see-time-remaining-for-a-running-job">Q: Can I see time remaining for a running job?</a></h3>
<p><strong>A</strong>: Not directly, but you can calculate it:</p>
<pre><code class="language-bash"># Show TIME and TIMELIMIT columns
gqueue -j &lt;job_id&gt; -f JOBID,NAME,TIME,TIMELIMIT

# Calculate: TIMELIMIT - TIME = Remaining time
</code></pre>
<p>A future enhancement could add a <code>REMAINING</code> column.</p>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="job-terminates-earlier-than-expected"><a class="header" href="#job-terminates-earlier-than-expected">Job Terminates Earlier Than Expected</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>
<p><strong>Wrong time format</strong>:</p>
<ul>
<li>❌ <code>--time 30</code> thinking it's seconds (it's actually 30 minutes)</li>
<li>✅ <code>--time 0:30</code> for 30 seconds</li>
</ul>
</li>
<li>
<p><strong>Time limit too strict</strong>: Check actual runtime of previous jobs</p>
</li>
<li>
<p><strong>Job failed for other reasons</strong>: Check logs and job state</p>
</li>
</ol>
<h3 id="job-doesnt-terminate-at-time-limit"><a class="header" href="#job-doesnt-terminate-at-time-limit">Job Doesn't Terminate at Time Limit</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li><strong>No time limit set</strong>: Verify with <code>gqueue -f TIMELIMIT</code></li>
<li><strong>Daemon not running</strong>: Check <code>ginfo info</code></li>
<li><strong>Job not in Running state</strong>: Time limits only apply to running jobs</li>
</ol>
<h3 id="time-limit-not-showing-in-gqueue"><a class="header" href="#time-limit-not-showing-in-gqueue">Time Limit Not Showing in <code>gqueue</code></a></h3>
<pre><code class="language-bash"># Make sure to include TIMELIMIT in format
gqueue -f JOBID,NAME,ST,TIME,TIMELIMIT

# Or check default columns for your gflow version
</code></pre>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h2>
<p>For developers and advanced users:</p>
<h3 id="architecture"><a class="header" href="#architecture">Architecture</a></h3>
<ul>
<li><strong>Storage</strong>: <code>time_limit</code> field in <code>Job</code> struct as <code>Option&lt;Duration&gt;</code></li>
<li><strong>Checking</strong>: Scheduler loop every 5 seconds</li>
<li><strong>Method</strong>: <code>Job::has_exceeded_time_limit()</code> compares elapsed vs limit</li>
<li><strong>Termination</strong>: <code>send_ctrl_c()</code> → transition to <code>Timeout</code> state</li>
</ul>
<h3 id="state-persistence"><a class="header" href="#state-persistence">State Persistence</a></h3>
<p>Time limits are persisted in <code>~/.local/share/gflow/state.json</code>:</p>
<pre><code class="language-json">{
  "id": 42,
  "time_limit": {
    "secs": 3600,
    "nanos": 0
  },
  "started_at": {
    "secs_since_epoch": 1234567890,
    "nanos_since_epoch": 0
  }
}
</code></pre>
<h3 id="scheduler-code"><a class="header" href="#scheduler-code">Scheduler Code</a></h3>
<p>Located in <code>src/bin/gflowd/scheduler.rs:242-267</code>, the timeout checking logic runs every scheduler cycle.</p>
<h2 id="related-features"><a class="header" href="#related-features">Related Features</a></h2>
<ul>
<li><strong>Job Dependencies</strong>: Combine with <code>--depends-on</code> for complex workflows</li>
<li><strong>Job Priorities</strong>: Use with <code>--priority</code> for important time-sensitive jobs</li>
<li><strong>Job Arrays</strong>: Apply time limits to parallel task batches</li>
<li><strong>Output Logging</strong>: All output captured via <code>pipe-pane</code> to log files</li>
</ul>
<h2 id="see-also-3"><a class="header" href="#see-also-3">See Also</a></h2>
<ul>
<li><a href="user-guide/../README.html">README.md</a> - Main documentation</li>
<li><a href="user-guide/./DEPENDENCIES.html">Job Dependencies</a> - Managing job dependencies</li>
<li><a href="user-guide/./GPU_SCHEDULING.html">GPU Scheduling</a> - GPU resource management</li>
<li>GitHub Issues - Report problems or request features</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration"><a class="header" href="#configuration">Configuration</a></h1>
<p>This guide covers how to configure gflow for your environment.</p>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<p>gflow uses a simple configuration system based on TOML files and environment variables. Most users can use gflow without any configuration, but customization options are available for specific needs.</p>
<h2 id="configuration-files-1"><a class="header" href="#configuration-files-1">Configuration Files</a></h2>
<h3 id="default-configuration-location"><a class="header" href="#default-configuration-location">Default Configuration Location</a></h3>
<pre><code>~/.config/gflow/gflow.toml
</code></pre>
<p>This file is created automatically when you first run gflow commands. If it doesn't exist, gflow uses built-in defaults.</p>
<h3 id="configuration-file-structure"><a class="header" href="#configuration-file-structure">Configuration File Structure</a></h3>
<pre><code class="language-toml">[daemon]
# Daemon connection settings
host = "localhost"
port = 59000

# Optional: Specify GPU indices to use (commented out = use all)
# gpus = [0, 1, 2]

# Optional: Log level (error, warn, info, debug, trace)
# log_level = "info"
</code></pre>
<h3 id="custom-configuration-location"><a class="header" href="#custom-configuration-location">Custom Configuration Location</a></h3>
<p>Use the <code>--config</code> flag (available on all commands, but hidden from help):</p>
<pre><code class="language-bash"># Use custom config file
gflowd --config /path/to/custom.toml up
gflowd --config /path/to/custom.toml status
ginfo --config /path/to/custom.toml info
gflowd --config /path/to/custom.toml down
gbatch --config /path/to/custom.toml ...
gqueue --config /path/to/custom.toml
</code></pre>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="daemon-configuration"><a class="header" href="#daemon-configuration">Daemon Configuration</a></h3>
<h4 id="host-and-port"><a class="header" href="#host-and-port">Host and Port</a></h4>
<p>Control where the daemon listens:</p>
<pre><code class="language-toml">[daemon]
host = "localhost"  # Listen address
port = 59000        # Listen port
</code></pre>
<p><strong>Default values</strong>:</p>
<ul>
<li>Host: <code>localhost</code> (127.0.0.1)</li>
<li>Port: <code>59000</code></li>
</ul>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Default is fine for single-machine use</li>
<li>Change port if 59000 is already in use</li>
<li>Use <code>0.0.0.0</code> to allow remote connections (⚠️ not recommended for security)</li>
</ul>
<h4 id="gpu-selection"><a class="header" href="#gpu-selection">GPU Selection</a></h4>
<p>Limit which GPUs gflow can use:</p>
<pre><code class="language-toml">[daemon]
# Use only GPUs 0 and 2
gpus = [0, 2]
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Reserve specific GPUs for other applications</li>
<li>Test with subset of GPUs</li>
<li>Isolate gflow from other workloads</li>
</ul>
<p><strong>Default</strong>: All detected GPUs are available</p>
<h4 id="logging-level"><a class="header" href="#logging-level">Logging Level</a></h4>
<p>Control daemon verbosity:</p>
<pre><code class="language-toml">[daemon]
log_level = "info"  # error | warn | info | debug | trace
</code></pre>
<p><strong>Levels</strong>:</p>
<ul>
<li><code>error</code>: Only critical errors</li>
<li><code>warn</code>: Warnings and errors</li>
<li><code>info</code>: General information (default)</li>
<li><code>debug</code>: Detailed debugging info</li>
<li><code>trace</code>: Very verbose (includes all internal operations)</li>
</ul>
<h2 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h2>
<h3 id="configuration-via-environment"><a class="header" href="#configuration-via-environment">Configuration via Environment</a></h3>
<p>gflow supports environment variable configuration with the <code>GFLOW_</code> prefix:</p>
<pre><code class="language-bash"># Set daemon host
export GFLOW_DAEMON_HOST="localhost"

# Set daemon port
export GFLOW_DAEMON_PORT="59000"

# Set log level
export GFLOW_LOG_LEVEL="debug"

# Start daemon with these settings
gflowd up
</code></pre>
<p><strong>Precedence</strong>:</p>
<ol>
<li>Command-line arguments (if available)</li>
<li>Configuration file (<code>--config</code> or default)</li>
<li>Environment variables</li>
<li>Built-in defaults</li>
</ol>
<h3 id="setting-cuda-devices-system-wide"><a class="header" href="#setting-cuda-devices-system-wide">Setting CUDA Devices System-wide</a></h3>
<p>To limit CUDA devices before gflow:</p>
<pre><code class="language-bash"># Make only GPU 0 visible to gflow
export CUDA_VISIBLE_DEVICES=0
gflowd up

# gflow will only see and manage GPU 0
ginfo info
</code></pre>
<p><strong>Warning</strong>: This affects all CUDA applications, not just gflow.</p>
<h2 id="file-locations"><a class="header" href="#file-locations">File Locations</a></h2>
<h3 id="standard-directories"><a class="header" href="#standard-directories">Standard Directories</a></h3>
<p>gflow uses XDG Base Directory specification:</p>
<pre><code class="language-bash"># Configuration
~/.config/gflow/
  └── gflow.toml          # Main configuration file

# Data (state and logs)
~/.local/share/gflow/
  ├── state.json           # Persistent job state
  └── logs/                # Job output logs
      ├── 1.log
      ├── 2.log
      └── ...

# Runtime (optional, not used by default)
~/.local/share/gflow/
</code></pre>
<h3 id="customizing-directories"><a class="header" href="#customizing-directories">Customizing Directories</a></h3>
<p>While not officially supported, you can use environment variables:</p>
<pre><code class="language-bash"># Custom config directory
export XDG_CONFIG_HOME="$HOME/my-config"
# Config will be at: $HOME/my-config/gflow/gflow.toml

# Custom data directory
export XDG_DATA_HOME="$HOME/my-data"
# State will be at: $HOME/my-data/gflow/state.json
# Logs will be at: $HOME/my-data/gflow/logs/
</code></pre>
<h2 id="configuration-management"><a class="header" href="#configuration-management">Configuration Management</a></h2>
<h3 id="view-current-configuration"><a class="header" href="#view-current-configuration">View Current Configuration</a></h3>
<pre><code class="language-bash"># View scheduler info (includes host and port)
ginfo info

# The config file itself
cat ~/.config/gflow/gflow.toml
</code></pre>
<h3 id="reset-configuration"><a class="header" href="#reset-configuration">Reset Configuration</a></h3>
<p>Remove configuration to use defaults:</p>
<pre><code class="language-bash"># Stop daemon first
gflowd down

# Remove config file
rm ~/.config/gflow/gflow.toml

# Restart daemon (uses defaults)
gflowd up
</code></pre>
<h3 id="configuration-cleanup"><a class="header" href="#configuration-cleanup">Configuration Cleanup</a></h3>
<p>Use the cleanup option (undocumented feature):</p>
<pre><code class="language-bash">gflowd --cleanup
</code></pre>
<p>This removes the configuration file and resets to defaults.</p>
<h2 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h2>
<h3 id="multiple-gflow-instances"><a class="header" href="#multiple-gflow-instances">Multiple gflow Instances</a></h3>
<p>Run multiple independent gflow instances with different configs:</p>
<p><strong>Instance 1</strong> (default):</p>
<pre><code class="language-toml"># ~/.config/gflow/gflow.toml
[daemon]
port = 59000
</code></pre>
<pre><code class="language-bash">gflowd up
</code></pre>
<p><strong>Instance 2</strong> (custom):</p>
<pre><code class="language-toml"># ~/gflow-dev/config.toml
[daemon]
port = 59001
</code></pre>
<pre><code class="language-bash">gflowd --config ~/gflow-dev/config.toml up
ginfo --config ~/gflow-dev/config.toml info
gbatch --config ~/gflow-dev/config.toml ...
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Testing new features without affecting production</li>
<li>Separate job queues for different projects</li>
<li>Different GPU allocations for different teams</li>
</ul>
<h3 id="per-project-configuration"><a class="header" href="#per-project-configuration">Per-Project Configuration</a></h3>
<p>Create a project-specific config:</p>
<pre><code class="language-bash"># Project directory
cd my-ml-project/

# Create local config
cat &gt; gflow.toml &lt;&lt; 'EOF'
[daemon]
host = "localhost"
port = 59001
gpus = [0, 1]  # Use only first 2 GPUs for this project
EOF

# Use with --config
gbatch --config ./gflow.toml --gpus 1 python train.py
</code></pre>
<p><strong>Tip</strong>: Add to <code>.gitignore</code>:</p>
<pre><code class="language-bash">echo "gflow.toml" &gt;&gt; .gitignore
</code></pre>
<h3 id="gpu-partitioning"><a class="header" href="#gpu-partitioning">GPU Partitioning</a></h3>
<p>Divide GPUs among users or projects:</p>
<p><strong>User A</strong> (GPUs 0-1):</p>
<pre><code class="language-toml"># ~/.config/gflow/gflow-userA.toml
[daemon]
port = 59000
gpus = [0, 1]
</code></pre>
<p><strong>User B</strong> (GPUs 2-3):</p>
<pre><code class="language-toml"># ~/.config/gflow/gflow-userB.toml
[daemon]
port = 59001
gpus = [2, 3]
</code></pre>
<p>Each user runs their own daemon instance.</p>
<h2 id="daemon-control"><a class="header" href="#daemon-control">Daemon Control</a></h2>
<h3 id="starting-the-daemon"><a class="header" href="#starting-the-daemon">Starting the Daemon</a></h3>
<pre><code class="language-bash"># Default config (creates/uses tmux session)
gflowd up

# Custom config
gflowd --config /path/to/config.toml up

# With verbosity
gflowd -vv up   # debug level
gflowd -vvv up  # trace level
</code></pre>
<p><code>gflowd up</code> detaches immediately after launching the daemon inside the <code>gflow_server</code> tmux session.</p>
<h3 id="stopping-the-daemon"><a class="header" href="#stopping-the-daemon">Stopping the Daemon</a></h3>
<pre><code class="language-bash">gflowd down
</code></pre>
<p>This politely stops the daemon, saves state, and removes the <code>gflow_server</code> session. If the tmux session is missing, <code>gflowd down</code> reports the failure but otherwise exits cleanly.</p>
<h3 id="checking-status"><a class="header" href="#checking-status">Checking Status</a></h3>
<pre><code class="language-bash">gflowd status
</code></pre>
<p><code>gflowd status</code> checks for the tmux session and performs a health probe against the HTTP API. Use <code>ginfo info</code> to inspect detailed resources:</p>
<pre><code class="language-bash">$ ginfo info
</code></pre>
<p><code>ginfo</code> prints scheduler metadata, GPU availability, and which jobs currently occupy each device.</p>
<h3 id="daemon-persistence"><a class="header" href="#daemon-persistence">Daemon Persistence</a></h3>
<p>The daemon runs in a tmux session:</p>
<pre><code class="language-bash"># Attach to daemon session
tmux attach -t gflow_server

# Detach without stopping (Ctrl-B, then D)

# View daemon logs
tmux attach -t gflow_server
# Then scroll up (Ctrl-B, then [)
</code></pre>
<h2 id="state-persistence-1"><a class="header" href="#state-persistence-1">State Persistence</a></h2>
<h3 id="job-state"><a class="header" href="#job-state">Job State</a></h3>
<p>Job state is automatically persisted to disk:</p>
<pre><code class="language-bash">~/.local/share/gflow/state.json
</code></pre>
<p><strong>When state is saved</strong>:</p>
<ul>
<li>When jobs are submitted</li>
<li>When job states change</li>
<li>Periodically during daemon operation</li>
<li>When daemon shuts down</li>
</ul>
<p><strong>State recovery</strong>:</p>
<ul>
<li>Daemon reads state on startup</li>
<li>Jobs resume from their previous state</li>
<li>Running jobs are marked as failed (tmux sessions stopped)</li>
</ul>
<h3 id="manual-state-management"><a class="header" href="#manual-state-management">Manual State Management</a></h3>
<p><strong>Backup state</strong>:</p>
<pre><code class="language-bash">cp ~/.local/share/gflow/state.json ~/.local/share/gflow/state.json.backup
</code></pre>
<p><strong>Clear all job history</strong>:</p>
<pre><code class="language-bash"># Stop daemon first!
gflowd down

# Remove state file
rm ~/.local/share/gflow/state.json

# Restart (fresh state)
gflowd up
</code></pre>
<p><strong>Restore state</strong>:</p>
<pre><code class="language-bash">gflowd down
cp state.json.backup ~/.local/share/gflow/state.json
gflowd up
</code></pre>
<h2 id="logging"><a class="header" href="#logging">Logging</a></h2>
<h3 id="job-logs"><a class="header" href="#job-logs">Job Logs</a></h3>
<p>Automatic log capture to files:</p>
<pre><code class="language-bash">~/.local/share/gflow/logs/&lt;job_id&gt;.log
</code></pre>
<p><strong>Features</strong>:</p>
<ul>
<li>Automatic directory creation</li>
<li>Real-time log writing via <code>tmux pipe-pane</code></li>
<li>Logs persist after job completion</li>
<li>No size limits (manage manually if needed)</li>
</ul>
<p><strong>Managing logs</strong>:</p>
<pre><code class="language-bash"># View recent logs
ls -lt ~/.local/share/gflow/logs/ | head -10

# Clean old logs
find ~/.local/share/gflow/logs/ -name "*.log" -mtime +30 -delete

# Archive logs
tar -czf logs-$(date +%Y%m%d).tar.gz ~/.local/share/gflow/logs/
</code></pre>
<h3 id="daemon-logs"><a class="header" href="#daemon-logs">Daemon Logs</a></h3>
<p>Daemon logs appear in its tmux session:</p>
<pre><code class="language-bash"># View daemon logs
tmux attach -t gflow_server

# Capture daemon logs to file
tmux capture-pane -t gflow_server -p &gt; daemon.log
</code></pre>
<h2 id="troubleshooting-configuration"><a class="header" href="#troubleshooting-configuration">Troubleshooting Configuration</a></h2>
<h3 id="issue-config-file-not-found"><a class="header" href="#issue-config-file-not-found">Issue: Config file not found</a></h3>
<p><strong>Check location</strong>:</p>
<pre><code class="language-bash">ls -la ~/.config/gflow/gflow.toml
</code></pre>
<p><strong>Solution</strong>: Create default config or specify with <code>--config</code></p>
<h3 id="issue-port-already-in-use"><a class="header" href="#issue-port-already-in-use">Issue: Port already in use</a></h3>
<p><strong>Check port</strong>:</p>
<pre><code class="language-bash">lsof -i :59000
</code></pre>
<p><strong>Solutions</strong>:</p>
<ol>
<li>
<p>Change port in config:</p>
<pre><code class="language-toml">[daemon]
port = 59001
</code></pre>
</li>
<li>
<p>Kill process using the port:</p>
<pre><code class="language-bash">kill &lt;PID&gt;
</code></pre>
</li>
</ol>
<h3 id="issue-gpus-not-detected"><a class="header" href="#issue-gpus-not-detected">Issue: GPUs not detected</a></h3>
<p><strong>Check config</strong>:</p>
<pre><code class="language-toml">[daemon]
# Make sure you don't have invalid GPU indices
# gpus = [0, 1, 2, 3]  # Comment out to use all
</code></pre>
<p><strong>Verify GPUs</strong>:</p>
<pre><code class="language-bash">nvidia-smi
ginfo info
</code></pre>
<h3 id="issue-cant-connect-to-daemon"><a class="header" href="#issue-cant-connect-to-daemon">Issue: Can't connect to daemon</a></h3>
<p><strong>Check</strong>:</p>
<ol>
<li>Daemon running: <code>gflowd status</code></li>
<li>Correct host/port in config</li>
<li>Firewall settings (if using custom host)</li>
</ol>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Restart daemon
gflowd down
gflowd up

# Check connection
ginfo info
</code></pre>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security Considerations</a></h2>
<h3 id="local-only-access"><a class="header" href="#local-only-access">Local-only Access</a></h3>
<p>By default, gflow only accepts local connections:</p>
<pre><code class="language-toml">[daemon]
host = "localhost"  # Only local access
</code></pre>
<p><strong>Don't expose to network</strong> unless you understand the risks:</p>
<pre><code class="language-toml">[daemon]
host = "0.0.0.0"  # ⚠️ Accepts connections from any network interface
</code></pre>
<h3 id="file-permissions"><a class="header" href="#file-permissions">File Permissions</a></h3>
<p>Protect your configuration and state:</p>
<pre><code class="language-bash"># Restrict config file
chmod 600 ~/.config/gflow/gflow.toml

# Restrict state file
chmod 600 ~/.local/share/gflow/state.json

# Restrict logs directory
chmod 700 ~/.local/share/gflow/logs/
</code></pre>
<h3 id="multi-user-systems"><a class="header" href="#multi-user-systems">Multi-user Systems</a></h3>
<p>On shared systems:</p>
<ul>
<li>Each user should run their own daemon instance</li>
<li>Use different ports for each user</li>
<li>Set proper file permissions on logs and state</li>
</ul>
<pre><code class="language-bash"># User 1
# ~/.config/gflow/gflow.toml
[daemon]
port = 59000

# User 2
# ~/.config/gflow/gflow.toml
[daemon]
port = 59001
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<ol>
<li><strong>Use default config</strong> unless you have specific needs</li>
<li><strong>Version control your config</strong> for project-specific settings</li>
<li><strong>Document custom configs</strong> for your team</li>
<li><strong>Backup state periodically</strong> if job history is important</li>
<li><strong>Clean logs regularly</strong> to manage disk space</li>
<li><strong>Use meaningful port numbers</strong> for multiple instances</li>
<li><strong>Test config changes</strong> before deploying to production</li>
<li><strong>Monitor daemon logs</strong> when debugging issues</li>
<li><strong>Set appropriate permissions</strong> on config and state files</li>
<li><strong>Use environment variables</strong> for CI/CD automation</li>
</ol>
<h2 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h2>
<h3 id="example-1-minimal-config"><a class="header" href="#example-1-minimal-config">Example 1: Minimal Config</a></h3>
<p>Use defaults for everything:</p>
<pre><code class="language-toml"># ~/.config/gflow/gflow.toml
# Empty file - all defaults
</code></pre>
<h3 id="example-2-custom-port"><a class="header" href="#example-2-custom-port">Example 2: Custom Port</a></h3>
<pre><code class="language-toml">[daemon]
port = 59001
</code></pre>
<h3 id="example-3-limited-gpu-access"><a class="header" href="#example-3-limited-gpu-access">Example 3: Limited GPU Access</a></h3>
<pre><code class="language-toml">[daemon]
# Only use GPUs 0 and 2
gpus = [0, 2]
</code></pre>
<h3 id="example-4-debug-mode"><a class="header" href="#example-4-debug-mode">Example 4: Debug Mode</a></h3>
<pre><code class="language-toml">[daemon]
log_level = "debug"
</code></pre>
<h3 id="example-5-multi-instance-setup"><a class="header" href="#example-5-multi-instance-setup">Example 5: Multi-instance Setup</a></h3>
<p><strong>Production</strong> (~/.config/gflow/gflow.toml):</p>
<pre><code class="language-toml">[daemon]
port = 59000
gpus = [0, 1]
log_level = "info"
</code></pre>
<p><strong>Development</strong> (~/gflow-dev/config.toml):</p>
<pre><code class="language-toml">[daemon]
port = 59001
gpus = [2, 3]
log_level = "debug"
</code></pre>
<h2 id="see-also-4"><a class="header" href="#see-also-4">See Also</a></h2>
<ul>
<li><a href="user-guide/../getting-started/installation.html">Installation</a> - Initial setup</li>
<li><a href="user-guide/../getting-started/quick-start.html">Quick Start</a> - Basic usage</li>
<li><a href="user-guide/./job-submission.html">Job Submission</a> - Submitting jobs</li>
<li><a href="user-guide/./gpu-management.html">GPU Management</a> - GPU allocation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gflow-quick-reference-card"><a class="header" href="#gflow-quick-reference-card">gflow Quick Reference Card</a></h1>
<h2 id="essential-commands"><a class="header" href="#essential-commands">Essential Commands</a></h2>
<h3 id="daemon-management"><a class="header" href="#daemon-management">Daemon Management</a></h3>
<pre><code class="language-bash">gflowd up                  # Start the scheduler daemon
gflowd down                # Stop the scheduler daemon
ginfo info              # Check daemon status and GPU allocation
watch -n 2 ginfo info   # Monitor scheduler state
</code></pre>
<h3 id="job-submission-1"><a class="header" href="#job-submission-1">Job Submission</a></h3>
<pre><code class="language-bash"># Basic submission
gbatch python script.py
gbatch my_script.sh

# With GPU
gbatch --gpus 1 python train.py

# With time limit
gbatch --time 2:00:00 python train.py    # 2 hours
gbatch --time 30 python train.py         # 30 minutes
gbatch --time 5:30 python train.py       # 5 min 30 sec

# With dependencies
gbatch --depends-on 123 python process.py

# With priority
gbatch --priority 100 python urgent.py

# Job arrays
gbatch --array 1-10 python task.py

# Conda environment
gbatch --conda-env myenv python script.py

# Combined options
gbatch --gpus 2 --time 4:00:00 --priority 50 \
       python train.py
</code></pre>
<h3 id="job-script-format"><a class="header" href="#job-script-format">Job Script Format</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1
# GFLOW --time 2:00:00
# GFLOW --priority 20
# GFLOW --conda-env myenv

echo "Starting job..."
python train.py
</code></pre>
<h3 id="querying-jobs"><a class="header" href="#querying-jobs">Querying Jobs</a></h3>
<pre><code class="language-bash"># Basic listing
gqueue                           # Show last 10 jobs
gqueue -a                        # Show all jobs
gqueue -n 20                     # Show last 20 jobs

# Filter by state
gqueue -s Running                # Running jobs only
gqueue -s Queued,Running         # Multiple states

# Filter by job ID
gqueue -j 42                     # Specific job
gqueue -j 40,41,42               # Multiple jobs

# Custom format
gqueue -f JOBID,NAME,ST,TIME,TIMELIMIT
gqueue -f JOBID,NAME,ST,NODES,NODELIST

# Sort options
gqueue -r id                     # Sort by ID (default)
gqueue -r time                   # Sort by start time
gqueue -r priority               # Sort by priority

# Group by state
gqueue -g                        # Group jobs by state

# Dependency tree
gqueue -t                        # Show job dependency tree
</code></pre>
<h3 id="job-control"><a class="header" href="#job-control">Job Control</a></h3>
<pre><code class="language-bash">gcancel &lt;job_id&gt;                 # Cancel a job
gcancel --finish &lt;job_id&gt;        # Mark job as finished (internal)
gcancel --fail &lt;job_id&gt;          # Mark job as failed (internal)
</code></pre>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<pre><code class="language-bash"># Watch queue
watch -n 5 gqueue

# Watch running jobs with time limits
watch -n 5 'gqueue -s Running -f JOBID,NAME,TIME,TIMELIMIT'

# Check logs
cat ~/.local/share/gflow/logs/&lt;job_id&gt;.log
tail -f ~/.local/share/gflow/logs/&lt;job_id&gt;.log

# Attach to daemon tmux session
tmux attach -t gflow_server

# Attach to job tmux session
tmux attach -t &lt;job_run_name&gt;
</code></pre>
<h2 id="job-states-1"><a class="header" href="#job-states-1">Job States</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Full Name</th><th>Description</th></tr></thead><tbody>
<tr><td><code>PD</code></td><td>Queued</td><td>Waiting for resources or dependencies</td></tr>
<tr><td><code>R</code></td><td>Running</td><td>Currently executing</td></tr>
<tr><td><code>CD</code></td><td>Finished</td><td>Completed successfully</td></tr>
<tr><td><code>F</code></td><td>Failed</td><td>Exited with non-zero status</td></tr>
<tr><td><code>CA</code></td><td>Cancelled</td><td>Manually cancelled by user</td></tr>
<tr><td><code>TO</code></td><td>Timeout</td><td>Exceeded time limit</td></tr>
</tbody></table>
</div>
<h2 id="time-limit-formats"><a class="header" href="#time-limit-formats">Time Limit Formats</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Example</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>HH:MM:SS</code></td><td><code>2:30:00</code></td><td>2 hours, 30 minutes</td></tr>
<tr><td><code>HH:MM:SS</code></td><td><code>12:00:00</code></td><td>12 hours</td></tr>
<tr><td><code>MM:SS</code></td><td><code>45:30</code></td><td>45 minutes, 30 seconds</td></tr>
<tr><td><code>MM:SS</code></td><td><code>5:00</code></td><td>5 minutes</td></tr>
<tr><td><code>MM</code></td><td><code>30</code></td><td>30 minutes</td></tr>
<tr><td><code>MM</code></td><td><code>120</code></td><td>120 minutes (2 hours)</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Single number is always minutes, not seconds!</p>
<h2 id="output-format-fields"><a class="header" href="#output-format-fields">Output Format Fields</a></h2>
<p>Available fields for <code>gqueue -f</code>:</p>
<ul>
<li><code>JOBID</code> - Job ID number</li>
<li><code>NAME</code> - Job run name (tmux session name)</li>
<li><code>ST</code> - State (short form)</li>
<li><code>TIME</code> - Elapsed time (HH:MM:SS)</li>
<li><code>TIMELIMIT</code> - Time limit (HH:MM:SS or UNLIMITED)</li>
<li><code>NODES</code> - Number of GPUs requested</li>
<li><code>NODELIST(REASON)</code> - GPU IDs assigned</li>
</ul>
<h2 id="environment-variables-3"><a class="header" href="#environment-variables-3">Environment Variables</a></h2>
<p>Set by gflow in job environment:</p>
<ul>
<li><code>CUDA_VISIBLE_DEVICES</code> - Comma-separated GPU IDs</li>
<li><code>GFLOW_ARRAY_TASK_ID</code> - Task ID for array jobs (0 for non-array)</li>
</ul>
<h2 id="file-locations-1"><a class="header" href="#file-locations-1">File Locations</a></h2>
<pre><code>~/.config/gflow/
  └── gflowd.toml              # Configuration file

~/.local/share/gflow/
  ├── state.json               # Job state (persisted)
  └── logs/
      ├── 1.log                # Job output logs
      ├── 2.log
      └── ...
</code></pre>
<h2 id="common-patterns-2"><a class="header" href="#common-patterns-2">Common Patterns</a></h2>
<h3 id="sequential-jobs-pipeline"><a class="header" href="#sequential-jobs-pipeline">Sequential Jobs (Pipeline)</a></h3>
<pre><code class="language-bash"># Step 1: Preprocessing
ID1=$(gbatch --time 30 python preprocess.py | grep -oP '\d+')

# Step 2: Training (depends on step 1)
ID2=$(gbatch --time 4:00:00 --depends-on $ID1 python train.py | grep -oP '\d+')

# Step 3: Evaluation (depends on step 2)
gbatch --time 10 --depends-on $ID2 python evaluate.py
</code></pre>
<h3 id="parallel-jobs-array-1"><a class="header" href="#parallel-jobs-array-1">Parallel Jobs (Array)</a></h3>
<pre><code class="language-bash"># Process 10 tasks in parallel
gbatch --array 1-10 --time 1:00:00 \
       python process.py --task $GFLOW_ARRAY_TASK_ID
</code></pre>
<h3 id="gpu-sweeps-1"><a class="header" href="#gpu-sweeps-1">GPU Sweeps</a></h3>
<pre><code class="language-bash"># Try different hyperparameters on different GPUs
gbatch --gpus 1 --time 2:00:00 python train.py --lr 0.001
gbatch --gpus 1 --time 2:00:00 python train.py --lr 0.01
gbatch --gpus 1 --time 2:00:00 python train.py --lr 0.1
</code></pre>
<h3 id="long-running-with-checkpointing-1"><a class="header" href="#long-running-with-checkpointing-1">Long-Running with Checkpointing</a></h3>
<pre><code class="language-bash"># Initial training
gbatch --time 8:00:00 --gpus 1 \
       python train.py --checkpoint checkpoint.pth

# Resume if timed out (submit manually after checking)
gbatch --time 8:00:00 --gpus 1 \
       python train.py --resume checkpoint.pth
</code></pre>
<h2 id="tips-and-tricks"><a class="header" href="#tips-and-tricks">Tips and Tricks</a></h2>
<h3 id="1-auto-submit-on-dependency-completion"><a class="header" href="#1-auto-submit-on-dependency-completion">1. Auto-submit on dependency completion</a></h3>
<pre><code class="language-bash"># Not built-in, but can script it:
while [ "$(gqueue -j $ID1 -f ST)" != "CD" ]; do sleep 5; done
gbatch python next_step.py
</code></pre>
<h3 id="2-get-job-output-path-programmatically"><a class="header" href="#2-get-job-output-path-programmatically">2. Get job output path programmatically</a></h3>
<pre><code class="language-bash">JOB_ID=42
LOG_PATH="$HOME/.local/share/gflow/logs/${JOB_ID}.log"
tail -f "$LOG_PATH"
</code></pre>
<h3 id="3-check-remaining-time-manually"><a class="header" href="#3-check-remaining-time-manually">3. Check remaining time (manually)</a></h3>
<pre><code class="language-bash"># Show time and limit
gqueue -j 42 -f TIME,TIMELIMIT

# Example output:
# TIME         TIMELIMIT
# 01:23:45     02:00:00
# Remaining: ~36 minutes
</code></pre>
<h3 id="4-filter-timed-out-jobs"><a class="header" href="#4-filter-timed-out-jobs">4. Filter timed-out jobs</a></h3>
<pre><code class="language-bash">gqueue -s Timeout -f JOBID,NAME,TIME,TIMELIMIT
</code></pre>
<h3 id="5-quick-job-status-check"><a class="header" href="#5-quick-job-status-check">5. Quick job status check</a></h3>
<pre><code class="language-bash"># Check if job finished successfully
[ "$(gqueue -j 42 -f ST)" = "CD" ] &amp;&amp; echo "Success!" || echo "Not done or failed"
</code></pre>
<h3 id="6-kill-all-your-running-jobs"><a class="header" href="#6-kill-all-your-running-jobs">6. Kill all your running jobs</a></h3>
<pre><code class="language-bash"># Get all running job IDs
RUNNING=$(gqueue -s Running -f JOBID | tail -n +2)
for jobid in $RUNNING; do
    gcancel $jobid
done
</code></pre>
<h3 id="7-find-jobs-that-timed-out"><a class="header" href="#7-find-jobs-that-timed-out">7. Find jobs that timed out</a></h3>
<pre><code class="language-bash">gqueue -a -s Timeout -f JOBID,NAME,TIME,TIMELIMIT
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="job-stuck-in-queued"><a class="header" href="#job-stuck-in-queued">Job stuck in Queued</a></h3>
<pre><code class="language-bash"># Check dependencies
gqueue -t

# Check GPU availability
gqueue -s Running -f JOBID,NODES,NODELIST

# Check if dependency finished
gqueue -j &lt;dependency_id&gt; -f ST
</code></pre>
<h3 id="job-timed-out-unexpectedly"><a class="header" href="#job-timed-out-unexpectedly">Job timed out unexpectedly</a></h3>
<pre><code class="language-bash"># Check actual runtime
gqueue -j &lt;job_id&gt; -f TIME,TIMELIMIT

# Verify time format (30 = 30 minutes, not seconds!)
# Resubmit with longer limit
gbatch --time 60 ...
</code></pre>
<h3 id="cant-find-job-logs"><a class="header" href="#cant-find-job-logs">Can't find job logs</a></h3>
<pre><code class="language-bash"># Logs are in
ls -la ~/.local/share/gflow/logs/

# Check job ID is correct
gqueue -a -f JOBID,NAME
</code></pre>
<h3 id="job-not-receiving-gpu"><a class="header" href="#job-not-receiving-gpu">Job not receiving GPU</a></h3>
<pre><code class="language-bash"># Check if GPUs were requested
gqueue -j &lt;job_id&gt; -f JOBID,NODES,NODELIST

# Check GPU availability
nvidia-smi

# Check if other jobs are using GPUs
gqueue -s Running -f JOBID,NODES,NODELIST
</code></pre>
<h2 id="resource-limits"><a class="header" href="#resource-limits">Resource Limits</a></h2>
<p>Default scheduler settings:</p>
<ul>
<li><strong>Check interval</strong>: 5 seconds</li>
<li><strong>Timeout accuracy</strong>: ±5 seconds</li>
<li><strong>Time limit range</strong>: No hard limit</li>
<li><strong>Priority range</strong>: 0-255 (default: 10)</li>
<li><strong>GPU detection</strong>: Via NVML (NVIDIA GPUs only)</li>
</ul>
<h2 id="exit-codes"><a class="header" href="#exit-codes">Exit Codes</a></h2>
<p>Common exit codes in logs:</p>
<ul>
<li><code>0</code> - Success</li>
<li><code>1</code> - General error</li>
<li><code>130</code> - SIGINT (Ctrl-C / Timeout)</li>
<li><code>137</code> - SIGKILL (forceful termination)</li>
<li><code>143</code> - SIGTERM (graceful termination)</li>
</ul>
<h2 id="quick-diagnosis"><a class="header" href="#quick-diagnosis">Quick Diagnosis</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Symptom</th><th>Likely Cause</th><th>Solution</th></tr></thead><tbody>
<tr><td>Job shows TO</td><td>Time limit exceeded</td><td>Increase <code>--time</code></td></tr>
<tr><td>Job shows F</td><td>Script error</td><td>Check logs</td></tr>
<tr><td>Job stuck PD</td><td>Dependency not done</td><td>Check dependency state</td></tr>
<tr><td>Job stuck PD</td><td>No free GPUs</td><td>Wait or reduce <code>--gpus</code></td></tr>
<tr><td>No output</td><td>Pipe-pane issue</td><td>Check tmux session</td></tr>
<tr><td>Can't attach</td><td>Session killed</td><td>Job likely finished</td></tr>
</tbody></table>
</div>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<ol>
<li><strong>Always set time limits</strong> for production jobs</li>
<li><strong>Use job arrays</strong> for parallel independent tasks</li>
<li><strong>Implement checkpointing</strong> for long-running jobs</li>
<li><strong>Monitor time usage</strong> with <code>watch gqueue</code></li>
<li><strong>Add buffer</strong> to time estimates (10-20%)</li>
<li><strong>Use dependencies</strong> for pipeline workflows</li>
<li><strong>Check logs</strong> when jobs fail or timeout</li>
<li><strong>Test scripts</strong> with short time limits first</li>
</ol>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<ul>
<li>Detailed docs: <code>docs/TIME_LIMITS.md</code></li>
<li>Main README: <code>README.md</code></li>
<li>Report issues: GitHub Issues</li>
<li>Source code: GitHub Repository</li>
</ul>
<hr />
<p><strong>Quick Help</strong>: Run any command with <code>--help</code> for detailed options:</p>
<pre><code class="language-bash">$ gbatch --help
Submits jobs to the gflow scheduler. Inspired by sbatch.

Usage: gbatch [OPTIONS] &lt;SCRIPT_OR_COMMAND&gt;... [COMMAND]

Commands:
  new   Create a new job script template
  help  Print this message or the help of the given subcommand(s)

Arguments:
  &lt;SCRIPT_OR_COMMAND&gt;...  The script or command to run (e.g., "script.sh" or "python train.py --epochs 100") If a single argument that exists as a file, it's treated as a script. Otherwise, all arguments are joined as a command

Options:
  -c, --conda-env &lt;CONDA_ENV&gt;    The conda environment to use
  -g, --gpus &lt;NUMS&gt;              The GPU count to request
      --priority &lt;PRIORITY&gt;      The priority of the job
      --depends-on &lt;DEPENDS_ON&gt;  The ID of the job this job depends on
      --array &lt;ARRAY&gt;            The job array specification (e.g., "1-10")
  -t, --time &lt;TIME&gt;              Time limit for the job (formats: "HH:MM:SS", "MM:SS", "MM", or seconds as number)
  -h, --help                     Print help
  -V, --version                  Print version
</code></pre>
<pre><code class="language-bash">$ gqueue --help
Lists jobs in the gflow scheduler.

Usage: gqueue [OPTIONS]

Options:
  -n, --limit &lt;LIMIT&gt;    Limit the number of jobs to display (positive: first N, negative: last N, 0: all) [default: -10]
  -a, --all              Show all jobs (equivalent to --limit 0)
  -r, --sort &lt;SORT&gt;      Sort jobs by field (options: id, state, time, name, gpus, priority) [default: id]
  -s, --states &lt;STATES&gt;  Filter by a comma-separated list of job states (e.g., Queued,Running)
  -j, --jobs &lt;JOBS&gt;      Filter by a comma-separated list of job IDs
  -N, --names &lt;NAMES&gt;    Filter by a comma-separated list of job names
  -f, --format &lt;FORMAT&gt;  Specify a comma-separated list of fields to display
  -g, --group            Group jobs by state (helps visualize job distribution)
  -t, --tree             Display jobs in tree format showing dependencies
  -h, --help             Print help
  -V, --version          Print version
</code></pre>
<pre><code class="language-bash">$ ginfo --help
Displays gflow scheduler and GPU information.

Usage: ginfo [OPTIONS] &lt;COMMAND&gt;

Commands:
  info  Display system information and GPU allocation
  help  Print this message or the help of the given subcommand(s)

Options:
  -v, --verbose...  Increase logging verbosity
  -q, --quiet...    Decrease logging verbosity
  -h, --help        Print help
  -V, --version     Print version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gbatch-command-reference"><a class="header" href="#gbatch-command-reference">gbatch Command Reference</a></h1>
<p>Complete reference for the <code>gbatch</code> command - gflow's job submission tool.</p>
<h2 id="synopsis"><a class="header" href="#synopsis">Synopsis</a></h2>
<pre><code class="language-bash">gbatch [OPTIONS] [COMMAND...]
gbatch [OPTIONS] [SCRIPT]
gbatch new &lt;NAME&gt;
</code></pre>
<h2 id="description"><a class="header" href="#description">Description</a></h2>
<p><code>gbatch</code> submits jobs to the gflow scheduler. It supports both script-based and direct command execution using positional arguments, with extensive options for resource allocation, scheduling, and job dependencies.</p>
<h2 id="modes"><a class="header" href="#modes">Modes</a></h2>
<h3 id="script-submission"><a class="header" href="#script-submission">Script Submission</a></h3>
<p>Submit a script file:</p>
<pre><code class="language-bash">gbatch [OPTIONS] &lt;SCRIPT&gt;
</code></pre>
<p>The script can contain <code># GFLOW</code> directives for job parameters.</p>
<h3 id="direct-command"><a class="header" href="#direct-command">Direct Command</a></h3>
<p>Execute a command directly using positional arguments:</p>
<pre><code class="language-bash">gbatch [OPTIONS] &lt;COMMAND&gt; [ARGS...]
</code></pre>
<p>The command and its arguments come after all options. Command-line options take precedence over script directives.</p>
<h3 id="template-creation"><a class="header" href="#template-creation">Template Creation</a></h3>
<p>Create a new job script template:</p>
<pre><code class="language-bash">gbatch new &lt;NAME&gt;
</code></pre>
<p>Creates <code>&lt;NAME&gt;.sh</code> with a template structure.</p>
<h2 id="options"><a class="header" href="#options">Options</a></h2>
<h3 id="job-submission-2"><a class="header" href="#job-submission-2">Job Submission</a></h3>
<h4 id="script"><a class="header" href="#script"><code>&lt;SCRIPT&gt;</code></a></h4>
<p>Path to script file to execute.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gbatch my_job.sh
gbatch ./scripts/train.sh
gbatch /absolute/path/to/job.sh
</code></pre>
<p><strong>Requirements</strong>:</p>
<ul>
<li>File must exist</li>
<li>Should be executable (<code>chmod +x</code>)</li>
<li>Can contain <code># GFLOW</code> directives</li>
</ul>
<p><strong>Mutually exclusive</strong> with direct command execution.</p>
<h4 id="direct-command-execution"><a class="header" href="#direct-command-execution">Direct Command Execution</a></h4>
<p>When no script is provided, all arguments after the options are treated as the command to execute.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gbatch python train.py
gbatch echo 'Hello'; sleep 10
gbatch nvidia-smi
</code></pre>
<p><strong>Notes</strong>:</p>
<ul>
<li>Executed in bash shell</li>
<li>Can contain multiple commands (use <code>;</code> or <code>&amp;&amp;</code>)</li>
<li>Mutually exclusive with <code>&lt;SCRIPT&gt;</code></li>
<li>Commands with complex arguments should be quoted appropriately</li>
</ul>
<h3 id="resource-allocation-1"><a class="header" href="#resource-allocation-1">Resource Allocation</a></h3>
<h4 id="--gpus-n--g-n"><a class="header" href="#--gpus-n--g-n"><code>--gpus &lt;N&gt;</code>, <code>-g &lt;N&gt;</code></a></h4>
<p>Number of GPUs to request.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Request 1 GPU
gbatch --gpus 1 python train.py

# Request 2 GPUs
gbatch -g 2 python multi_gpu_train.py

# No GPU (default)
gbatch python cpu_task.py
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Default: 0 (no GPU)</li>
<li>Sets <code>CUDA_VISIBLE_DEVICES</code> automatically</li>
<li>Job waits if insufficient GPUs available</li>
<li>See <a href="reference/../user-guide/gpu-management.html">GPU Management</a></li>
</ul>
<h4 id="--conda-env-env"><a class="header" href="#--conda-env-env"><code>--conda-env &lt;ENV&gt;</code></a></h4>
<p>Conda environment to activate.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gbatch --conda-env myenv python script.py
gbatch --conda-env pytorch_env my_training.sh
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Runs <code>conda activate &lt;ENV&gt;</code> before job</li>
<li>Requires conda to be initialized in shell</li>
<li>Job fails if environment doesn't exist</li>
</ul>
<p><strong>Auto-detection</strong> (for direct command mode only):</p>
<ul>
<li>If <code>--conda-env</code> is not specified, gflow automatically detects your currently active conda environment</li>
<li>Uses the <code>CONDA_DEFAULT_ENV</code> environment variable</li>
<li>Only applies when using direct command execution, not when submitting scripts</li>
<li>Explicit <code>--conda-env</code> always takes precedence over auto-detection</li>
</ul>
<pre><code class="language-bash"># With auto-detection (uses currently active conda env)
conda activate myenv
gbatch python script.py  # Will use 'myenv'

# Explicit override (ignores active env)
conda activate myenv
gbatch --conda-env otherenv python script.py  # Uses 'otherenv'

# No conda environment
conda deactivate
gbatch python script.py  # No conda activation
</code></pre>
<h3 id="scheduling-options"><a class="header" href="#scheduling-options">Scheduling Options</a></h3>
<h4 id="--priority-n"><a class="header" href="#--priority-n"><code>--priority &lt;N&gt;</code></a></h4>
<p>Job priority (0-255, default: 10).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># High priority (runs first)
gbatch --priority 100 python urgent.py

# Default priority
gbatch python normal.py  # priority = 10

# Low priority (runs last)
gbatch --priority 1 python background.py
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Higher values = higher priority</li>
<li>Jobs with higher priority start first when resources free</li>
<li>Doesn't preempt running jobs</li>
</ul>
<h4 id="--depends-on-id"><a class="header" href="#--depends-on-id"><code>--depends-on &lt;ID&gt;</code></a></h4>
<p>Job ID this job depends on. Supports shorthand for recent submissions.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Job 1
gbatch python preprocess.py
# Returns job ID 1

# Job 2 (depends on 1)
gbatch --depends-on 1 python train.py

# Equivalent shorthand using the last submission
gbatch --depends-on @ python train.py

# Two submissions back
gbatch --depends-on @~2 python evaluate.py
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Job waits for dependency to reach <code>Finished</code> state</li>
<li>If dependency fails, this job never starts</li>
<li>Only one dependency per job supported</li>
<li>See <a href="reference/../user-guide/job-dependencies.html">Job Dependencies</a></li>
<li>Shorthand values resolve to the most recent job IDs recorded by <code>gbatch</code></li>
</ul>
<p><strong>Validation</strong>:</p>
<ul>
<li>Dependency job must exist</li>
<li>No circular dependencies allowed</li>
<li>Cannot depend on self</li>
<li><code>@~N</code> requires at least <code>N</code> previous submissions</li>
</ul>
<h4 id="--time-time--t-time"><a class="header" href="#--time-time--t-time"><code>--time &lt;TIME&gt;</code>, <code>-t &lt;TIME&gt;</code></a></h4>
<p>Maximum job runtime (time limit).</p>
<p><strong>Formats</strong>:</p>
<ul>
<li><code>MM</code>: Minutes only (e.g., <code>30</code> = 30 minutes)</li>
<li><code>MM:SS</code>: Minutes and seconds (e.g., <code>5:30</code> = 5min 30sec)</li>
<li><code>HH:MM:SS</code>: Hours, minutes, seconds (e.g., <code>2:00:00</code> = 2 hours)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># 30 minutes
gbatch --time 30 python quick.py

# 2 hours
gbatch --time 2:00:00 python train.py

# 5 minutes 30 seconds
gbatch -t 5:30 python test.py
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Job terminated if exceeds limit</li>
<li>Graceful termination (SIGINT/Ctrl-C)</li>
<li>State changes to <code>Timeout</code></li>
<li>See <a href="reference/../user-guide/time-limits.html">Time Limits</a></li>
</ul>
<h4 id="--array-spec"><a class="header" href="#--array-spec"><code>--array &lt;SPEC&gt;</code></a></h4>
<p>Create job array.</p>
<p><strong>Format</strong>: <code>START-END</code> (e.g., <code>1-10</code>)</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Create 10 jobs (tasks 1-10)
gbatch --array 1-10 python process.py --task $GFLOW_ARRAY_TASK_ID

# Create 5 jobs with GPUs
gbatch --array 1-5 --gpus 1 python train.py --fold $GFLOW_ARRAY_TASK_ID
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Creates multiple independent jobs</li>
<li>Each job gets unique <code>$GFLOW_ARRAY_TASK_ID</code></li>
<li>All jobs share same resource requirements</li>
<li>Useful for parameter sweeps</li>
</ul>
<p><strong>Environment variable</strong>:</p>
<ul>
<li><code>GFLOW_ARRAY_TASK_ID</code>: Task number (1, 2, 3, ...)</li>
<li>Set to 0 for non-array jobs</li>
</ul>
<h4 id="--name-name"><a class="header" href="#--name-name"><code>--name &lt;NAME&gt;</code></a></h4>
<p>Custom job name.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gbatch --name "my-training-run" python train.py
gbatch --name "experiment-1" my_job.sh
</code></pre>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Default: Auto-generated name (e.g., "silent-pump-6338")</li>
<li>Used as tmux session name</li>
<li>Helps identify jobs in queue</li>
<li>Must be unique (or gflow appends suffix)</li>
</ul>
<h3 id="global-options"><a class="header" href="#global-options">Global Options</a></h3>
<h4 id="--config-path"><a class="header" href="#--config-path"><code>--config &lt;PATH&gt;</code></a></h4>
<p>Use custom configuration file (hidden option).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gbatch --config /path/to/custom.toml your_command
</code></pre>
<h4 id="--help--h"><a class="header" href="#--help--h"><code>--help</code>, <code>-h</code></a></h4>
<p>Display help message.</p>
<pre><code class="language-bash">$ gbatch --help
Submits jobs to the gflow scheduler. Inspired by sbatch.

Usage: gbatch [OPTIONS] &lt;SCRIPT_OR_COMMAND&gt;... [COMMAND]

Commands:
  new   Create a new job script template
  help  Print this message or the help of the given subcommand(s)

Arguments:
  &lt;SCRIPT_OR_COMMAND&gt;...  The script or command to run (e.g., "script.sh" or "python train.py --epochs 100") If a single argument that exists as a file, it's treated as a script. Otherwise, all arguments are joined as a command

Options:
  -c, --conda-env &lt;CONDA_ENV&gt;    The conda environment to use
  -g, --gpus &lt;NUMS&gt;              The GPU count to request
      --priority &lt;PRIORITY&gt;      The priority of the job
      --depends-on &lt;DEPENDS_ON&gt;  The ID of the job this job depends on
      --array &lt;ARRAY&gt;            The job array specification (e.g., "1-10")
  -t, --time &lt;TIME&gt;              Time limit for the job (formats: "HH:MM:SS", "MM:SS", "MM", or seconds as number)
  -h, --help                     Print help
  -V, --version                  Print version
</code></pre>
<h4 id="--version--v"><a class="header" href="#--version--v"><code>--version</code>, <code>-V</code></a></h4>
<p>Display version information.</p>
<pre><code class="language-bash">$ gbatch --version
gbatch 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<h2 id="script-directives-1"><a class="header" href="#script-directives-1">Script Directives</a></h2>
<p>Embed job parameters in script using <code># GFLOW</code> comments.</p>
<h3 id="syntax"><a class="header" href="#syntax">Syntax</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --option value
# GFLOW --another-option value

# Your commands here
</code></pre>
<h3 id="supported-directives"><a class="header" href="#supported-directives">Supported Directives</a></h3>
<pre><code class="language-bash"># GFLOW --gpus &lt;N&gt;
# GFLOW --time &lt;TIME&gt;
# GFLOW --priority &lt;N&gt;
# GFLOW --conda-env &lt;ENV&gt;
# GFLOW --depends-on &lt;ID&gt;
</code></pre>
<h3 id="example-script"><a class="header" href="#example-script">Example Script</a></h3>
<pre><code class="language-bash">#!/bin/bash
# GFLOW --gpus 1
# GFLOW --time 2:00:00
# GFLOW --priority 20
# GFLOW --conda-env pytorch

echo "Starting training at $(date)"
python train.py --epochs 100
echo "Training complete at $(date)"
</code></pre>
<h3 id="precedence"><a class="header" href="#precedence">Precedence</a></h3>
<p>Command-line options override script directives:</p>
<pre><code class="language-bash"># Script has: # GFLOW --time 1:00:00
# CLI overrides it:
gbatch --time 2:00:00 my_script.sh  # Uses 2 hours, not 1
</code></pre>
<h2 id="template-creation-1"><a class="header" href="#template-creation-1">Template Creation</a></h2>
<h3 id="new-subcommand"><a class="header" href="#new-subcommand"><code>new</code> Subcommand</a></h3>
<pre><code class="language-bash">gbatch new &lt;NAME&gt;
</code></pre>
<p>Creates <code>&lt;NAME&gt;.sh</code> with template structure.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">$ gbatch new my_job
Created template: my_job.sh

$ cat my_job.sh
#!/bin/bash
# GFLOW --gpus 0
# GFLOW --time 1:00:00
# GFLOW --priority 10

# Your commands here
echo "Job started at $(date)"

# Add your actual commands
# python script.py

echo "Job finished at $(date)"
</code></pre>
<p><strong>Usage</strong>:</p>
<ol>
<li>Create template: <code>gbatch new my_job</code></li>
<li>Edit script: <code>vim my_job.sh</code></li>
<li>Make executable: <code>chmod +x my_job.sh</code></li>
<li>Submit: <code>gbatch my_job.sh</code></li>
</ol>
<h2 id="environment-variables-4"><a class="header" href="#environment-variables-4">Environment Variables</a></h2>
<p>gflow sets these variables in your job:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>CUDA_VISIBLE_DEVICES</code></td><td>Allocated GPU IDs</td><td><code>0,1</code></td></tr>
<tr><td><code>GFLOW_ARRAY_TASK_ID</code></td><td>Array task ID (0 if not array)</td><td><code>5</code></td></tr>
</tbody></table>
</div>
<p><strong>Usage in scripts</strong>:</p>
<pre><code class="language-bash">#!/bin/bash
echo "GPUs: $CUDA_VISIBLE_DEVICES"
echo "Task: $GFLOW_ARRAY_TASK_ID"
python train.py
</code></pre>
<h2 id="output"><a class="header" href="#output">Output</a></h2>
<h3 id="submission-success"><a class="header" href="#submission-success">Submission Success</a></h3>
<pre><code class="language-bash">$ gbatch python train.py
Submitted batch job 42 (silent-pump-6338)
</code></pre>
<p><strong>Format</strong>: <code>Submitted batch job &lt;ID&gt; (&lt;NAME&gt;)</code></p>
<h3 id="job-logs-1"><a class="header" href="#job-logs-1">Job Logs</a></h3>
<p>Output captured to: <code>~/.local/share/gflow/logs/&lt;JOBID&gt;.log</code></p>
<p><strong>View logs</strong>:</p>
<pre><code class="language-bash"># View completed job
cat ~/.local/share/gflow/logs/42.log

# Follow running job
tail -f ~/.local/share/gflow/logs/42.log
</code></pre>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<h3 id="basic-submission"><a class="header" href="#basic-submission">Basic Submission</a></h3>
<pre><code class="language-bash"># Direct command
gbatch echo 'Hello, gflow!'

# Script file
gbatch my_script.sh

# With options
gbatch --gpus 1 --time 2:00:00 python train.py
</code></pre>
<h3 id="resource-allocation-2"><a class="header" href="#resource-allocation-2">Resource Allocation</a></h3>
<pre><code class="language-bash"># GPU job
gbatch --gpus 2 python multi_gpu_train.py

# CPU job with time limit
gbatch --time 30 python preprocess.py

# Conda environment (explicit)
gbatch --conda-env myenv python script.py

# Conda environment (auto-detected from currently active env)
conda activate myenv
gbatch python script.py  # Automatically uses 'myenv'
</code></pre>
<h3 id="job-dependencies-3"><a class="header" href="#job-dependencies-3">Job Dependencies</a></h3>
<pre><code class="language-bash"># Sequential pipeline
ID1=$(gbatch --time 30 python prep.py | grep -oP '\d+')
ID2=$(gbatch --depends-on $ID1 --gpus 1 python train.py | grep -oP '\d+')
gbatch --depends-on $ID2 python eval.py
</code></pre>
<h3 id="job-arrays-1"><a class="header" href="#job-arrays-1">Job Arrays</a></h3>
<pre><code class="language-bash"># Process 10 tasks in parallel
gbatch --array 1-10 python process.py --id $GFLOW_ARRAY_TASK_ID

# GPU sweep
gbatch --array 1-5 --gpus 1 --time 4:00:00 \
       python train.py --lr $(echo "0.001 0.01 0.1 0.5 1.0" | cut -d" " -f$GFLOW_ARRAY_TASK_ID)
</code></pre>
<h3 id="priority-and-scheduling"><a class="header" href="#priority-and-scheduling">Priority and Scheduling</a></h3>
<pre><code class="language-bash"># Urgent job
gbatch --priority 100 --gpus 1 python urgent.py

# Background job
gbatch --priority 1 python background.py

# Named job
gbatch --name "exp-baseline" python train_baseline.py
</code></pre>
<h3 id="script-templates"><a class="header" href="#script-templates">Script Templates</a></h3>
<pre><code class="language-bash"># Create template
gbatch new experiment

# Edit it
vim experiment.sh

# Submit it
gbatch experiment.sh
</code></pre>
<h2 id="validation-and-errors"><a class="header" href="#validation-and-errors">Validation and Errors</a></h2>
<h3 id="common-errors"><a class="header" href="#common-errors">Common Errors</a></h3>
<pre><code class="language-bash"># Both script and command
Error: Cannot specify both script and direct command

# Script not found
Error: Script file not found: missing.sh

# Invalid dependency
Error: Dependency job 999 not found

# Circular dependency
Error: Circular dependency detected

# Invalid time format
Error: Invalid time format. Use HH:MM:SS, MM:SS, or MM

# Conda env not found
Error: Conda environment 'invalid_env' not found
</code></pre>
<h3 id="validation-checks"><a class="header" href="#validation-checks">Validation Checks</a></h3>
<p>At submission, gbatch validates:</p>
<ul>
<li>✅ Script exists (if using script mode)</li>
<li>✅ Dependency job exists</li>
<li>✅ No circular dependencies</li>
<li>✅ Valid time format</li>
<li>✅ Not both script and direct command</li>
<li>✅ GPU count is reasonable</li>
</ul>
<h2 id="integration-examples"><a class="header" href="#integration-examples">Integration Examples</a></h2>
<h3 id="shell-script-batch-submission"><a class="header" href="#shell-script-batch-submission">Shell Script: Batch Submission</a></h3>
<pre><code class="language-bash">#!/bin/bash
# submit_experiments.sh - Submit multiple experiments

for lr in 0.001 0.01 0.1; do
    for bs in 32 64 128; do
        gbatch --gpus 1 --time 4:00:00 \
               --name "lr${lr}_bs${bs}" \
               python train.py --lr $lr --batch-size $bs
    done
done
</code></pre>
<h3 id="shell-script-pipeline-submission"><a class="header" href="#shell-script-pipeline-submission">Shell Script: Pipeline Submission</a></h3>
<pre><code class="language-bash">#!/bin/bash
# submit_pipeline.sh - Submit data processing pipeline

set -e

echo "Submitting pipeline..."

# Stage 1: Download
ID1=$(gbatch --time 1:00:00 --name "download" \
             python download.py | grep -oP '\d+')
echo "Job $ID1 (download) submitted"

# Stage 2: Process (depends on download)
ID2=$(gbatch --depends-on $ID1 --time 2:00:00 --name "process" \
             python process.py | grep -oP '\d+')
echo "Job $ID2 (process) submitted"

# Stage 3: Train (depends on process)
ID3=$(gbatch --depends-on $ID2 --gpus 1 --time 8:00:00 --name "train" \
             python train.py | grep -oP '\d+')
echo "Job $ID3 (train) submitted"

echo "Pipeline submitted! Monitor with: watch gqueue -t"
</code></pre>
<h3 id="python-script-job-submission"><a class="header" href="#python-script-job-submission">Python Script: Job Submission</a></h3>
<pre><code class="language-python">#!/usr/bin/env python3
# submit_jobs.py - Submit jobs from Python

import subprocess
import re

def submit_job(command, **kwargs):
    """Submit a job and return its ID."""
    cmd = ['gbatch']

    # Add options first
    if 'gpus' in kwargs:
        cmd += ['--gpus', str(kwargs['gpus'])]
    if 'time' in kwargs:
        cmd += ['--time', kwargs['time']]
    if 'priority' in kwargs:
        cmd += ['--priority', str(kwargs['priority'])]
    if 'depends_on' in kwargs:
        cmd += ['--depends-on', str(kwargs['depends_on'])]
    if 'name' in kwargs:
        cmd += ['--name', kwargs['name']]

    # Add command at the end
    cmd += command.split() if isinstance(command, str) else command

    result = subprocess.run(cmd, capture_output=True, text=True)
    match = re.search(r'job (\d+)', result.stdout)
    return int(match.group(1)) if match else None

# Submit pipeline
prep_id = submit_job('python preprocess.py', time='30', name='prep')
train_id = submit_job('python train.py', gpus=1, time='4:00:00',
                       depends_on=prep_id, name='train')
eval_id = submit_job('python evaluate.py', time='10',
                      depends_on=train_id, name='eval')

print(f"Pipeline: {prep_id} -&gt; {train_id} -&gt; {eval_id}")
</code></pre>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<ol>
<li>
<p><strong>Always set time limits</strong> for production jobs</p>
<pre><code class="language-bash">gbatch --time 2:00:00 your_command
</code></pre>
</li>
<li>
<p><strong>Use meaningful names</strong> for easier tracking</p>
<pre><code class="language-bash">gbatch --name "exp-baseline-lr0.01" your_command
</code></pre>
</li>
<li>
<p><strong>Test scripts locally</strong> before submitting</p>
<pre><code class="language-bash">bash my_job.sh  # Test first
gbatch my_job.sh  # Then submit
</code></pre>
</li>
<li>
<p><strong>Request only needed GPUs</strong></p>
<pre><code class="language-bash">gbatch --gpus 1 "..."  # Not --gpus 4 if you only need 1
</code></pre>
</li>
<li>
<p><strong>Use dependencies</strong> for workflows</p>
<pre><code class="language-bash">ID=$(gbatch python prep.py | grep -oP '\d+')
gbatch --depends-on $ID python train.py
</code></pre>
</li>
<li>
<p><strong>Use job arrays</strong> for parallel tasks</p>
<pre><code class="language-bash">gbatch --array 1-10 python process.py --id $GFLOW_ARRAY_TASK_ID
</code></pre>
</li>
<li>
<p><strong>Add error handling</strong> in scripts</p>
<pre><code class="language-bash">#!/bin/bash
set -e  # Exit on error
</code></pre>
</li>
<li>
<p><strong>Log important info</strong> in your jobs</p>
<pre><code class="language-bash">echo "Job started: $(date)"
echo "GPUs: $CUDA_VISIBLE_DEVICES"
</code></pre>
</li>
</ol>
<h2 id="see-also-5"><a class="header" href="#see-also-5">See Also</a></h2>
<ul>
<li><a href="reference/./gqueue-reference.html">gqueue</a> - Job queue reference</li>
<li><a href="reference/./gcancel-reference.html">gcancel</a> - Job cancellation reference</li>
<li><a href="reference/./ginfo-reference.html">ginfo</a> - Scheduler inspection reference</li>
<li><a href="reference/../user-guide/job-submission.html">Job Submission</a> - Detailed submission guide</li>
<li><a href="reference/../user-guide/job-dependencies.html">Job Dependencies</a> - Workflow management</li>
<li><a href="reference/../user-guide/gpu-management.html">GPU Management</a> - GPU allocation guide</li>
<li><a href="reference/../user-guide/time-limits.html">Time Limits</a> - Time limit documentation</li>
<li><a href="reference/./quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gqueue-command-reference"><a class="header" href="#gqueue-command-reference">gqueue Command Reference</a></h1>
<p>Complete reference for the <code>gqueue</code> command - gflow's job queue monitoring tool.</p>
<h2 id="synopsis-1"><a class="header" href="#synopsis-1">Synopsis</a></h2>
<pre><code class="language-bash">gqueue [OPTIONS]
</code></pre>
<h2 id="description-1"><a class="header" href="#description-1">Description</a></h2>
<p><code>gqueue</code> displays information about jobs in the gflow queue. It provides flexible filtering, formatting, and visualization options similar to Slurm's <code>squeue</code> command.</p>
<h2 id="options-1"><a class="header" href="#options-1">Options</a></h2>
<h3 id="filtering-options"><a class="header" href="#filtering-options">Filtering Options</a></h3>
<h4 id="--states-states--s-states"><a class="header" href="#--states-states--s-states"><code>--states &lt;STATES&gt;</code>, <code>-s &lt;STATES&gt;</code></a></h4>
<p>Filter jobs by state (comma-separated list).</p>
<p><strong>Valid states</strong>:</p>
<ul>
<li><code>Queued</code> or <code>PD</code>: Waiting for resources or dependencies</li>
<li><code>Running</code> or <code>R</code>: Currently executing</li>
<li><code>Finished</code> or <code>CD</code>: Completed successfully</li>
<li><code>Failed</code> or <code>F</code>: Exited with error</li>
<li><code>Cancelled</code> or <code>CA</code>: Manually cancelled</li>
<li><code>Timeout</code> or <code>TO</code>: Exceeded time limit</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Show only running jobs
gqueue -s Running

# Show running and queued jobs
gqueue -s Running,Queued

# Show all terminal states
gqueue -s Finished,Failed,Cancelled,Timeout

# Use short form
gqueue -s R,PD
</code></pre>
<h4 id="--jobs-ids--j-ids"><a class="header" href="#--jobs-ids--j-ids"><code>--jobs &lt;IDS&gt;</code>, <code>-j &lt;IDS&gt;</code></a></h4>
<p>Filter by job ID (comma-separated list or ranges).</p>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Single job
gqueue -j 42

# Multiple jobs
gqueue -j 1,2,3

# Range (if supported)
gqueue -j 1-10

# Mixed
gqueue -j 1,5,10-15
</code></pre>
<h4 id="--names-names--n-names"><a class="header" href="#--names-names--n-names"><code>--names &lt;NAMES&gt;</code>, <code>-N &lt;NAMES&gt;</code></a></h4>
<p>Filter by job name (comma-separated list).</p>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Single name
gqueue -N training-job

# Multiple names
gqueue -N "prep,train,eval"

# Pattern matching (depends on implementation)
gqueue -N "train*"
</code></pre>
<h3 id="display-options"><a class="header" href="#display-options">Display Options</a></h3>
<h4 id="--limit-num--n-num"><a class="header" href="#--limit-num--n-num"><code>--limit &lt;NUM&gt;</code>, <code>-n &lt;NUM&gt;</code></a></h4>
<p>Limit number of jobs displayed.</p>
<p><strong>Behavior</strong>:</p>
<ul>
<li>Positive number: Show first N jobs</li>
<li>Negative number: Show last N jobs (default: -10)</li>
<li>Zero: Show all jobs (same as <code>--all</code>)</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Show last 10 jobs (default)
gqueue

# Show last 20 jobs
gqueue -n 20

# Show first 5 jobs
gqueue -n 5

# Show all jobs
gqueue -n 0
</code></pre>
<h4 id="--all--a"><a class="header" href="#--all--a"><code>--all</code>, <code>-a</code></a></h4>
<p>Show all jobs (equivalent to <code>-n 0</code>).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gqueue -a
</code></pre>
<h4 id="--format-fields--f-fields"><a class="header" href="#--format-fields--f-fields"><code>--format &lt;FIELDS&gt;</code>, <code>-f &lt;FIELDS&gt;</code></a></h4>
<p>Custom output format (comma-separated field list).</p>
<p><strong>Available fields</strong>:</p>
<ul>
<li><code>JOBID</code>: Job ID number</li>
<li><code>NAME</code>: Job name (tmux session name)</li>
<li><code>ST</code>: Job state (short form: PD, R, CD, F, CA, TO)</li>
<li><code>STATE</code>: Job state (long form: Queued, Running, Finished, etc.)</li>
<li><code>TIME</code>: Elapsed time (HH:MM:SS)</li>
<li><code>TIMELIMIT</code>: Time limit (HH:MM:SS or UNLIMITED)</li>
<li><code>NODES</code>: Number of GPUs requested</li>
<li><code>NODELIST</code>: GPU IDs assigned (or REASON for queued jobs)</li>
<li><code>NODELIST(REASON)</code>: Alias for NODELIST</li>
<li><code>PRIORITY</code>: Job priority (0-255)</li>
<li><code>DEPENDENCY</code>: Job ID this job depends on</li>
</ul>
<p><strong>Default format</strong>:</p>
<pre><code class="language-bash">JOBID,NAME,ST,TIME,TIMELIMIT,NODES,NODELIST(REASON)
</code></pre>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Minimal output
gqueue -f JOBID,NAME,ST

# Time-focused view
gqueue -f JOBID,TIME,TIMELIMIT

# Resource-focused view
gqueue -f JOBID,NODES,NODELIST,STATE

# Full info
gqueue -f JOBID,NAME,STATE,TIME,TIMELIMIT,NODES,NODELIST,PRIORITY,DEPENDENCY
</code></pre>
<h4 id="--group--g"><a class="header" href="#--group--g"><code>--group</code>, <code>-g</code></a></h4>
<p>Group jobs by state.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">$ gqueue -g
RUNNING:
JOBID    NAME                ST    TIME         TIMELIMIT
1        train-resnet        R     00:15:23     04:00:00
2        train-vit           R     00:12:45     04:00:00

QUEUED:
JOBID    NAME                ST    TIME         TIMELIMIT
3        eval-models         PD    00:00:00     00:30:00

FINISHED:
JOBID    NAME                ST    TIME         TIMELIMIT
4        preprocess          CD    00:05:12     01:00:00
</code></pre>
<h4 id="--tree--t"><a class="header" href="#--tree--t"><code>--tree</code>, <code>-t</code></a></h4>
<p>Display jobs in dependency tree format.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">$ gqueue -t
JOBID    NAME           ST    TIME         TIMELIMIT
1        data-prep      CD    00:05:23     01:00:00
├─ 2     train-model-a  R     00:15:45     04:00:00
│  └─ 4  eval-a         PD    00:00:00     00:10:00
└─ 3     train-model-b  R     00:15:50     04:00:00
   └─ 5  eval-b         PD    00:00:00     00:10:00
</code></pre>
<p><strong>Features</strong>:</p>
<ul>
<li>Shows parent-child relationships</li>
<li>Visualizes workflow structure</li>
<li>Detects and handles circular dependencies gracefully</li>
<li>ASCII tree drawing with box-drawing characters</li>
</ul>
<h3 id="sorting-options"><a class="header" href="#sorting-options">Sorting Options</a></h3>
<h4 id="--sort-field--r-field"><a class="header" href="#--sort-field--r-field"><code>--sort &lt;FIELD&gt;</code>, <code>-r &lt;FIELD&gt;</code></a></h4>
<p>Sort jobs by field.</p>
<p><strong>Valid fields</strong>:</p>
<ul>
<li><code>id</code>: Job ID (default)</li>
<li><code>state</code>: Job state</li>
<li><code>time</code>: Start time</li>
<li><code>name</code>: Job name</li>
<li><code>gpus</code>: Number of GPUs</li>
<li><code>priority</code>: Job priority</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Sort by priority (high to low)
gqueue -r priority

# Sort by name
gqueue -r name

# Sort by elapsed time
gqueue -r time

# Sort by GPU count
gqueue -r gpus
</code></pre>
<p><strong>Note</strong>: Sorting works with filtering and formatting options.</p>
<h3 id="global-options-1"><a class="header" href="#global-options-1">Global Options</a></h3>
<h4 id="--config-path-1"><a class="header" href="#--config-path-1"><code>--config &lt;PATH&gt;</code></a></h4>
<p>Use custom configuration file (hidden option).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gqueue --config /path/to/custom.toml
</code></pre>
<h4 id="--help--h-1"><a class="header" href="#--help--h-1"><code>--help</code>, <code>-h</code></a></h4>
<p>Display help message.</p>
<pre><code class="language-bash">$ gqueue --help
Lists jobs in the gflow scheduler.

Usage: gqueue [OPTIONS]

Options:
  -n, --limit &lt;LIMIT&gt;    Limit the number of jobs to display (positive: first N, negative: last N, 0: all) [default: -10]
  -a, --all              Show all jobs (equivalent to --limit 0)
  -r, --sort &lt;SORT&gt;      Sort jobs by field (options: id, state, time, name, gpus, priority) [default: id]
  -s, --states &lt;STATES&gt;  Filter by a comma-separated list of job states (e.g., Queued,Running)
  -j, --jobs &lt;JOBS&gt;      Filter by a comma-separated list of job IDs
  -N, --names &lt;NAMES&gt;    Filter by a comma-separated list of job names
  -f, --format &lt;FORMAT&gt;  Specify a comma-separated list of fields to display
  -g, --group            Group jobs by state (helps visualize job distribution)
  -t, --tree             Display jobs in tree format showing dependencies
  -h, --help             Print help
  -V, --version          Print version
</code></pre>
<h4 id="--version--v-1"><a class="header" href="#--version--v-1"><code>--version</code>, <code>-V</code></a></h4>
<p>Display version information.</p>
<pre><code class="language-bash">$ gqueue --version
gqueue 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<h2 id="output-format"><a class="header" href="#output-format">Output Format</a></h2>
<h3 id="default-output"><a class="header" href="#default-output">Default Output</a></h3>
<pre><code>JOBID    NAME                ST    TIME         TIMELIMIT    NODES    NODELIST(REASON)
1        silent-pump-6338    R     00:15:23     02:00:00     1        0
2        brave-river-1234    PD    00:00:00     04:00:00     2        (Resources)
3        gentle-wave-9876    CD    00:45:12     UNLIMITED    0        N/A
</code></pre>
<h3 id="column-descriptions"><a class="header" href="#column-descriptions">Column Descriptions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Column</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td>JOBID</td><td>Unique job identifier</td><td>42</td></tr>
<tr><td>NAME</td><td>Job run name (tmux session)</td><td>silent-pump-6338</td></tr>
<tr><td>ST</td><td>State (short)</td><td>R, PD, CD, F, CA, TO</td></tr>
<tr><td>STATE</td><td>State (long)</td><td>Running, Queued, Finished</td></tr>
<tr><td>TIME</td><td>Elapsed time</td><td>00:15:23</td></tr>
<tr><td>TIMELIMIT</td><td>Maximum runtime</td><td>02:00:00, UNLIMITED</td></tr>
<tr><td>NODES</td><td>GPU count</td><td>0, 1, 2</td></tr>
<tr><td>NODELIST(REASON)</td><td>GPU IDs or wait reason</td><td>0,1 or (Resources)</td></tr>
<tr><td>PRIORITY</td><td>Job priority</td><td>10 (default)</td></tr>
<tr><td>DEPENDENCY</td><td>Parent job ID</td><td>5 (or N/A)</td></tr>
</tbody></table>
</div>
<h3 id="state-codes"><a class="header" href="#state-codes">State Codes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Full State</th><th>Meaning</th></tr></thead><tbody>
<tr><td>PD</td><td>Queued</td><td>Waiting for resources or dependencies</td></tr>
<tr><td>R</td><td>Running</td><td>Currently executing</td></tr>
<tr><td>CD</td><td>Finished</td><td>Completed successfully</td></tr>
<tr><td>F</td><td>Failed</td><td>Exited with non-zero status</td></tr>
<tr><td>CA</td><td>Cancelled</td><td>Manually cancelled</td></tr>
<tr><td>TO</td><td>Timeout</td><td>Exceeded time limit</td></tr>
</tbody></table>
</div>
<h3 id="time-format"><a class="header" href="#time-format">Time Format</a></h3>
<p><strong>Elapsed time and time limits</strong>:</p>
<ul>
<li>Format: <code>HH:MM:SS</code> or <code>D-HH:MM:SS</code> (with days)</li>
<li>Examples:
<ul>
<li><code>00:15:23</code>: 15 minutes, 23 seconds</li>
<li><code>02:30:00</code>: 2 hours, 30 minutes</li>
<li><code>1-04:30:00</code>: 1 day, 4 hours, 30 minutes</li>
<li><code>UNLIMITED</code>: No time limit</li>
</ul>
</li>
</ul>
<h3 id="node-list-format"><a class="header" href="#node-list-format">Node List Format</a></h3>
<p><strong>For running jobs</strong>: Comma-separated GPU IDs</p>
<pre><code>0,1,2
</code></pre>
<p><strong>For queued jobs</strong>: Reason for waiting</p>
<pre><code>(Resources)
(Dependency: Job 5)
</code></pre>
<p><strong>For non-GPU jobs</strong>: N/A</p>
<pre><code>N/A
</code></pre>
<h2 id="examples-2"><a class="header" href="#examples-2">Examples</a></h2>
<h3 id="basic-usage-3"><a class="header" href="#basic-usage-3">Basic Usage</a></h3>
<pre><code class="language-bash"># View last 10 jobs
gqueue

# View all jobs
gqueue -a

# View last 20 jobs
gqueue -n 20
</code></pre>
<h3 id="filtering"><a class="header" href="#filtering">Filtering</a></h3>
<pre><code class="language-bash"># Show only running jobs
gqueue -s Running

# Show running and queued jobs
gqueue -s Running,Queued

# Show specific job
gqueue -j 42

# Show multiple jobs
gqueue -j 40,41,42

# Show jobs by name
gqueue -N "training-job"
</code></pre>
<h3 id="custom-formatting"><a class="header" href="#custom-formatting">Custom Formatting</a></h3>
<pre><code class="language-bash"># Minimal view
gqueue -f JOBID,NAME,ST

# Time-focused
gqueue -f JOBID,NAME,TIME,TIMELIMIT

# GPU-focused
gqueue -f JOBID,NAME,NODES,NODELIST

# Priority queue view
gqueue -f JOBID,NAME,PRIORITY,ST -r priority
</code></pre>
<h3 id="visualization"><a class="header" href="#visualization">Visualization</a></h3>
<pre><code class="language-bash"># Group by state
gqueue -g

# Show dependency tree
gqueue -t

# Tree view with filtering
gqueue -s Running,Queued -t
</code></pre>
<h3 id="sorting"><a class="header" href="#sorting">Sorting</a></h3>
<pre><code class="language-bash"># Sort by priority (highest first)
gqueue -r priority

# Sort by elapsed time
gqueue -r time

# Sort by job ID (default)
gqueue -r id
</code></pre>
<h3 id="monitoring-1"><a class="header" href="#monitoring-1">Monitoring</a></h3>
<pre><code class="language-bash"># Watch queue in real-time
watch -n 2 gqueue

# Watch running jobs
watch -n 2 'gqueue -s Running'

# Watch with custom format
watch -n 2 'gqueue -f JOBID,NAME,TIME,TIMELIMIT'

# Monitor dependency tree
watch -n 2 'gqueue -t'
</code></pre>
<h3 id="combined-options"><a class="header" href="#combined-options">Combined Options</a></h3>
<pre><code class="language-bash"># Running GPU jobs with details
gqueue -s Running -f JOBID,NAME,NODES,NODELIST,TIME

# Last 5 finished jobs
gqueue -s Finished -n 5 -r time

# All queued jobs grouped
gqueue -s Queued -g

# High-priority jobs first
gqueue -r priority -n 20
</code></pre>
<h2 id="common-patterns-3"><a class="header" href="#common-patterns-3">Common Patterns</a></h2>
<h3 id="check-job-status"><a class="header" href="#check-job-status">Check Job Status</a></h3>
<pre><code class="language-bash"># Is job 42 running?
gqueue -j 42 -f ST

# What's the status of my job?
gqueue -N "my-job-name" -f JOBID,ST
</code></pre>
<h3 id="monitor-pipeline"><a class="header" href="#monitor-pipeline">Monitor Pipeline</a></h3>
<pre><code class="language-bash"># View workflow
gqueue -t

# Watch pipeline progress
watch -n 2 'gqueue -t'
</code></pre>
<h3 id="find-stuck-jobs"><a class="header" href="#find-stuck-jobs">Find Stuck Jobs</a></h3>
<pre><code class="language-bash"># Jobs queued for long time
gqueue -s Queued -r time -f JOBID,NAME,TIME

# Why is my job queued?
gqueue -j 42 -t
</code></pre>
<h3 id="resource-monitoring"><a class="header" href="#resource-monitoring">Resource Monitoring</a></h3>
<pre><code class="language-bash"># What GPUs are in use?
gqueue -s Running -f JOBID,NAME,NODES,NODELIST

# How many jobs are waiting for GPUs?
gqueue -s Queued -f JOBID,NODELIST
</code></pre>
<h3 id="job-history"><a class="header" href="#job-history">Job History</a></h3>
<pre><code class="language-bash"># Recent completions
gqueue -s Finished -n 10 -r time

# Failed jobs
gqueue -s Failed -a

# Timed out jobs
gqueue -s Timeout -a
</code></pre>
<h2 id="integration-examples-1"><a class="header" href="#integration-examples-1">Integration Examples</a></h2>
<h3 id="shell-scripts"><a class="header" href="#shell-scripts">Shell Scripts</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Wait for job to complete

JOB_ID=42

while true; do
    STATUS=$(gqueue -j $JOB_ID -f ST | tail -n 1)

    if [ "$STATUS" = "CD" ]; then
        echo "Job completed successfully!"
        break
    elif [ "$STATUS" = "F" ] || [ "$STATUS" = "TO" ]; then
        echo "Job failed or timed out!"
        exit 1
    fi

    sleep 5
done
</code></pre>
<h3 id="pipeline-monitoring"><a class="header" href="#pipeline-monitoring">Pipeline Monitoring</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Monitor pipeline progress

echo "=== Pipeline Status ==="
gqueue -j 1,2,3,4,5 -t

echo -e "\n=== Running Jobs ==="
gqueue -s Running -f JOBID,NAME,TIME,TIMELIMIT

echo -e "\n=== Queued Jobs ==="
gqueue -s Queued -f JOBID,NAME,NODELIST
</code></pre>
<h3 id="resource-dashboard"><a class="header" href="#resource-dashboard">Resource Dashboard</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Simple resource dashboard

clear
echo "╔════════════════════════════════════════╗"
echo "║         gflow Resource Dashboard       ║"
echo "╚════════════════════════════════════════╝"

echo -e "\n📊 Running Jobs:"
gqueue -s Running -f JOBID,NAME,NODES,NODELIST

echo -e "\n⏳ Queued Jobs:"
gqueue -s Queued -f JOBID,NAME,NODES,NODELIST

echo -e "\n✅ Recently Completed:"
gqueue -s Finished -n 5 -r time -f JOBID,NAME,TIME
</code></pre>
<h3 id="job-stats"><a class="header" href="#job-stats">Job Stats</a></h3>
<pre><code class="language-bash">#!/bin/bash
# Job statistics

TOTAL=$(gqueue -a -f JOBID | tail -n +2 | wc -l)
RUNNING=$(gqueue -s Running -f JOBID | tail -n +2 | wc -l)
QUEUED=$(gqueue -s Queued -f JOBID | tail -n +2 | wc -l)
FINISHED=$(gqueue -s Finished -f JOBID | tail -n +2 | wc -l)
FAILED=$(gqueue -s Failed -f JOBID | tail -n +2 | wc -l)

echo "Total jobs: $TOTAL"
echo "Running: $RUNNING"
echo "Queued: $QUEUED"
echo "Finished: $FINISHED"
echo "Failed: $FAILED"
</code></pre>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="empty-output"><a class="header" href="#empty-output">Empty Output</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>No jobs in queue</li>
<li>All jobs filtered out by state/name/id filter</li>
<li>Daemon not running</li>
</ol>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check daemon
ginfo info

# View all jobs
gqueue -a

# Remove filters
gqueue
</code></pre>
<h3 id="formatting-issues"><a class="header" href="#formatting-issues">Formatting Issues</a></h3>
<p><strong>Issue</strong>: Columns misaligned</p>
<p><strong>Solution</strong>: Terminal too narrow or too many columns</p>
<pre><code class="language-bash"># Use fewer columns
gqueue -f JOBID,NAME,ST

# Increase terminal width
</code></pre>
<h3 id="state-not-updating"><a class="header" href="#state-not-updating">State Not Updating</a></h3>
<p><strong>Issue</strong>: Job state seems stale</p>
<p><strong>Solution</strong>: Daemon updates state every 5 seconds</p>
<pre><code class="language-bash"># Wait a few seconds
sleep 5
gqueue

gflowd down
gflowd up
</code></pre>
<h2 id="performance-notes"><a class="header" href="#performance-notes">Performance Notes</a></h2>
<ul>
<li><code>gqueue</code> is fast even with thousands of jobs</li>
<li>Filtering by ID is faster than by name</li>
<li>Tree view may be slow with very deep dependencies</li>
<li>Default limit (-10) keeps output manageable</li>
</ul>
<h2 id="see-also-6"><a class="header" href="#see-also-6">See Also</a></h2>
<ul>
<li><a href="reference/./gbatch-reference.html">gbatch</a> - Job submission reference</li>
<li><a href="reference/./gcancel-reference.html">gcancel</a> - Job cancellation reference</li>
<li><a href="reference/./ginfo-reference.html">ginfo</a> - Scheduler inspection reference</li>
<li><a href="reference/./quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
<li><a href="reference/../user-guide/job-submission.html">Job Submission</a> - Job submission guide</li>
<li><a href="reference/../user-guide/job-dependencies.html">Job Dependencies</a> - Dependency management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gcancel-command-reference"><a class="header" href="#gcancel-command-reference">gcancel Command Reference</a></h1>
<p>Complete reference for the <code>gcancel</code> command - gflow's job cancellation tool.</p>
<h2 id="synopsis-2"><a class="header" href="#synopsis-2">Synopsis</a></h2>
<pre><code class="language-bash">gcancel [OPTIONS] [IDS...]
gcancel --dry-run [IDS...]
gcancel --finish &lt;ID&gt;
gcancel --fail &lt;ID&gt;
</code></pre>
<h2 id="description-2"><a class="header" href="#description-2">Description</a></h2>
<p><code>gcancel</code> cancels one or more jobs in the gflow queue. It supports individual job IDs, ranges, and lists. The command also provides a dry-run mode to preview the impact of cancellation before executing it.</p>
<h2 id="options-2"><a class="header" href="#options-2">Options</a></h2>
<h3 id="job-selection"><a class="header" href="#job-selection">Job Selection</a></h3>
<h4 id="ids"><a class="header" href="#ids"><code>[IDS...]</code></a></h4>
<p>Job ID(s) to cancel. Supports multiple formats:</p>
<p><strong>Formats</strong>:</p>
<ul>
<li>Single ID: <code>42</code></li>
<li>Multiple IDs: <code>1 2 3</code> or <code>1,2,3</code></li>
<li>Ranges: <code>1-5</code> (IDs 1, 2, 3, 4, 5)</li>
<li>Mixed: <code>1,3,5-7,10</code></li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Cancel single job
gcancel 42

# Cancel multiple jobs
gcancel 1 2 3
gcancel 1,2,3

# Cancel range
gcancel 1-5

# Cancel mixed
gcancel 1,3,5-7,10
</code></pre>
<h3 id="preview-mode"><a class="header" href="#preview-mode">Preview Mode</a></h3>
<h4 id="--dry-run"><a class="header" href="#--dry-run"><code>--dry-run</code></a></h4>
<p>Preview cancellation without executing.</p>
<p><strong>Features</strong>:</p>
<ul>
<li>Shows which jobs would be cancelled</li>
<li>Identifies dependent jobs that will be affected</li>
<li>Validates job IDs before cancellation</li>
<li>Safe to run - makes no changes</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">$ gcancel --dry-run 1
Would cancel job 1 (data-prep)

⚠️  Warning: The following jobs depend on job 1:
  - Job 2 (train-model)
  - Job 3 (evaluate)

These jobs will never start if job 1 is cancelled.

To proceed with cancellation, run:
  gcancel 1
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Check impact before cancelling</li>
<li>Verify job IDs are correct</li>
<li>Understand dependency chains</li>
<li>Plan cleanup operations</li>
</ul>
<h3 id="internal-state-management-hidden"><a class="header" href="#internal-state-management-hidden">Internal State Management (Hidden)</a></h3>
<p>These options are used internally by gflow and are not intended for direct user interaction.</p>
<h4 id="--finish-id"><a class="header" href="#--finish-id"><code>--finish &lt;ID&gt;</code></a></h4>
<p>Mark job as finished (internal use only).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gcancel --finish 42
</code></pre>
<p><strong>Note</strong>: Used by the system to transition job states. Not recommended for manual use.</p>
<h4 id="--fail-id"><a class="header" href="#--fail-id"><code>--fail &lt;ID&gt;</code></a></h4>
<p>Mark job as failed (internal use only).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gcancel --fail 42
</code></pre>
<p><strong>Note</strong>: Used by the system to transition job states. Not recommended for manual use.</p>
<h3 id="global-options-2"><a class="header" href="#global-options-2">Global Options</a></h3>
<h4 id="--config-path-2"><a class="header" href="#--config-path-2"><code>--config &lt;PATH&gt;</code></a></h4>
<p>Use custom configuration file (hidden option).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gcancel --config /path/to/custom.toml 42
</code></pre>
<h4 id="--help--h-2"><a class="header" href="#--help--h-2"><code>--help</code>, <code>-h</code></a></h4>
<p>Display help message.</p>
<pre><code class="language-bash">$ gcancel --help
Controls job states in the gflow scheduler.

Usage: gcancel [OPTIONS] [IDS]

Arguments:
  [IDS]  Job ID(s) to cancel. Supports ranges like "1-3" or individual IDs like "1,2,3"

Options:
      --dry-run  If set, the job will not be cancelled, but the action will be printed
  -h, --help     Print help
  -V, --version  Print version
</code></pre>
<h4 id="--version--v-2"><a class="header" href="#--version--v-2"><code>--version</code>, <code>-V</code></a></h4>
<p>Display version information.</p>
<pre><code class="language-bash">$ gcancel --version
gcancel 0.3.14 (2025-10-31T07:56:04.036593510Z)
Branch: main
Commit: ca405086be69e9efa97b13daf61c1ed8a12f98ed
Authors: PuQing &lt;me@puqing.work&gt;
</code></pre>
<h2 id="behavior"><a class="header" href="#behavior">Behavior</a></h2>
<h3 id="successful-cancellation"><a class="header" href="#successful-cancellation">Successful Cancellation</a></h3>
<p>When a job is successfully cancelled:</p>
<ol>
<li>Job state changes to <code>Cancelled</code> (CA)</li>
<li>If the job is running:
<ul>
<li>tmux session receives <code>Ctrl-C</code> (SIGINT)</li>
<li>Job process is gracefully interrupted</li>
<li>Session is cleaned up</li>
</ul>
</li>
<li>If the job is queued:
<ul>
<li>Job is removed from the run queue</li>
<li>State changes immediately</li>
</ul>
</li>
<li>Output is captured to log file</li>
<li>Finish time is recorded</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">$ gcancel 42
Job 42 cancelled successfully

$ gqueue -j 42
JOBID    NAME      ST    TIME
42       my-job    CA    00:05:23
</code></pre>
<h3 id="dependent-jobs"><a class="header" href="#dependent-jobs">Dependent Jobs</a></h3>
<p>Cancelling a job affects dependent jobs:</p>
<ul>
<li>Dependent jobs remain in <code>Queued</code> state</li>
<li>They will <strong>never</strong> start automatically</li>
<li>You must manually cancel them</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash"># Job 2 depends on Job 1
$ gqueue -t
JOBID    NAME      ST
1        prep      R
└─ 2     train     PD

# Cancel job 1
$ gcancel 1
Job 1 cancelled

# Job 2 is now orphaned
$ gqueue -t
JOBID    NAME      ST
1        prep      CA
└─ 2     train     PD    # Will never start

# Must cancel job 2 manually
$ gcancel 2
</code></pre>
<h3 id="already-completed-jobs"><a class="header" href="#already-completed-jobs">Already Completed Jobs</a></h3>
<p>Cannot cancel finished jobs:</p>
<pre><code class="language-bash">$ gcancel 42
Error: Job 42 is already in terminal state (Finished)
</code></pre>
<p><strong>Terminal states</strong> (cannot be cancelled):</p>
<ul>
<li><code>Finished</code> (CD)</li>
<li><code>Failed</code> (F)</li>
<li><code>Cancelled</code> (CA)</li>
<li><code>Timeout</code> (TO)</li>
</ul>
<h3 id="non-existent-jobs"><a class="header" href="#non-existent-jobs">Non-existent Jobs</a></h3>
<pre><code class="language-bash">$ gcancel 999
Error: Job 999 not found
</code></pre>
<h2 id="examples-3"><a class="header" href="#examples-3">Examples</a></h2>
<h3 id="basic-cancellation"><a class="header" href="#basic-cancellation">Basic Cancellation</a></h3>
<pre><code class="language-bash"># Cancel single job
gcancel 42

# Cancel multiple jobs
gcancel 1 2 3
gcancel 1,2,3

# Cancel range
gcancel 10-20

# Cancel mixed
gcancel 1,5,10-15,20
</code></pre>
<h3 id="preview-before-cancelling"><a class="header" href="#preview-before-cancelling">Preview Before Cancelling</a></h3>
<pre><code class="language-bash"># Check what would happen
gcancel --dry-run 5

# Read output carefully
# If acceptable, proceed
gcancel 5
</code></pre>
<h3 id="cancel-pipeline"><a class="header" href="#cancel-pipeline">Cancel Pipeline</a></h3>
<pre><code class="language-bash"># View pipeline
$ gqueue -t
JOBID    NAME      ST
1        prep      R
├─ 2     train-a   PD
└─ 3     train-b   PD

# Cancel entire pipeline
gcancel 1,2,3

# Or cancel parent and children separately
gcancel 1
gcancel 2 3
</code></pre>
<h3 id="cancel-all-running-jobs"><a class="header" href="#cancel-all-running-jobs">Cancel All Running Jobs</a></h3>
<pre><code class="language-bash"># Get running job IDs
RUNNING=$(gqueue -s Running -f JOBID | tail -n +2 | tr '\n' ',' | sed 's/,$//')

# Cancel them
gcancel $RUNNING
</code></pre>
<h3 id="cancel-queued-jobs"><a class="header" href="#cancel-queued-jobs">Cancel Queued Jobs</a></h3>
<pre><code class="language-bash"># Get queued job IDs
QUEUED=$(gqueue -s Queued -f JOBID | tail -n +2)

# Cancel each one
for job in $QUEUED; do
    gcancel $job
done
</code></pre>
<h3 id="conditional-cancellation"><a class="header" href="#conditional-cancellation">Conditional Cancellation</a></h3>
<pre><code class="language-bash"># Cancel if job is taking too long
JOB_ID=42
ELAPSED=$(gqueue -j $JOB_ID -f TIME | tail -n 1 | cut -d: -f1)

if [ "$ELAPSED" -gt 2 ]; then
    echo "Job taking too long, cancelling..."
    gcancel $JOB_ID
fi
</code></pre>
<h2 id="common-patterns-4"><a class="header" href="#common-patterns-4">Common Patterns</a></h2>
<h3 id="cancel-and-resubmit"><a class="header" href="#cancel-and-resubmit">Cancel and Resubmit</a></h3>
<pre><code class="language-bash"># Cancel old job
gcancel 42

# Resubmit with corrections
gbatch --gpus 1 --time 2:00:00 python train.py --fixed
</code></pre>
<h3 id="cancel-failed-dependencies"><a class="header" href="#cancel-failed-dependencies">Cancel Failed Dependencies</a></h3>
<pre><code class="language-bash"># Find failed job
$ gqueue -s Failed
JOBID    NAME      ST
5        prep      F

# Cancel dependent jobs (they won't start anyway)
$ gqueue -t | grep -A10 "^5"
5        prep      F
└─ 6     train     PD

$ gcancel 6
</code></pre>
<h3 id="emergency-stop"><a class="header" href="#emergency-stop">Emergency Stop</a></h3>
<pre><code class="language-bash"># Stop all running and queued jobs
gcancel $(gqueue -s Running,Queued -f JOBID | tail -n +2)
</code></pre>
<h3 id="selective-cancellation"><a class="header" href="#selective-cancellation">Selective Cancellation</a></h3>
<pre><code class="language-bash"># Cancel low-priority queued jobs
gqueue -s Queued -r priority -f JOBID,PRIORITY | awk '$2 &lt; 10 {print $1}' | xargs gcancel
</code></pre>
<h2 id="integration-examples-2"><a class="header" href="#integration-examples-2">Integration Examples</a></h2>
<h3 id="script-safe-cancellation"><a class="header" href="#script-safe-cancellation">Script: Safe Cancellation</a></h3>
<pre><code class="language-bash">#!/bin/bash
# safe_cancel.sh - Cancel with dependency check

JOB_ID=$1

# Check dependencies
gcancel --dry-run $JOB_ID

read -p "Proceed with cancellation? (y/n) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    gcancel $JOB_ID
    echo "Job $JOB_ID cancelled"
else
    echo "Cancellation aborted"
fi
</code></pre>
<h3 id="script-cancel-pipeline"><a class="header" href="#script-cancel-pipeline">Script: Cancel Pipeline</a></h3>
<pre><code class="language-bash">#!/bin/bash
# cancel_pipeline.sh - Cancel all jobs in a pipeline

ROOT_JOB=$1

# Get all dependent jobs
JOBS=$(gqueue -t | awk -v root=$ROOT_JOB '
    $1 == root || seen {
        seen = 1
        print $1
    }
')

echo "Jobs to cancel: $JOBS"
gcancel $JOBS
</code></pre>
<h3 id="script-timeout-watcher"><a class="header" href="#script-timeout-watcher">Script: Timeout Watcher</a></h3>
<pre><code class="language-bash">#!/bin/bash
# timeout_watcher.sh - Cancel jobs exceeding expected time

MAX_TIME=120  # 2 hours in minutes

gqueue -s Running -f JOBID,TIME | tail -n +2 | while read -r jobid time; do
    # Convert time to minutes
    IFS=: read -r h m s &lt;&lt;&lt; "$time"
    minutes=$((10#$h * 60 + 10#$m))

    if [ $minutes -gt $MAX_TIME ]; then
        echo "Job $jobid exceeded $MAX_TIME minutes, cancelling..."
        gcancel $jobid
    fi
done
</code></pre>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<h3 id="issue-cannot-cancel-job"><a class="header" href="#issue-cannot-cancel-job">Issue: Cannot cancel job</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>Job already in terminal state</li>
<li>Job ID doesn't exist</li>
<li>Permission issues</li>
</ol>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check job state
gqueue -j &lt;job_id&gt; -f JOBID,ST

# Verify job exists
gqueue -a | grep &lt;job_id&gt;

# Check daemon status
ginfo info
</code></pre>
<h3 id="issue-dependent-jobs-not-cancelled"><a class="header" href="#issue-dependent-jobs-not-cancelled">Issue: Dependent jobs not cancelled</a></h3>
<p><strong>Expected behavior</strong>: gcancel only cancels specified jobs, not dependents.</p>
<p><strong>Solution</strong>: Cancel dependents manually:</p>
<pre><code class="language-bash"># Use dry-run to see dependents
gcancel --dry-run 1

# Cancel parent and children
gcancel 1,2,3
</code></pre>
<h3 id="issue-job-still-running-after-cancellation"><a class="header" href="#issue-job-still-running-after-cancellation">Issue: Job still running after cancellation</a></h3>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>Job is handling SIGINT gracefully (saving state)</li>
<li>tmux session cleanup delay</li>
<li>Job process not responding</li>
</ol>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Wait a few seconds
sleep 5
gqueue -j &lt;job_id&gt;

# Check tmux session
tmux ls

# Force kill tmux session if needed
tmux kill-session -t &lt;session_name&gt;
</code></pre>
<h3 id="issue-range-parsing-error"><a class="header" href="#issue-range-parsing-error">Issue: Range parsing error</a></h3>
<p><strong>Example</strong>:</p>
<pre><code class="language-bash">gcancel 1-5,10
</code></pre>
<p><strong>Solution</strong>: Check range syntax:</p>
<ul>
<li>Ranges: <code>1-5</code> (valid)</li>
<li>Lists: <code>1,2,3</code> (valid)</li>
<li>Mixed: <code>1-5,10</code> (depends on implementation)</li>
</ul>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<ol>
<li>
<p><strong>Use dry-run first</strong> for important cancellations</p>
<pre><code class="language-bash">gcancel --dry-run 42
gcancel 42
</code></pre>
</li>
<li>
<p><strong>Check dependencies</strong> before cancelling parent jobs</p>
<pre><code class="language-bash">gqueue -t
</code></pre>
</li>
<li>
<p><strong>Cancel gracefully</strong> during development/testing</p>
<ul>
<li>Jobs can save checkpoints</li>
<li>Logs are preserved</li>
</ul>
</li>
<li>
<p><strong>Clean up dependents</strong> when cancelling parent jobs</p>
<pre><code class="language-bash">gcancel 1,2,3  # parent and children
</code></pre>
</li>
<li>
<p><strong>Monitor cancellation</strong> to ensure it completes</p>
<pre><code class="language-bash">gcancel 42
watch -n 1 'gqueue -j 42'
</code></pre>
</li>
<li>
<p><strong>Log cancellations</strong> for audit trail</p>
<pre><code class="language-bash">echo "$(date): Cancelled job 42" &gt;&gt; ~/gflow-cancellations.log
gcancel 42
</code></pre>
</li>
<li>
<p><strong>Use job names</strong> to identify which jobs to cancel</p>
<pre><code class="language-bash">gqueue -N "old-experiment*"
gcancel &lt;identified_ids&gt;
</code></pre>
</li>
<li>
<p><strong>Avoid cancelling system jobs</strong> (if any)</p>
<ul>
<li>Be careful with automated cancellation scripts</li>
</ul>
</li>
</ol>
<h2 id="error-messages"><a class="header" href="#error-messages">Error Messages</a></h2>
<h3 id="common-errors-1"><a class="header" href="#common-errors-1">Common Errors</a></h3>
<pre><code class="language-bash"># Job not found
Error: Job 999 not found
</code></pre>
<pre><code class="language-bash"># Job already terminal
Error: Job 42 is already in terminal state (Finished)
</code></pre>
<pre><code class="language-bash"># Invalid job ID
Error: Invalid job ID: abc
</code></pre>
<pre><code class="language-bash"># No job ID provided
Error: No job IDs specified
Usage: gcancel [OPTIONS] [IDS...]
</code></pre>
<pre><code class="language-bash"># Daemon not running
Error: Could not connect to gflowd (connection refused)
</code></pre>
<h2 id="exit-codes-1"><a class="header" href="#exit-codes-1">Exit Codes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Meaning</th></tr></thead><tbody>
<tr><td>0</td><td>Success</td></tr>
<tr><td>1</td><td>Error (job not found, already terminal, etc.)</td></tr>
<tr><td>2</td><td>Invalid arguments</td></tr>
</tbody></table>
</div>
<h2 id="see-also-7"><a class="header" href="#see-also-7">See Also</a></h2>
<ul>
<li><a href="reference/./gbatch-reference.html">gbatch</a> - Job submission reference</li>
<li><a href="reference/./gqueue-reference.html">gqueue</a> - Job queue reference</li>
<li><a href="reference/./ginfo-reference.html">ginfo</a> - Scheduler inspection reference</li>
<li><a href="reference/./quick-reference.html">Quick Reference</a> - Command cheat sheet</li>
<li><a href="reference/../user-guide/job-submission.html">Job Submission</a> - Job submission guide</li>
<li><a href="reference/../user-guide/job-dependencies.html">Job Dependencies</a> - Dependency management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ginfo-command-reference"><a class="header" href="#ginfo-command-reference">ginfo Command Reference</a></h1>
<p>Complete reference for the <code>ginfo</code> command — gflow's scheduler inspection tool.</p>
<h2 id="synopsis-3"><a class="header" href="#synopsis-3">Synopsis</a></h2>
<pre><code class="language-bash">ginfo &lt;COMMAND&gt; [OPTIONS]
</code></pre>
<h2 id="description-3"><a class="header" href="#description-3">Description</a></h2>
<p><code>ginfo</code> connects to a running gflow daemon (<code>gflowd</code>) and prints scheduler metadata, GPU availability, and which jobs are currently bound to each device. The command is read-only and can be run as often as needed to monitor the system.</p>
<p>If the daemon is unreachable, <code>ginfo</code> reports the connection failure without modifying any state.</p>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<h3 id="info"><a class="header" href="#info"><code>info</code></a></h3>
<p>Display the current scheduler status and GPU allocation.</p>
<p><strong>Syntax</strong></p>
<pre><code class="language-bash">ginfo info
</code></pre>
<p><strong>What it shows</strong></p>
<ul>
<li>GPU indices, short UUIDs, and availability</li>
<li>Jobs currently occupying each GPU (job ID and run name)</li>
<li>Scheduler metadata (total GPUs detected, availability)</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code class="language-bash"># Query the default daemon using the default config path
ginfo info

# Use a custom configuration file
ginfo --config ~/gflow-dev/config.toml info

# Refresh the view every 2 seconds
watch -n 2 ginfo info
</code></pre>
<p>When the daemon is offline, the command prints a helpful error such as:</p>
<pre><code>ginfo: daemon not reachable: ...
</code></pre>
<h2 id="global-options-3"><a class="header" href="#global-options-3">Global Options</a></h2>
<h3 id="--config-path-3"><a class="header" href="#--config-path-3"><code>--config &lt;PATH&gt;</code></a></h3>
<p>Specify an alternate configuration file when connecting to the daemon.</p>
<pre><code class="language-bash">ginfo --config /path/to/custom.toml info
</code></pre>
<p>Use this when running multiple gflow instances or testing non-default settings.</p>
<h3 id="-v--vv--q"><a class="header" href="#-v--vv--q"><code>-v</code>, <code>-vv</code>, <code>-q</code></a></h3>
<p>Adjust log verbosity for troubleshooting:</p>
<ul>
<li><code>-v</code> enables info-level logging</li>
<li><code>-vv</code> enables debug logging</li>
<li><code>-q</code> suppresses non-error output</li>
</ul>
<h2 id="usage-patterns"><a class="header" href="#usage-patterns">Usage Patterns</a></h2>
<pre><code class="language-bash"># Combine with gqueue for a full snapshot
ginfo info &amp;&amp; gqueue -s Running -f JOBID,NAME,NODES,NODELIST

# Create a lightweight dashboard
watch -n 5 '
  clear
  date
  echo
  ginfo info
'
</code></pre>
<p><code>ginfo</code> is safe to run from scripts, cron jobs, and monitoring tooling because it never mutates scheduler state.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
